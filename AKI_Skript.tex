\documentclass[12pt, german]{article}
\usepackage[ngerman]{babel}
\usepackage[T1]{fontenc}  
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{array}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{upgreek}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{listings}  
\usepackage{mathtools}
\usepackage{listings}
\usepackage{endnotes}
\usepackage{color}
\usepackage{tasks}
\usepackage{mathtools}
\usepackage{forest}
\usetikzlibrary{backgrounds,fit}
\usepackage[outline]{contour}
\usetikzlibrary{shapes.multipart}
\usetikzlibrary{shapes,fit}
\usetikzlibrary{fit}
\usepackage{wrapfig}
\usepackage{hyperref}
\usepackage{mathrsfs}
\usepackage{tikz-cd}
\usepackage[bottom]{footmisc}
\usepackage{booktabs}
\usetikzlibrary{decorations,decorations.markings,decorations.text}
\usepackage{tabularx}
\usetikzlibrary{arrows}
\usepackage{float}
\usepackage{dsfont}
\usepackage{relsize}
\usepackage{ stmaryrd }
\usepackage{multirow,bigdelim}
\usepackage{stackengine}
\usepackage{amsmath}
\usetikzlibrary{backgrounds}
\usepackage{array, makecell}
\usepackage{pst-node}
\usepackage{multicol}
\usetikzlibrary{calc}
\usetikzlibrary{automata, positioning}
\usetikzlibrary{fit}
\usetikzlibrary{positioning,arrows}

%Half grey node
\makeatletter
\tikzset{
	prefix after node/.style={
		prefix after command={\pgfextra{#1}}
	},
	/semifill/ang/.store in=\semi@ang,
	/semifill/ang=0,
	semifill/.style={
		circle, draw,
		prefix after node={
			\typeout{aaa \semi@ang}
			\let\nodename\tikz@last@fig@name
			\fill[/semifill/.cd, /semifill/.search also={/tikz}, #1]
			let \p1 = (\nodename.north), \p2 = (\nodename.center) in
			let \n1 = {\y1 - \y2} in
			(\nodename.\semi@ang) arc [radius=\n1, start angle=\semi@ang, delta angle=180];
		},
	}
}
\makeatother



\stackMath


\hypersetup{
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}

%Für Binärbaum
\usepackage{tikz}
\tikzset{
	treenode/.style = {align=center, inner sep=0pt, text centered, font=\upshape},
	arn_b/.style = {treenode, circle, black, font=\upshape, draw=black, fill=okmama, text width=1.5em, thick},
	arn_x/.style = {treenode, rectangle, draw=black, minimum width=0.5em, minimum height=0.5em}
}


%Zum runden
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

%Document Feineinstellungen
\usepackage[a4paper, left=2cm, right=2cm, top=2.5cm]{geometry}

%Deaktiviert Seitenummerierung
%\pagenumbering{gobble}

%Farben für Einstellungen der Code Fragmente
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{okmama}{RGB}{150,170,120}
\definecolor{character}{RGB}{179, 178, 255}

%Einstellungen für Code Fragmente
\lstset{ 
	backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}; should come as last argument
	%	basicstyle=\footnotesize,        % the size of the fonts that are used for the code
	%	breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
	%	breaklines=true,                 % sets automatic line breaking
	captionpos=b,                    % sets the caption-position to bottom
	commentstyle=\color{mygreen},    % comment style
	deletekeywords={...},            % if you want to delete keywords from the given language
	escapeinside={(*}{*)},          % if you want to add LaTeX within your code
	extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
	frame=single,	                   % adds a frame around the code
	keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
	keywordstyle=\color{blue},       % keyword style
	language=Octave,                 % the language of the code
	morekeywords={*, Algorithm, ...},            % if you want to add more keywords to the set
	numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
	numbersep=5pt,                   % how far the line-numbers are from the code
	numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
	rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
	showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
	showstringspaces=false,          % underline spaces within strings only
	showtabs=false,                  % show tabs within strings adding particular underscores
	stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
	stringstyle=\color{mymauve},     % string literal style
	tabsize=2,	                   % sets default tabsize to 2 spaces
	title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}


%Für Klammern neben Align Zeilen
\makeatletter

\newcommand*{\rbracedalign}[5][c]{%
	\sbox0{\m@th$\begin{aligned}[b]#3\end{aligned}$}%
	\sbox1{\m@th$\vcenter{\hrule \@width\z@ \@height\ht0 \@depth\dp0}$}%
	\sbox0{\raise\dimexpr\dp1-\dp0\relax\hbox{\m@th$\left. \box1 \right\rbrace #5$}}%
	\dp0=\z@ \ht0=\z@
	\begin{aligned}[#1]
		\if\relax\detokenize{#2}\relax\expandafter\@gobble\else\expandafter\@firstofone\fi{#2&\\}
		#3& \box0
		\if\relax\detokenize{#4}\relax\expandafter\@gobble\else\expandafter\@firstofone\fi{\\#4&}
	\end{aligned}
}

\makeatother



%Global Align
\newcommand*{\LongestName}{\ensuremath{h(x)+g(x)}}% function name
\newcommand*{\LongestValue}{\ensuremath{-1}}% function value
\newcommand*{\LongestText}{fermentum fringilla mauris }%

%größere Brüche
\newcommand\ddfrac[2]{\frac{\displaystyle #1}{\displaystyle #2}}

\newlength{\LargestNameSize}%
\newlength{\LargestValueSize}%
\newlength{\LargestTextSize}%

\settowidth{\LargestNameSize}{\LongestName}%
\settowidth{\LargestValueSize}{\LongestValue}%
\settowidth{\LargestTextSize}{\LongestText}%

% Choose alignment of the various elements here: [r], [l] or [c]
\newcommand*{\MakeBoxName}[1]{{\makebox[\LargestNameSize][r]{\ensuremath{#1}}}}%
\newcommand*{\MakeBoxValue}[1]{\ensuremath{\makebox[\LargestValueSize][l]{\ensuremath{#1}}}}%
\newcommand*{\MakeBoxText}[1]{\makebox[\LargestTextSize][l]{#1}}%

%Isomorph zeichen
\newcommand\iso{\xrightarrow{
		\,\smash{\raisebox{-0.65ex}{\ensuremath{\scriptstyle\sim}}}\,}}

%Mathematische Zeichen
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\B}{\mathbb{B}}
\newcommand{\sigstern}{\Sigma^\ast}
\newcommand{\inv}{^{-1}}
\newcommand{\pom}{^{\omega}}
\newcommand{\rat}{\mathsf{RAT}}
\newcommand{\rec}{\mathsf{REC}}
\newcommand{\starfree}{\mathsf{SF}}
\newcommand{\synt}{\mathsf{Synt}}
\newcommand{\wop}{\mathsf{WP}}
\newcommand{\equivWP}{\equiv_{\mathsf{WP}(G)}}


\newcommand{\grel}{\sim_{\mathcal{L}}}
\newcommand{\grer}{\sim_{\mathcal{R}}}
\newcommand{\grej}{\sim_{\mathcal{J}}}
\newcommand{\greh}{\sim_{\mathcal{H}}}
\newcommand{\gred}{\sim_{\mathcal{D}}}
\newcommand{\grey}{\sim_{\mathcal{Y}}}

\newcommand{\lgreleq}{\leqslant_{\mathcal{L}}}
\newcommand{\lgrereq}{\leqslant_{\mathcal{R}}}
\newcommand{\lgrejeq}{\leqslant_{\mathcal{J}}}
\newcommand{\lgreheq}{\leqslant_{\mathcal{H}}}
\newcommand{\lgredeq}{\leqslant_{\mathcal{D}}}
\newcommand{\lgreyeq}{\leqslant_{\mathcal{Y}}}
\usepackage{blkarray}

\newcommand{\lcal}{\mathcal L}
\newcommand{\rcal}{\mathcal R}
\newcommand{\hcal}{\mathcal H}
\newcommand{\jcal}{\mathcal J}
\newcommand{\dcal}{\mathcal D}

\newcommand{\rgreleq}{\geqslant_{\mathcal{L}}}
\newcommand{\rgrereq}{\geqslant_{\mathcal{R}}}
\newcommand{\rgrejeq}{\geqslant_{\mathcal{J}}}
\newcommand{\rgreheq}{\geqslant_{\mathcal{H}}}
\newcommand{\rgredeq}{\geqslant_{\mathcal{D}}}
\newcommand{\rgreyeq}{\geqslant_{\mathcal{Y}}}
\newcommand{\aast}{A^{\ast}}
\newcommand{\bast}{B^{\ast}}
\newcommand{\east}{E^{\ast}}
\newcommand{\sast}{\Sigma^{\ast}}

%MSO
\newcommand{\fv}{\mathsf{FV}}
\newcommand{\fo}{\mathsf{FO}}
\newcommand{\so}{\mathsf{SO}}
\newcommand{\mso}{\mathsf{MSO}}
\newcommand{\reg}{\mathsf{REG}}
\newcommand{\ap}{\mathsf{AP}}
\newcommand{\ltl}{\mathsf{LTL}}
\newcommand{\tl}{\mathsf{TL}}

%LTL
\newcommand{\sX}{\mathsf{X}}
\newcommand{\sF}{\mathsf{F}}
\newcommand{\sG}{\mathsf{G}}
\newcommand{\sT}{\mathsf{T}}
\newcommand{\sY}{\mathsf{Y}}
\newcommand{\sS}{\mathsf{S}}
\newcommand{\sU}{\mathsf{U}}
\newcommand{\sR}{\mathsf{R}}
\newcommand{\sende}{\mathsf{END}}
\newcommand{\tf}{\mathsf{TF}}

%ohne einschränkung
\newcommand{\oei}{\OE\hspace{2pt}}



%Erzeugt das "bewiesen" Kästen rechts unten
\newcommand{\bewiesen}{
	
	\begin{flushright}
		$\square$  \\
\end{flushright}}


%\newcommand\TBox[3][]{%
%	\tikz\node[draw,thick,text width=#2,#1] {#3};}


\title{Inoffizielles Skript für Algebra \& Kombinatorik}

\author{Maximilian Kurz \and Amelie Heindl}
\setlength\parindent{0pt}

\begin{document}
	\maketitle
	\newpage
	\tableofcontents
	\newpage
	
	\section{Grundlagen - Vorlesung 1}
	\subsection{Diedergruppen}
	\subsubsection{Definition}
	Die Diedergruppe $D_n$ ist die Bewegungsgruppe des regelmäßigen $n$-Ecks mit $n \geq 3$. Dabei ist die Gruppenverknüpfung die Drehung oder Spiegelung des $n$-Ecks. \\ 
	
	Nun ist das $n$-Eck durch folgende Knoten und Kanten definiert: 
	\begin{align*}
		\text{Knotenmenge: } &\mathbb{Z}/n\mathbb{Z} \\
		\text{Kanten: } &\{ \{i, i+1\} \mid i \in \mathbb{Z}/n\mathbb{Z} \}  \\
	\end{align*}
	
	Weiter sind die Drehungen und Spiegelungen bijektive Abbildung von Knoten auf Knoten der Form
	\begin{align*}
		&f: \mathbb{Z}/n\mathbb{Z} \iso \mathbb{Z}/n\mathbb{Z},\, \text{ wobei }\\
		&f(i+1) \in \{f(i)+1, f(i)-1\}\, \text{ gilt}
	\end{align*}
	
	Zu jeden $n \in \mathbb{N}$ gehört eine Diedergruppe $D_n$ mit $|D_n| = 2n$. 
	Diese $2n$ Elemente sind Äuivalenzklassen aus Sequenzen von $\delta s$ und $\sigma s$.
	Wie in \ref{sec:diederEigenschaften} zu sehen sein wird, führt bei $\sigma$ die Kongruenz modulo $2$ und bei $\delta$ die Kongruenz modulo $n$ zum selben Bild, weshalb es gesamt $2n$ verschiedene Bilder gibt.
	
	
	Folglich lassen sich Diedergruppen so definieren, dass sie aus der Menge $\{\Sigma_{i=1}^{k}\alpha_i \, | \, \alpha_i \in \{\sigma, \delta\}, k \in \N\}$ besteht und als Verknüpfung die Konkatenation hat, also die Hintereinanderausführung der Abbildungssequenzen.
	
	
	\subsubsection{Eigenschaften von Diedergruppen}
	\label{sec:diederEigenschaften}
	Wir bezeichnen die Spiegelung mit $\sigma$ und die Drehung im Uhrzeiger mit $\delta$. Dann gilt Folgendes:
	
	\begin{align*}
		\sigma(j)&=-j\\
		\delta(j)&=j+1\\
		\sigma^2 = id &= \delta^n = \delta^0 \\ 	 
	\end{align*}
	Dies bedeutet, dass $n$-faches drehen oder doppeltes Spiegeln eines  $n$-Ecks keine Änderung bewirkt.  \\
	Daraus lässt sich dann folgender Satz ableiten mit $\forall \varepsilon, \varepsilon', m, m' \in \mathbb{Z}$: 
	
	\begin{align*}
		\sigma^\varepsilon\delta^m = \sigma^{\varepsilon'}\delta^{m'} \iff \varepsilon \equiv \varepsilon' (2) \text{ und } m \equiv m' (n)
	\end{align*}
	Weiter gilt, dass $\sigma\delta = \delta^{-1}\sigma$, also dass erst spiegeln und dann drehen denselben Effekt hat wie in die andere Richtung drehen und dann spiegeln. Im Folgenden wird gezeigt, weshalb dies gilt:
	
	\begin{align*}
		\sigma \delta(j) = \sigma(j+1) = -(j + 1) = -j -1 = \delta^{-1}(-j)=\delta^{-1}\sigma(j)
	\end{align*}
	\bewiesen
	Dieser Satz gibt uns also die Möglichkeit das $\sigma$ nach rechts oder links zu schieben und wir können die Gleichheit $\sigma\delta\sigma = \delta^{-1}$ folgern.
	
	\subsubsection{Fixpunkte in Diedergruppen}
	Ein Fixpunkt $x$ einer Abbildung $f$ ist ein Punkt, für den $f(x) = x$ gilt. Da die Elemente der Diedergruppe durch $\sigma\delta^i(j)$ dargestellt werden können, fragen wir uns, wann folgende Gleichheit gilt:
	\begin{align*}
		\sigma\delta^i(j) = j
	\end{align*} 
	
	Wegen
	\begin{align*}
		\sigma\delta^i(j)  = j &\iff \sigma(j+1)  = j  \\
		&\iff 	-j -i  = j \\
		&\iff 	-i  = 2j
	\end{align*} 
	ist dies der Fall, wenn $-i = 2j \textrm{ in } \mathbb Z /n \mathbb Z$ gilt. Für ungerades $n$ existiert für alle $i$ genau ein $j$, welches diese Gleichheit erfüllt. Für gerades $n$ unterscheiden wir weiter nach der Parität von $i$. Falls auch $i$ gerade ist, existieren genau $2$ verschiedene $j$ und falls $i$ ungerade ist, existiert keine Lösung. Damit ergeben sich bestimmte Fixpunkte für die Drehungen und Spiegelungen, welche in Tabelle~\ref{tab:diederFixpunkte} aufgezeigt sind.
	\begin{table*}[h]
		\centering
		\begin{tabular}{lll}
			\toprule[2pt]
			Abbildung & Parität von $n$ & Fixpunkte\\
			\midrule
			$\sigma$ & ungerade & $\{i\}$ \\
			\addlinespace
			$\sigma$ & gerade & $ \left \{
			
			%Lässt mehr Abstand zwischen den Zeilen, erhöht lesbarkeit denke ich :) 
			\arraycolsep=1.4pt\def\arraystretch{1.5}
			\begin{array}{ll}
				\{0,\frac{n}{2}\}\textrm{, falls }i \equiv 0 \, (2)\\
				\emptyset\textrm{, falls } i \equiv 1\, (2)
			\end{array}
			\right. $ \\
			\addlinespace
			$\delta^k$ & gerade oder ungerade & $ \left \{
			\arraycolsep=1.4pt\def\arraystretch{1.5}
			\begin{array}{ll}
				\emptyset\textrm{, falls }1\leq k < n\\
				\Z/n\Z\textrm{, falls } k \equiv 0\, (n)
			\end{array}
			\right. $ \\
			\bottomrule[2pt]
		\end{tabular}
		\caption{Fixpunkte der Abbildungen in Diedergruppen.}
		\label{tab:diederFixpunkte}
	\end{table*}
	
	\subsubsection{Erweiterung auf unendliche Gruppen}
	
	Im Fall $n=0$ ist das $n$-Eck die unendliche gerade $\Z/0\Z = \Z$.
	
	Durch Einführen eines weiteren Zeichens $\overline{\delta}$ für negative Potenzen von $\delta$ gelten dieselben Rechenregeln wie im endlichen Fall.
	
	Dann gilt $D_0 = \{\sigma, \delta, \overline{\delta}\}^*$ mit
	\begin{align*}
		\sigma^i(j) & = j+i &&\delta(j)  = -j \\
		\sigma^2 & = 1 &&\delta\overline{\delta} = \overline{\delta}\delta = 1 \\
		\sigma\delta\sigma & = \overline{\delta}
	\end{align*}
	
	\section{Gruppentheorie 1 - Vorlesung 2}
	\subsection{Untergruppen}
	\subsubsection{Definition}
	Sei im folgenden $G=(G, \cdot, 1)$ eine Gruppe. Dann gilt 
	\begin{align*}
		H \subseteq G \text{ ist eine Untergruppe} \iff H \not = \emptyset \text{ und } \forall g, h \in H : gh^{-1} \in H
	\end{align*}
	$H$ ist also eine Untergruppe von $G$ genau dann, wenn $H$ nicht leer ist, abgeschlossen ist und für alle Elemente ein Inverses enthält. Aus diesen Bedingungen folgt direkt, dass dann auch $1 \in H$ gilt.
	Für Untergruppen ist die Schreibweise $H\leq G$ üblich.
	
	
	\subsection{Nebenklassen}
	\subsubsection{Definition}
	Für eine Untergruppe $H \leq G$ sind die folgenden Nebenklassen definiert:
	\begin{align*}
		G/H &= \{gH \subseteq G \mid g \in G\} \quad \text{Menge der Linksnebenklassen } \\
		H/G &= \{Hg \subseteq G \mid g \in G\} \quad \text{Menge der Rechtsnebenklassen } 
	\end{align*}
	wobei $gH$ die Multiplikation von  g mit allen Elementen aus $H$ ist, also die Linksnebenklasse bezüglich dem Element $g$. 
	
	\subsubsection{Grö\ss e von Nebenklassen}
	Wir definieren die folgenden Abbildungen $	\forall f,g \in G$ ist
	\begin{align*}
		(fg^{-1} \cdot): gH &\iso fH \\
		gh &\mapsto fh = fg^{-1}gh
	\end{align*}
	Diese ist bijektiv mit der Umkehrabbildung $(gf^{-1}\cdot)$.
	Wir können dann folgern, dass $\forall f,g \in G$
	\begin{align*}
		gH \iso H \iso Hf 
	\end{align*} 
	Es gilt also $|gH| = |Hf| = |H|\text{ für alle } f,g \in G$.
	
	\subsubsection{Gleichheit und Disjunktheit von Nebenklassen}
	Sowohl $G/H$ als auch $H/G$ sind jeweils Partitionen von $G$.
	Um das zu beweisen, wird im Folgenden gezeigt, dass $gH \cap fH \not = \emptyset \iff gH = fH$ gilt.
	Die Rückrichtung ist hierbei trivial, da der Schnitt von $gH$ und $fH$ bei Gleichheit offensichtlich nicht leer ist, sofern die Nebenklassen an sich nicht leer sind, was per Definition gegeben ist. \\
	
	Für den Beweis der Hinrichtung seinen $h_1, h_2 \in H$ mit $gh_1 = fh_2$
	\begin{align*}
		&\implies g=fh_2h_1^{-1} \in fH \\
		&\implies gH \subseteq fH. 
	\end{align*}
	Analog dazu kann man $fH \subseteq gH$ zeigen, womit $gH = fH$ folgt.
	\bewiesen
	
	\subsubsection{Graphische Interpretation von Nebenklassen}
	Sei $G= (G, \cdot, 1)$ eine Gruppe und $H\leq G$. 
	In Abbildung \ref{fig:nebenklassen} sind mögliche Partitionen von $G$ dargestellt.
	Dies veranschaulicht, dass Links- und Rechtsnebenklassen (i.A. verschiedene) gleichmä\ss ige Partitionen von $G$ sind.
	\begin{figure}[H]
		\centering
		$G=\begin{array}{c}
			
			\begin{tikzpicture}[every fit/.style={inner sep=0pt, outer sep=0pt, draw}]
				\begin{scope}[yshift=1.5cm,y=1cm]
					\node [fit={(0,0) (1,3)}, label=center:{$H$}] {};
				\end{scope}
				\begin{scope}[yshift=1.5cm,y=1cm]
					\node [fit={(1,0) (4,1)}, label=center:{$fH$}] {};
				\end{scope}
				\begin{scope}[yshift=2.5cm,y=1cm]
					\node [fit={(1,0) (4,1)}, label=center:{$\vdots$}] {};
				\end{scope}
				\begin{scope}[yshift=3.5cm,y=1cm]
					\node [fit={(1,0) (4,1)}, label=center:{$gH$}] {};
				\end{scope}
				
			\end{tikzpicture} 
		\end{array}
		= 
		\begin{array}{c}
			\begin{tikzpicture}[every fit/.style={inner sep=0pt, outer sep=0pt, draw}]
				\begin{scope}[yshift=1.5cm,y=1cm]
					\node [fit={(0,0) (1,3)}, label=center:{$H$}] {};
				\end{scope}
				\begin{scope}[yshift=1.5cm,y=1cm]
					\node [fit={(1,3) (2,0)}, label=center:{$Hg$}] {};
				\end{scope}
				\begin{scope}[yshift=1.5cm,y=1cm]
					\node [fit={(2,0) (3,3)}, label=center:{$\ldots$}] {};
				\end{scope}
				\begin{scope}[yshift=1.5cm,y=1cm]
					\node [fit={(3,3) (4,0)}, label=center:{$Hf$}] {};
				\end{scope}
				
			\end{tikzpicture} 
		\end{array}$
		\caption{Zerlegung von $G$ in Links- bzw. Rechtsnebenklassen}
		\label{fig:nebenklassen}
	\end{figure}
	
	Wir sehen, dass $|H|=|gH| = |Hf|$ gilt.
	
	\subsection{Repräsentantensysteme}		
	\subsubsection{Definition}
	Ein Repräsentantensystem soll für eine Klasseneinteilung aus jeder Klasse genau ein Element enthalten.
	Auf Linksnebenklassen bezogen, wählt man ein Element aus jeder Klasse $gH \in G/H$ (analog für Rechtsnebenklassen).
	Dieses Element bezeichnen wir mit $r(gH)$ für die Klasse $gH$. 
	Dann ist $R_H := \{r(gH) \mid gH \in G/H\} \subseteq G$ ein Repräsentantensystem.
	Mit der bijektiven  Abbildung
	\begin{align*}
		R_H &\iso G/H \\
		r(gH) &\mapsto gH 
	\end{align*}
	kann man sehen, dass das Repräsentantensystem offensichtlich gleichmächtig wie die Menge der Klassen ist.
	\subsection{Satz von Lagrange}	
	\subsubsection{Definition}
	Für eine Gruppe $G$ mit Untergruppe $H$ gilt:
	\begin{align*}
		|G| = [G:H] \cdot |H|\, ,
	\end{align*}	
	wobei $[G:H]$ als Index von $H$ in $G$ bezeichnet wird und die Anzahl der Nebenklassen von $H$ in $G$ angibt. Für den Index gilt $[G:H] = |G/H| = |H/G|$, da man für ein Linksrepresentantensystem $R = \{r(gH) \mid g \in G \}$, wegen $H=H^{-1}$ und $(rH)^{-1} = H^{-1}r^{-1} = Hr^{-1}$, ein Rechtsrepräsentantensystem
	$R^{-1} = \{r(gH)^{-1} \mid g \in G \}$ definieren kann und somit $|G/H| = |H/G|$ , da gilt.
	
	\subsubsection{Beweis}
	Wir definieren die folgende Abbildung
	\begin{align*}
		\lambda: (G/H) \times H &\iso G \\
		(gH, h) &\mapsto r(gH) \cdot h
	\end{align*}
	und wollen zeigen, dass diese bijektiv ist, woraus der Satz diekt folgt.
	Die Injektivität ist hierbei trivial, da die Nebenklassen disjunkt sind und man mit unterschiedlichen Nebenklassen oder unterschiedlichen Elementen aus $H$ somit nicht dasselbe Element in $G$ über $\lambda$ erreichen kann. Die Surjektivität ist auch trivial, da die Klasseneinteilung eine Partition von $G$ ist.
	\bewiesen	
	
	\subsection{Der Homomorphiesatz}		
	\subsubsection{Grundlagen: Homomorphismus}
	Seien $G,F$ Gruppen. 
	Eine Abbildung $\varphi: G \to F$ hei\ss t Homomorphismus\footnote{ab hier abgekürzt Hom.}, falls $\forall g,h \in G : \varphi(gh) = \varphi(g)\varphi(h)$ gilt. Daraus folgt:\\
	\begin{enumerate}[label=\roman*)]
		\item $\varphi(1_G) = 1_F$ ~\par
		Denn $g=1_G\cdot g \implies \varphi(g)=\varphi(1_G\cdot g)=\varphi(1_G)\varphi(g) \implies \varphi(1_G) = \varphi(g) \varphi(g)^{-1} = 1_F$
		
		\item $\varphi(g^{-1})=\varphi(g)^{-1}$ ~\par
		Denn $\varphi(1_G)=\varphi(gg^{-1}) \implies 1_F =\varphi(gg^{-1})= \varphi(g)\varphi(g^{-1}) \implies \varphi(g)^{-1} = \varphi(g^{-1})$
	\end{enumerate}
	
	\subsubsection{Lemma: Injektive Homomorphismen}
	Ein Hom. $\varphi: G \to F$ ist injektiv $\iff$ $ker(\varphi) = \{g \in G \mid \varphi(g)= 1\} = \{1\}$ 
	
	Die Richtung $"\implies "$ ist trivial, da definiert ist, dass das Einselement auf das Einselement abgebildet wird und bei einer injektiven Abbildung kein weiteres Element aus $G$ auf dasselbe Element in $F$ abgebildet werden kann.
	Im Folgenden beweisen wir die zweite Richtung unter Benutzung der Äquivalenz $\varphi(g) = \varphi(h) \iff \varphi(gh^{-1}) = \{1\} $:
	\begin{align*}
		ker(\varphi) &= \{1\} \\
		&\implies [\varphi(gh^{-1}) = \{1\} \implies gh^{-1} = 1 \implies g = h] \\ 
		&\implies \varphi \text{ ist injektiv}
	\end{align*}
	
	\subsubsection{Definition Homomorphiesatz}
	Sei $\varphi: G \to F$ ein Hom.  und $N = ker(\varphi)$. \\
	Dann induziert $\varphi$ einen injektiven Hom. $\overline{\varphi} : G/N \to F$ durch $\overline{\varphi}(gN) = \varphi(g)$.
	\newline
	
	Genauer induziert $\varphi$ also einen Isomorphismus $\overline{\varphi}: G/N \iso im(G) = \{\varphi(g) \mid g \in G\} \leq F$.
	
	\subsubsection{Beweis Homomorphiesatz}
	\begin{enumerate}[label=\arabic*)]
		\item $\overline{\varphi}$ ist wohldefiniert ~\par
		Sei $f\in gN \implies \varphi(f) \in \varphi(g)N = \{\varphi(g)\}$
		
		\item $\overline{\varphi}$ ist injektiv ~\par
		$ker(\overline{\varphi}) = ker(\varphi) = N = 1_{G/N}$
	\end{enumerate}
	
	\subsubsection{Beispiel für den Homomorphiesatz}
	Wir definieren 
	\begin{align*}
		exp: &\,\mathbb{R} \to \mathbb{C}^\ast\\
		&\, x \mapsto e^{2\pi i x}
	\end{align*}
	Dann ist $ker(exp) = \mathbb Z $.\\ 
	Also ist $\mathbb R / \mathbb Z \cong \{z \in \mathbb C \mid |z| = 1\}$.
	
	
	
	\subsection{Normalteiler}		
	\subsubsection{Definition}
	$H \leq G$ hei\ss t Normalteiler, falls $\forall g \in G : gH = Hg$ gilt.
	Man schreibt dann $H\trianglelefteq G$. 
	
	\subsubsection{Satz zu Normalteilern}
	Sei $H \subseteq G$. Dann sind die folgenden Aussagen äquivalent: 
	\begin{enumerate}[label=\arabic*)]
		\item $H\trianglelefteq G$
		\item $H \leq G$ und $gH \cdot fH = gfH$ definiert eine Gruppenstruktur auf $G/H$
		\item Es existiert ein Hom. $\varphi: G \to F$ mit $ker(\varphi) = \{g \in G \mid \varphi(g)= 1\} = H$
		\item $\forall g \in G : gHg^{-1} \subseteq H$ und $H \leq G$
	\end{enumerate}
	
	Im Folgenden wird die Äquivalenz der Aussagen gezeigt: 
	\begin{itemize}
		\item $1)\implies 2)$ ~\par
		$H\trianglelefteq G \implies gHfH = g(Hf)H = g(fH)H = gfHH = gfH$ mit
		\begin{align*}
			&\text{ Neutralem Element: } &&1_{G/H} = H \\
			&\text{ Inversen: } &&(gH)^{-1} = H^{-1}g^{-1}= Hg^{-1}=g^{-1}H \\
			&\text{ Assoziativität: } &&(fH)(gH)(hH)= fghH\\
		\end{align*}
		
		\item $2)\implies 3)$ ~\par
		Wir wählen $F=G/H$.
		Dann ist $\varphi : G \to G/H $, $\varphi(g) = gH$ ein Hom. mit
		\begin{align*}
			ker(\varphi) = \{g \in G \mid gH = H\} = H = 1_{G/H}
		\end{align*}
		
		\item $3)\implies 4)$~\par
		Sei $H = ker(\varphi)$, dann
		\begin{align*}
			\varphi(gHg^{-1}) = \varphi(gg^{-1}) = \varphi(1) \subseteq H 
		\end{align*}
		
		\item $4)\implies 1)$~\par
		$\forall g \in G : gHg^{-1} \subseteq H$
		\begin{align*}
			&\implies  \forall g \in G : H \subseteq g^{-1}Hg &| \text{ durch } g\cdot \text{ und } \cdot g^{-1}\\
			&\implies \forall g \in G : H \subseteq gHg^{-1} &| \text{ da jedes Elemet ein Inverses ist}\\
			&\implies gHg^{-1} = H \\
			&\implies gH = Hg
		\end{align*}
	\end{itemize}
	
	
	
	\subsection{G-Mengen}		
	\subsubsection{Definition}
	Sei $G = (G, *, 1)$ eine Gruppe und $X$ eine Menge.
	Dann operiert $G$ auf $X$ falls folgende Abbildung existiert 
	\begin{align*}
		\cdot : &G \times X \to X \\ 
		&(g,x) \mapsto gx \quad \text{(man schreibt auch g(x) statt (g,x))}
	\end{align*}
	sodass $\forall g,h \in G: g(h(x)) = (g*h)(x)$ und $(1,X) = id_X$ gilt.
	
	Die Menge $X$ zusammen mit der Operation von $G$ auf $X$ wird dann als G-Menge bezeichnet.
	
	\subsubsection{Homomorphismen auf G-Mengen}
	Ein Hom. von $G$-Mengen $X$ mit der Operation $\cdot$ und $Y$ mit der Operation $\star$ ist eine Abbildung 
	\begin{align*}
		f: X \to Y \text{ mit } f(g \cdot x) = g \star f(x)\, ,
	\end{align*}
	wobei $g \in G$ gilt.
	
	\subsubsection{Fixpunkte in G-Mengen}
	Sei $X$ eine  $G$-Menge. Dann hei\ss t t $x$ ein Fixpunkt von $g \in G$ falls $gx=x$. \\
	Weiter ist für alle $x \in X$ die Menge $Fix(x)$  der Fixpunkte eine Untergruppe von $G$:
	\begin{align*}
		Fix(x) = \{g \in G \mid  gx = x\} \leq G 
	\end{align*}
	
	
	\subsection{Das Bahnenlemma}		
	\subsubsection{Definition Bahn}
	Wir definieren die Bahn eines Elements $x \in X$ wie folgt: $$Bahn(x) = Orbit(x) = G\cdot x = \{gx \mid  g \in G \}$$
	
	
	Ebenfalls gilt, dass die Bahn eine G-Menge und isomorph zu $G/Fix(x)$ ist. 
	Dies kann man mit der folgenden Bijektion begründen:
	\begin{align*}
		G/Fix(x) \to Gx \\ 
		gFix(x) \mapsto gx
	\end{align*}
	Die Bijektion ist wohldefiniert, da für jedes Element $h \in gFix(x)$ gilt, dass $h=gf$ mit einem $f \in Fix(x)$. \\ 
	Also folgt $hx = gf(x) = g(x)$.\\
	Mit dem Wissen, dass $|Gx|=|G/Fix(x)|$ ein Teiler von $|G|$ ist, kann man insbesondere für den Spezialfall, dass $|G| = p$ für eine Primzahl $p$ gilt, folgern, dass $\forall x \in X : |Gx|=1$ $\vee\, $$|Gx|=p$ gelten muss.
	
	
	\subsubsection{Bahnenlemma}
	Das Bahnenlemma besagt $$Gx \cap Gy \not = \emptyset \iff Gx = Gy\, .$$
	Im Allgemeinen folgt also $$ X = \dot{\bigcup} \{Gx \mid  x \in X \}\, ,$$ wobei hier die disjunkte Vereinigung benutzt wird, welche durch den Punkt über dem Vereinigungszeichen gekennzeichnet wird. 
	\subsubsection{Beweis des Bahnenlemmas}
	Die Rückrichtung ist hier ebenfalls trivial (wie bei dem sehr ähnlichen Resultat über Nebenklassen). Wir zeigen deshalb nur die erste Richtung $"\implies"$. \\ 
	
	Sei $gx = hy$ für $g,h \in G$
	\begin{align*}
		&\implies h^{-1}gx = y \\
		&\implies y \in Gx \\
		&\implies Gy \subseteq Gx
	\end{align*}
	Analog dazu kann man $Gx \subseteq Gy$ zeigen, was insgesamt zu $Gx = Gy$ führt.
	
	\subsubsection{Graphische Interpretation einer Bahn}
	
	Sei $X$ eine $G$-Menge. Dann kann man sich die Zerlegung von $X$ durch die Operation von $G$ wie in Abbildung~\ref{fig:bahnen} dargestellt, vorstellen.
	
	\begin{figure}[H]
		\centering
		$X=\begin{array}{c}
			
			\begin{tikzpicture}[every fit/.style={inner sep=0pt, outer sep=0pt, draw}]
				\begin{scope}[y=1.5cm]
					\node [fit={(4,0) (7,1)}, label=center:{$Gx_1$}] {};
				\end{scope}		
				\begin{scope}[yshift=1.5cm,y=1cm]
					\node [fit={(0,-1.5) (4,1)}, label=center:{$Gx_2$}] {};
					\node [fit={(4,0) (7,1)}, label=center:{$Gx_3$}] {};
				\end{scope}
				\begin{scope}[yshift=2.5cm,y=1.2cm]
					\node [fit={(0,0) (5,1)}, label=center:{$Gx_4$}] {};
					\node [fit={(5,0) (7,1)}, label=center:{$Gx_5$}] {};
				\end{scope}
			\end{tikzpicture}
		\end{array}$
		\caption{Disjunkte Zerlegung von $X$ in Bahnen}
		\label{fig:bahnen}
	\end{figure}
	
	
	
	\subsection{Satz von Cauchy}		
	\subsubsection{Definition}
	Sei $G$ eine endliche Gruppe und $p \in \mathbb P$ mit $p \mid |G|$. \\
	Dann existiert $g \in G$ mit $g \not = 1$ und $ g^p = 1$. Also $ord(g)= p$. (Und $G$ enthält eine Untergruppe, die isomorph ist zu $\Z/p\Z$.)
	\subsubsection{Beweis}
	Wir betrachten die Menge der Tupel $(g_1,\ldots , g_p) \in G^p$ mit $g_1 \cdot \ldots \cdot g_p = 1$ und nennen diese Menge $T$. Also $T = \{(g_1, \ldots, g_p) \mid  g_1 \cdot \ldots \cdot g_p = 1 \}$. 
	Nun gilt
	\begin{align*}
		|T| &= |\{(g_1, \ldots, g_p) \mid  g_1 \cdot \ldots \cdot g_p = 1 \}| \\
		&= |\{(g_1, \ldots, g_{p-1}) \in G^{p-1} \}| \\
		&= |G|^{p-1}
	\end{align*}
	Nun soll $\mathbb Z /p\mathbb Z$ auf $T$ operieren durch
	\begin{align*}
		m \cdot (g_1,\ldots ,g_p) = (g_{1+m},\ldots ,g_{p+m})\, ,
	\end{align*}
	wobei die Indizes aus $\Z/p\Z$ sind. 
	Das entspricht einem zyklischen Shift um $m$ und lässt sich folgenderma\ss en veranschaulichen:.
	\begin{align*}
		t = (\underbrace{g_1, \ldots, g_m}_{\substack{u}}, \underbrace{g_{m+1}, \ldots, g_p}_{\substack{v}}) \text{ und } m\cdot t = (\underbrace{g_{m+1}, \ldots, g_p}_{\substack{v}}, \underbrace{g_1, \ldots, g_m}_{\substack{u}})
	\end{align*}
	Es gilt also $uv = 1 \iff v(uv)v^{-1} = 1 \iff vu = 1$.\\
	Weiter gilt $|G|^{p-1} = n^{p-1}$ und $p \mid n^{p-1} $, da $p \mid n$
	und Bahnen haben entweder die Länge $1$ oder $p$, da $\mathbb Z /p\mathbb Z$ nur zwei Untergruppen hat. 
	Damit folgt, dass die Menge $\{(g, \ldots, g) \mid g^p= 1 \}$ mindestens ein von $(1,\ldots, 1)$ verschiedenes Element enthalten muss und damit
	
	\begin{align*}
		\implies \exists g \text{ mit } g^p = 1
	\end{align*}
	\bewiesen
	
	\section{Gruppentheorie 2 - Vorlesung 3}
	\subsection{p-Gruppen}
	\subsubsection{Definition}
	Eine Gruppe $G$ hei\ss t $p$-Gruppe, falls $p$ eine Primzahl ist und $|G| \in p^{\mathbb N}$.
	
	\subsubsection{Zentrum einer Gruppe}
	Wir definieren das Zentrum einer Gruppe wie folgt: $$Zentrum(G)= Z(G) = C(G) = \{g \in G \mid  \forall x \in G: xg = gx\}$$
	
	Das Zentrum enthält also genau die Elemente, die mit allen anderen kommutieren.
	Falls $Z(G)=\{1\}$ gilt, nennt man dies das triviale Zentrum.
	Offensichtlich ist $Z(G)$ immer ein Normalteiler von $G$.
	
	\subsubsection{Satz: p-Gruppen haben kein triviales Zentrum}
	\begin{align*}
		G \text{ ist eine $p$-Gruppe} \implies Z(G) \not = \{1\}
	\end{align*}
	
	\subsubsection{Beweis des Satzes}
	Sei $G$ eine p-Gruppe. Da $xg=gx \iff x=gxg^{-1}$ gilt, sind die Elemente des Zentrums genau die Fixpunkte der Operation $x \mapsto gxg^{-1}$ von $G$ auf sich selbst. Diese Operation zerlegt $G$ in disjunkte Bahnen. Jede Bahn hat dabei die Grö\ss e $|G/Fix(x)|$. 
	Also $Fix(x) \not= G \implies p \mid |G/Fix(x)|$. Dann gilt: 
	\begin{align*}
		|G| &\equiv \sum_{x \in Z(G)} |G/Fix(x)|  \mod p\\
		&\equiv \sum_{x \in Z(G)} 1  \mod p\\
		&\equiv |Z(G) |\mod p
	\end{align*}
	Wir wissen, dass das Zentrum auf jeden Fall die $1$ enthält und, da das Zentrum kongruent modulo $p$ zu einer Gruppe mit $|G| \in p^{\N}$ sein muss, muss es also mindestens $p$ Elemente enthalten. Daraus folgt also $p \mid |Z(G)|$, was $Z(G) \neq \{1\}$ zur Folge hat. 
	\bewiesen
	
	
	Wir können daraus weiter schlie\ss en, dass auch $G/Z(G)$ eine $p$-Gruppe ist mit $Z(G/Z(G)) \not = \{1\}$ oder $G=Z(G)$.
	
	
	\subsection{Zyklische Gruppen}
	\subsubsection{Nilpotenz}
	Eine Gruppe $G$ hei\ss t nilpotent, falls es eine Kette von Gruppen $G_0,\ldots,G_m$ gibt, sodass
	\begin{align*}
		\langle 1 \rangle &= G_0, G_1, \ldots, G_m = G  \text{ und } G_k/Z(G) = G_{k-1} \text{ für } 1 \leq k \leq m \text{ gilt.}
	\end{align*}
	
	\subsubsection{Beispiele: Nilpotenz}
	\begin{itemize}
		\item Kommutative Gruppen sind immer nilpotent, da dann $Z(G)=G$ gilt und eine Kette mit $G_1=G$ die Voraussetzung für Nilpotenz erfüllt.
		\item $D_3$ mit $|D_3| = 6$ ist die kleinste, nicht triviale, nicht nilpotente Gruppe, da $Z(D_3) = \{1\}$ und somit $G/Z(G)=G$ gilt und es keine Kette von Gruppen geben kann, die bei $\{1\}$ endet.
		\item $D_4$ mit $|D_4| = 8$ ist nilpotent, da $D_4/Z(D_4) = \mathbb Z/2 \mathbb Z \times \mathbb Z /2\mathbb Z$.
	\end{itemize}
	
	\subsubsection{Zyklische Gruppen}
	Eine Gruppe $G$ hei\ss t zyklisch, falls $\exists g \in G$ mit $G=g^{\mathbb Z}$.
	
	\subsubsection{Satz: Endliche zyklische Gruppen}
	$|G| < \infty$ und $G$ zyklisch $\implies \exists g \in G$ mit $G =\{g^0, g^1, \ldots, g^{|G| -1} \}$  
	
	\subsubsection{Beweis des Satzes }
	Sei $|G|<\infty$ und $G$ zyklisch. Betrachte $g, g^2, g^3, \ldots$ für $g^{\mathbb Z}=G$. Da die Gruppe endlich ist, existieren $i,j$ mit $0 \leq i < j $, sodass $g^i = g^j$. Daraus ergibt sich dass $1 = g^j-g^i=g^{j-i}$ gilt. \\
	Betrachte nun ein minimales $n \in \mathbb N_+$ mit $g^n = g^0 = 1$ , welches demnach existieren muss (\OE  $\, \,G \not = \{1\}$).
	Da $n$ minimal ist, sind  $g^0, \ldots g^{n-1}$ paarweise verschieden. Ferner gilt $(g^i = g^j \iff i \equiv j \mod n) \implies G \cong (\mathbb Z /n\mathbb Z, +, 0)$ für ein $n \in \N$.
	\bewiesen
	
	\subsubsection{Satz: Zyklische Untergruppen}
	$H \leq G \wedge G$ ist zyklisch $\implies H$ ist zyklisch
	
	\subsubsection{Beweis des Satzes}
	\OE  $\, \, \{1\} \not = H \not = G$ und  $G \cong \mathbb Z /n\mathbb Z$ für $n=0,2,3,\ldots$\\ 
	\newline
	Es existiert ein minimales $d > 0$ mit $g^d \in H$ für $G = g^{\mathbb Z}$.
	Wir setzten nun $G=\Z/n\Z$. Dann gilt $d\mathbb Z \leq H$ in $\mathbb Z /n\mathbb Z$. 
	$d\Z$ ist offensichtlich zyklisch und wir zeigen nun $d\mathbb Z = H$, was dann beweist, dass auch $H$ zyklisch ist. 
	
	Sei ein $a \in H$, dann gilt $a\in r + d\mathbb Z$ mit $0 \leq r < d$ 
	\begin{align*}
		&\implies r \in H &| \text{ wegen Abgeschlossenheit}\\
		&\implies r = 0 &| \text{ da } d \text{ die kleinste Zahl in } H  \text{ ist}\\
		&\implies a \in d\mathbb Z \\ 
		&\implies H \text{ ist zyklisch}
	\end{align*}
	\bewiesen
	Falls $n=0$ ist, dann gilt $d\mathbb Z \cong \mathbb Z$. Falls $|\Z /n\Z| < \infty$ ist, also $n \geq 2$, 
	dann ist $d\cdot \frac{n}{d} \equiv 0 \mod n$ und $d$ hat die Ordnung $\frac{n}{d}$. Also $|G/H|= d$.
	
	\subsection{Permutationsgruppen}
	\subsubsection{Definition}
	
	Sei $X$ eine Menge, dann ist die Permutationsgruppe $Perm(X)$ zu $X$ wie folgt definiert:
	$$Perm(X)= \{ f: X \iso X \mid f \text{ ist eine bijektive Abbildung}\}$$
	Die Gruppenoperation ist dabei die Hintereinanderausführung.
	
	\subsubsection{Symmetrische Gruppe}
	Wir schreiben ab jetzt $[n]$ für $\{1, \ldots, n\}$ mit $n \in \mathbb N$.  \\ 
	\newline
	Eine symmetrische Gruppe $S_n$ enthält alle Permutationen der Zahlen von $1$ bis $n$. Es gilt also: $$S_n = Perm([n])$$ 
	Elemente $\pi \in S_n$ lassen sich darstellen als $\pi = (\pi(1), \ldots, \pi(n))$.
	Es gilt $|S_n|=n!$.
	
	\subsubsection{q-Zykel}
	Ein Element $\pi \in S_n$ hei\ss t $q$-Zykel, falls $$ \exists I \in \binom{[n]}{q}: I=\{i_1,\ldots, i_q\} \text{ mit } (\pi(i_j) = i_{(j+1)}\,\, \forall j \in \mathbb Z / q \mathbb Z) \wedge (\pi(m)= m \,\, \forall m \in [n]  \setminus  I)$$. \\ 
	Die Menge $I$ hei\ss t dann Träger von $\pi$.
	Durch $\pi$ werden also Elemente im Träger zyklisch permutiert, während alle übrigen Element unverändert bleiben.
	Wir können für einen $q$-Zykel die Folge $(i_1, \ldots, i_q) = (i_{p+1}, \ldots, i_q, i_1, \ldots, i_p)$ schreiben.\\
	
	Weiter definieren wir $$\left[\begin{array}{c}n\\k\end{array}\right] = |\{ \pi \in S_n \mid \pi \text{ ist Produkt von $k$ Zykeln  mit paarweise disjunkten Trägern} \}|$$
	als die Anzahl der disjunkten Möglichkeiten $[n]$ in $k$ Zykel zu zerlegen.
	
	
	\subsubsection{Transposition}
	Ein $2$-Zykel hei\ss t Transposition.
	Die Menge $\mathcal T_n$ der Transpositionen von $[n]$ ist damit definiert durch  $$\mathcal T_n = \{ \tau \in S_n  \mid \tau = (i, j), \, 1 \leq i \leq j \leq n \}\,.$$
	
	\subsubsection{Graphische Interpretation von Zykeln}
	Abbildung~\ref{fig:zykel} veranschaulicht ein mögliches Element $\pi \in S_n$ als Produkt von Zykeln.
	
	\begin{figure}[H]
		\centering
		$ \pi = c_1\cdot \ldots\cdot c_k = \begin{array}{ccc}
			\begin{tikzpicture}[->,scale=.7] 
				\foreach \a/\t in {90/.,-30/.,210/.}{
					\node (\t) at (\a:1cm) {$\bullet$};
					\draw (\a-20:1cm)  arc (\a-20:\a-100:1cm);
				} 
			\end{tikzpicture}
		\end{array} \ldots
		\begin{array}{ccc}
			\begin{tikzpicture}[->,scale=.7] 
				\foreach \a/\t in {90/.,-90/.}{
					\node (\t) at (\a:1cm) {$\bullet$};
					\draw (\a-20:1cm)  arc (\a-20:\a-160:1cm);
				} 
			\end{tikzpicture}
		\end{array}
		\ldots
		\begin{array}{ccc}
			\begin{tikzpicture}[->,scale=.7] 
				\foreach \a/\t in {90/.}{
					\node (\t) at (\a:1cm) {$\bullet$};
					\draw (\a-20:1cm)  arc (\a-20:\a-340:1cm);
				} 
			\end{tikzpicture}
		\end{array}$
		\caption{Zerlegung von $\pi$ in $c_1$ bis $c_k$.}
		\label{fig:zykel}
	\end{figure}
	
	\subsubsection{Bubblesort-Lemma}
	Das Bubblesort-Lemma besagt $\mathcal T_n$ erzeugt $S_n = Perm(\{1, \ldots, n\})$. Oder genauer formuliert, gilt: $S_n$ wird erzeugt von $\tau \in \mathcal T_n$ mit $\tau= (i, i+1)$ für $1 \leq i < n$.
	\newline
	
	Den Beweis liefert der Bubblesort Algorithmus, da die Transpositionen als Bubblesort-Schritte gesehen werden können. 
	\newline
	Sei $\pi$ eine beliebige Permutation in $S_n$. Verwendet man nun den Bubblesort Algorithmus zum Sortieren, werden immer zwei Elemente $(i, i+1)$ mit $1 \leq i <n $ vertauscht, was einer Transposition entspricht. Am Ende des Sortierens erhält man die Identität. Wenn man nun die gemachten Schritte rückwärts ausführt, also bei der Identität startet, so kommt man zu allen Permutationen, also zum gewünschten Ergebnis.
	
	\subsubsection{Signum}
	Sei $\pi \in S_n$. Dann ist das zugehörige Signum $sign(\pi)$ wie folgt definiert $$sign(\pi) = \prod_{1 \leq i < j \leq n} \frac{\pi(j) - \pi(i)}{j -i}\, .$$
	
	Sei weiter $F(\pi) = \{(i,j)\, |\, (\pi(j) - \pi(i))(j-i) \leq -1\}$ die Menge der Fehlstellungen von $\pi$. 
	Es hängt also von $F(\pi)$ ab, ob $sign(\pi)$ positiv oder negativ ist, da jede Fehlstellung einen negativen Faktor zu $sign(\pi)$ beiträgt.
	
	\subsubsection{Lemma: Signumsbetrag}
	Es gilt $|sign(\pi) |= 1$.
	
	\subsubsection{Beweis des Lemmas}
	Die Aussage ist wahr, da 
	\begin{align*}
		sign(\pi) &= \ddfrac{\prod_{1 \leq i < j \leq n}  |\pi(j) - \pi(i)|}{\prod_{1 \leq i < j \leq n}  |j -i|} = \ddfrac{ \prod_{ \{i,j\} \in \binom{[n]}{2}} |\pi(j) - \pi(i)| }{ \prod_{ \{i,j\} \in \binom{[n]}{2}} |j - i|} = \ddfrac{ \prod_{ \{i,j\} \in \binom{[n]}{2}} |j - i| }{ \prod_{ \{i,j\} \in \binom{[n]}{2}} |j - i|} = 1
	\end{align*}
	\bewiesen
	
	Dann folgt nun $sign(\pi)= 1^{|F(\pi)|}$. 
	Somit ist $sign(id) = +1$ und $sign(\tau) = \frac{j-i}{i-j} = -1$ für $\tau= (i,j) \in \mathcal T_n$.
	
	
	\subsubsection{Lemma: $sign$ ist ein Hom.}
	$$ \text{Die Abbildung }sign: S_n \to \{ \pm 1\} \text{ ist ein Homomorphismus.}$$
	
	\subsubsection{Beweis des Lemmas}
	Seien $\pi, \sigma \in S_n$. Es gilt 
	\begin{align*}
		sign(\pi\sigma) &= \prod_{1 \leq i < j \leq n} \ddfrac{\pi\sigma(j) - \pi \sigma(i)}{j -i} = \prod_{1 \leq i < j \leq n} \ddfrac{\pi\sigma(j) - \pi \sigma(i)}{\sigma(j) -\sigma(i)} \cdot \prod_{1 \leq i < j \leq n}\ddfrac{\sigma(j) - \sigma(i)}{j -i}\\
		&= \prod_{1 \leq i < j \leq n} \ddfrac{\pi(j) - \pi (i)}{j -i} \cdot \prod_{1 \leq i < j \leq n}\ddfrac{\sigma(j) - \sigma(i)}{j -i} = sign(\pi) sign(\sigma)\, .
	\end{align*}
	\bewiesen
	Weiter bezeichnen wir $ker(sign) = A_n$ als die alternierende Gruppe über $n$.
	Es gilt $A_n \trianglelefteq S_n$ und $|A_n| = \binom{n!}{2}$ für $n \geq 2$. 
	
	\section{Gruppentheorie 3 - Vorlesung 4}
	\subsection{Semidirekte Produkte}
	\subsubsection{Direktes Produkt}
	Für zwei Gruppen $H$ und $F$ ist das Gruppe $H \times F$ mit  der komponentenweisen Verknüfung $$(h,f)(h', f') = (hh', ff')$$ definiert als das direkte Produkt.
	
	\subsubsection{Semidirektes Produkt}
	Das semidirekte Produkt ist ein Spezialfall des direkten Produkts.
	$G = H \rtimes F$ ist ein semidirektes Produkt, falls $H \trianglelefteq G$, $F \leq G$,  $G = H\cdot F$ und $H \cap F = \{1\}$ gilt. 
	Die Gruppenoperation ist dabei 
	$$(h,f)(h',f') = hfh'(f^{-1}f)f' = h(fh'f^{-1})ff'  = (h\varphi(f)(h'), ff')$$
	mit $\varphi(f) \in Aut(H)$.
	$Aut(H)$ ist die Menge der Automorphismen in $H$.
	\newline
	$S_3 = \Z/3\Z \rtimes \Z/2\Z$ ist ein Beispiel für ein semidirektes Produkt.
	\subsubsection{Konstruktionsmöglichkeit 1 für semidirekte Produkte}
	Seien $H, F$ Gruppen und $\varphi: F\to Aut(H)$ ein Hom. \\ 
	Wir nehmen $G = H \times F$ als Menge und $$ (h,f)(h',f') = (h\varphi(f)h', ff')$$ als Verknüpfung.\\
	Dann ist $H= H \times \{1\}$ und damit $H \trianglelefteq H \times F$. 
	Weiter ist dann $F = \{1\} \times F \leq G$ und $G= H\cdot F$, sowie $H\cap F = \{1\}$.
	Gesamt sind also alle Bedingungen für ein semidirektes Produkt erfüllt.
	
	\subsubsection{Korrektheit der Konstruktionsmöglichkeit 1}
	Um die Korrektheit zu beweisen, muss gezeigt werden, dass $G$ eine Gruppe ist.
	Zuerst zeigen wir die Gültigkeit des Assoziativgesetzes für $G$.
	Es ist $(h_1, f_1)(h_2, f_2)(h_3, f_3) = (h, f_1f_2f_3)$ mit 
	\begin{align*}
		h&=h_1\varphi(f_1)[h_2\varphi(f_2)(h_3)] \\
		&=h_1\varphi(f_1)(h_2)\varphi(f_1f_2)(h_3)\\
		&=[h_1\varphi(f_1)(h_2)]\varphi(f_1f_2)(h_3)\, .
	\end{align*} 
	\\ 
	Das neutrale Element ist $(1,1)$.\\
	Nun bleibt die Existenz von Inversen zu zeigen.
	Sei $(h,f)\in G$. $(h, f)^{-1} = (h', f^{-1})$ mit $h' = \varphi(f^{-1})(h^{-1})$, weil $h\varphi(f)(h')= 1$ gelten muss.
		
	\subsubsection{Exakte Sequenzen}
	Eine Sequenz von Homs. $\varphi_i: G_{i-1} \to G_i$ mit $i \in I$ wobei $I$ eine linear geordnete Menge ist, hei\ss t exakte Sequenz, falls $$\forall i \in I : im(\varphi_i) = ker(\varphi_{i+1})$$ gilt.\\
	Abbildung~\ref{fig:sequenz} veranschaulicht die Idee von Hom. Sequenzen.
	\begin{figure}[h!]
		\centering
		\begin{equation*}
			\begin{tikzcd}[column sep=3.5pc]
				\ldots \arrow{r}{\varphi_{i-1}} & G_{i -1} \arrow{r}{\varphi_{i}} & G_{i} \arrow{r}{\varphi_{i+1}} & G_{i+1} \ldots 
			\end{tikzcd}
		\end{equation*}
		\caption{Graphische Darstellung einer Sequenz.}
		\label{fig:sequenz}
	\end{figure}

	\subsubsection{Kurze Exakte Sequenzen}
	Eine kurze exakte Sequenz ist eine exakte Sequenz der Form 
		\begin{equation*}
			\begin{tikzcd}[column sep=2.5pc]
				\{1\} \arrow{r}{} & H \arrow{r}{\varphi} & G \arrow{r}{\psi} & F \arrow{r}{} & \{1\}\, ,
			\end{tikzcd}
		\end{equation*}
	wobei $\varphi: H \mapsto G$ injektiv ist, $\psi: G \mapsto F$ surjektiv ist, und die induzierte Abbildung $\overline{\psi} : G/H \iso F$ ein Isomorphismus ist.
	
	\subsubsection{Konstruktionsmöglichkeit 2 für semidirekte Produkte}
	Eine zweite Möglichkeit zur Konstruktion von semidirekten Produkten entsteht durch den folgenden Zusammenhang mit exakten Sequenzen.\\
	$G$ ist ein semidirektes Produkt $G = H\rtimes F$ mit der exakten Sequenz 
	\begin{equation*}
		\begin{tikzcd}[column sep=2.5pc]
			\{1\} \arrow{r}{} & H \arrow{r}{\varphi} & G \arrow{r}{\psi} & F \arrow{r}{} & \{1\}\, ,
		\end{tikzcd}
	\end{equation*}
	falls ein Hom. $s: F \to G$ existiert  mit $\psi s = id_F$.
	
	\section{Gruppentheorie 4 - Vorlesung 5}
	\subsection{Einfache Gruppen}
	\subsubsection{Definition}
	Eine Gruppe $G$ hei\ss t einfach, wenn sie außer $\{1\}$ und $G$ selbst keine weiteren Normalteiler besitzt.
	
	\subsubsection{Beispiele}
	\begin{itemize}
		\item $\mathbb Z / p \mathbb Z$ mit $p \in \mathbb{P}$ ist einfach. 
		\item $\mathbb Z / n \mathbb Z$ mit $n \in \N \wedge n \notin \mathbb{P}$ ist nicht einfach. 
	\end{itemize}
	
	\subsection{Kommutate Untergruppen}
	\subsubsection{Definition}
	Für eine Gruppe $G$, ist $[G, G] = \langle [g, h] \mid g, h \in G \rangle$ mit $[g, h] = g^{-1}h^{-1}gh$ die kommutate Untergruppe. \\
	\newline
	Wenn $G$ einfach und nicht abelsch ist, dann gilt $[G, G] =1$. 
	
	\subsubsection{Satz: Kommutate Untergruppen abelscher Gruppen}
	Für eine Gruppe $G$ gilt: $$ G \text{ abelsch } \iff [G, G] = 1$$
	
	\subsubsection{Beweis des Satzes}
	Es gilt $g^{-1}h^{-1}gh = 1 \iff gh = hg \iff G$ ist abelsch. 
	\bewiesen
	
	\subsubsection{Definition: auflösbar}
	Jede abelsche Gruppe ist auflösbar. Jede nicht abelsche Gruppe ist auflösbar, falls die ''abgeleitete'' Untergruppe $[G, G]$ von $G$ verschieden und auflösbar ist. 
	Für eine auflösbare Gruppe, kann man also eine Folge der Form
	\begin{equation*}
		1 \leq \ldots \leq G^{(2)} = [G^{(1)}, G^{(1)} ] \leq G^{(1)} = [G, G ] \leq G  
	\end{equation*}
	finden.
	
	\subsection{Alternierende Gruppen}
	
	\subsubsection{Definition}
	Die Alternierende Gruppe $A_n$ für $n \in \N$ enthält genau diejenigen Elemente $\pi \in S_n$, für die $sign(\pi)$ positiv ist, also $$A_n=\{\pi\, | \, \pi \in S_n \wedge sign(\pi) = 1\}\, .$$
	\subsubsection{Lemma: Erzeugung von $A_n$}
	Für $n \geq 5$ wird $A_n$ sowohl von der Menge der Doppel-Transpositionen als auch von der Menge der $3$-Zykel erzeugt.\\
	Hierbei gilt, dass eine Doppel-Transposition das Produkt $(i,j)(k,l)$ zweier Transpositionen mit disjunkten Elementen $i,j,k,l$ ist.
	
	\subsubsection{Beweis des Lemmas}
	Wir wissen dass $\pi \in A_n \iff sign(\pi) = 1$ gilt und somit auch, dass $A_n$ von einem Produkt $\tau \tau'$ mit $\tau, \tau' \in \mathcal T_n$ erzeugt wird, 
	da $S_n$ von $\mathcal T_n$ erzeugt wird. 
	\newline 
	
	Die Menge der $3$-Zykel erzeugt $A_n$, da man alle $3$-Zykel als Doppel-Trasnposition darstellen kann.
	Es gilt 
	\begin{align*}
		(1,2)(3,4) = (1,2,3)(3,4,2) \text{ und } (1,2)(2,3) = (1,2,3)\, .
	\end{align*}
	Mit $n\geq 5$ können wir schreiben 
	\begin{align*}
		(1,2, 3) = (1,2)(2,3) =((1,2)(4,5))((4,5)(2,3))
	\end{align*}
	
	Deshalb kann man $(1,2,3)$ als Produkt von zwei Permutationen des Typ $(2,2)$ schreiben.
	\bewiesen
	
	\subsubsection{Lemma: $3$-Zykel sind konjugiert in $A_n$}
	Sei $n \geq 5$ und $\sigma$ ein $3$-Zykel. Dann existiert ein $\pi \in A_n$, sodass $\pi\sigma\pi^{-1} = (1,2,3)$.
	
	\subsubsection{Beweis des Lemmas}
	Man sieht deutlich, dass $\pi \in S_n$ existiert, sodass $\pi\sigma\pi^{-1} = (1,2,3)$. 
	Wenn $\pi \in A_n$ gilt, dann sind wir bereits fertig. 
	\newline
	
	Anderenfalls definieren wir $\pi' = (4,5)\pi \in A_n$.  Wir schlie\ss en daraus 
	\begin{align*}
		\pi'\sigma\pi'^{-1} = (4,5)\pi\sigma\pi^{-1}(4,5) = (4,5)(1,2,3)(4,5) = (1,2,3)\,,
	\end{align*}
	wodurch die Behauptung folgt.
	\bewiesen
	
	\subsubsection{Lemma: Normalteiler von $S_n$}
	Sei $n \geq 3$ und $K \trianglelefteq S_n$, dann ist $K \in \{ \{1\}, A_n, S_n\}$.
	
	\subsubsection{Beweis des Lemmas}
	Wir nehmen an, dass $\{1\} \not = K$ gilt. Sei $N= K \cap A_n$, dann ist $N$ als Schnitt zweier Normalteiler selbst ein Normalteiler in $S_n$. Es reicht an dieser Stelle aus, zu zeigen, dass dies $N=A_n$ impliziert, da $N = A_n \implies K \in \{ A_n, S_n\}$ dann folgt, wegen $[S_n : A_n] = 2$.
	\newline
	
	Um nun zu zeigen, dass $N=A_n$ gilt, wählen wir $\sigma \in N$ und $i$ mit $i \not = \sigma(i)$. Da $\sigma$ keine Transposition ist, gibt es noch ein $j \notin \{i, \sigma(i)\}$ sodass $j \not=\sigma(j)$ gilt. \\
	
	Sei nun $\tau = (i, j)$ und $\rho = (\sigma(i), \sigma(j))$. 
	Wir behaupten dann, dass $\rho\tau = \sigma\tau\sigma^{-1}\tau$ gilt, und $\sigma\tau\sigma^{-1}\tau \in N$ ist. Um diese Behauptung zu zeigen, beweisen wir $\rho\sigma = \sigma\tau$. 
	Es gilt:
	\begin{align*}
		\rho\sigma(j) &= \sigma(i) = \sigma\tau(j) \text{, } \rho\sigma(i) = \sigma(j) = \sigma\tau(i) \text{ und }\\
		\rho\sigma(k) &= \sigma(k) = \sigma\tau(k) \text{ für } k \not \in \{i, j\}\, .
	\end{align*}
	
	Wenn nun $\sigma(j) = i$ gilt, dann ist $\rho\tau \in N$ ein $3$-Zykel und somit in $A_n$, was zu $N=A_n$ führt. 
	Anderenfalls ist $\rho\tau \in N$ vom Typ $(2,2)$. Alle Permutationen des Typ(2,2) sind in $S_n$ konjugiert. Daher haben wir wieder $N=A_n$.
	\bewiesen
	
	\subsubsection{Lemma: Normalteiler von Normalteilern}
	Sei $N \trianglelefteq A_n$ und $\pi \in S_n$, dann ist auch $\pi N\pi^{-1} \trianglelefteq A_n$. Genauer gilt $\tau N \tau \trianglelefteq A_n$ für alle $\tau \in \mathcal T_n$.
	\subsubsection{Beweis des Lemmas}
	Zuerst ein direkter Beweis: \\
	Falls $\pi \in A_n$ gilt, ist die Behauptung direkt offensichtlich. Es reicht also zu zeigen, dass $\sigma\tau N\tau\sigma^{-1} = \tau N \tau$ für $\sigma \in A_n$ und $\tau\in S_n \setminus A_n$ gilt. Dies ist äquivalent zu $ \tau \sigma \tau N \tau \sigma^{-1}\tau \subseteq N$. Auch in diesem Fall folgt die Behauptung direkt, da $\tau\sigma\tau \in A_n$ und $N\trianglelefteq A_n$. 
	\newline
	
	Als zweites eine elegantere Version: \\
	Wir haben $N \trianglelefteq H \trianglelefteq G$ mit $H = A_n$ und $G= S_n$. Für alle $\pi \in G$ erhalten wir einen Automorphismus $\varphi \in Aut(H)$ durch $\varphi(h) = \pi h\pi^{-1}$. Nun ist $\varphi(N) = \pi N\pi^{-1}$ ein Normalteiler von $H$. Für alle $h \in H$ ist $\varphi^{-1}(h) \in H$. 
	Deshalb gilt: 
	\begin{align*}
		h\varphi(N)h^{-1} = \varphi(\varphi^{-1}(h)N\varphi^{-1}(h^{-1})) = \varphi(N)
	\end{align*}
	
	Die allgemeine Aussage ist, dass aus $N \trianglelefteq H$ und $\varphi \in Aut(H)$ folgt, dass $\varphi(N) \trianglelefteq H$ gilt. 
	\bewiesen
	
	\subsubsection{Satz: Einfachheit von alternierenden Gruppen}
	Für $n \geq 5$ ist $A_n$ einfach. (C.Jordan, 1875).
	
	\subsubsection{Strategie zum Beweis des Satzes}
	$\tau \in \mathcal T_n$ soll eine feste Transposition sein. Wir zeigen durch Widerspruch, dass $A_n$ einfach ist. Dazu nehmen wir an, dass ein $N \trianglelefteq A_n$ existiere, mit $\{1\} \triangleleft N \triangleleft A_n$.  \\
	
	Wir wissen, dass $S_n$ nur die Normalteiler $\{1\}, A_n$ und $S_n$ hat, und dadurch können wir schlie\ss en, dass $\tau N\tau \not = N$ ist, da sonst auch $N = \tau N \tau $ ein Normalteiler in $S_n$ wäre. Wir erinnern uns daran, dass $\tau N \tau \trianglelefteq A_n$ gilt. \\
	Durch folgende Schritte können wir dann einen Widerspruch herleiten: 
	
	\begin{enumerate}[label=\arabic*.]
		\item Der Schnitt von $N$ und $\tau N \tau$ ist trivial: $N \cap \tau N \tau = \{1\}$.
		\item Das Produkt $N(\tau N \tau)$ ist ein Normalteiler in $S_n$. Da $N \subseteq N(\tau N \tau) \leq A_n$, impliziert dies $N(\tau N \tau) = A_n$.
		\item Da $N\cap \tau N \tau =  \{1\}$ und $N(  \tau N \tau ) = A_n$ gilt, schlie\ss en wir, dass $n! = 2 |N|^2$ ist, und weiter, dass $4 \mid n$ gilt und $|N|$ somit gerade sein muss. 
		\item Der Widerspruch entsteht dadurch, dass wir entweder mit Hilfe des Bertrandschen Postulates ($\forall m \in \R\, \exists p \in \mathbb{P}: \, m < p \leq 2m$, sofern $m \geq 1$) zeigen, dass $\frac{n!}{2}$ keine Quadratzahl ist, oder den Satz von Cauchy benutzen. 
	\end{enumerate}
	Die Punkte $1$ -$3$ werden durch die folgenden Lemmata (\ref{lemma1}, \ref{lemma2}, und \ref{lemma3}) gezeigt. 
	
	\subsubsection{Lemma: Trivialer Schnitt \label{lemma1}}
	$N \cap \tau N \tau = \{1\}$
	\subsubsection{Beweis des Lemma \ref{lemma1}}
	$N \cap \tau N \tau$ ist ein Normalteiler in $A_n$. Jedes $\pi \in S_n \setminus A_n$ kann auch als $\pi = \tau\sigma$ mit $\sigma \in A_n$ geschrieben werden.
	Es gilt
	\begin{align*}
		\pi N \pi^{-1} &= \tau \sigma N \sigma^{-1} \tau = \tau N \tau  \\ 
		\pi \tau N \tau \pi^{-1} &= N
	\end{align*} 
	da $\pi\tau \in A_n$ ist. 
	Deshalb ist $\pi(\tau N \tau \cap N) \pi^{-1} \subseteq N \cap \tau N \tau$ und $\tau N \tau \cap N$ ist ein Normalteiler von $S_n$. Da $N$ ganz in $A_n$ liegt, folgt daraus, dass $\tau N \tau \cap N = \{1\}$. 
	\bewiesen
	
	\subsubsection{Lemma: $N(\tau N\tau)$ ist Normalteiler \label{lemma2}}
	Das Produkt $N(\tau N \tau)$ ist ein Normalteiler in $S_n$. Da $N \subseteq N(\tau N \tau) \leq A_n$, impliziert dies $N(\tau N \tau) = A_n$.
	\subsubsection{Beweis des Lemma \ref{lemma2}}
	Nach Blatt 1, Aufgabe 3 der Übungen ist $N(\tau N \tau) \trianglelefteq A_n$. Ferner ist für $\pi = \sigma\tau \in S_N \setminus A_n$ mit $\sigma \in A_n$: 
	\begin{align*}
		\pi N(\tau N\tau) \pi^{-1} &= \sigma \tau N (\tau N \tau) \tau \sigma^{-1}  \\ 
		&= \sigma\tau N \tau N  \sigma^{-1} \\
		&= \sigma N \tau N \tau \sigma^{-1} \\
		&= N(\tau N \tau)\, .
	\end{align*}
	\bewiesen
	
	\subsubsection{Lemma: Grö\ss e von $N$ \label{lemma3}}
	Es gilt $n! = 2 |N|^2$. Weiter gilt $4 \mid n$ und somit folgt, dass $|N|$ gerade ist. 
	\subsubsection{Beweis des Lemma \ref{lemma3}}
	Sei $\sigma, \sigma' \in N$ und $\pi', \pi \in \tau N \tau$, sodass $\sigma\pi' = \sigma'\pi$ ist. Dann ist $\sigma^{-1}\sigma' = \pi'\pi^{-1} \in N \cap \tau N \tau = \{1\}$. Dadurch ist $\sigma = \sigma'$ und $\pi' = \pi$. Somit ergibt sich 
	\begin{align*}
		|A_n| = |N\tau N\tau| = |N| \cdot |\tau N \tau| = |N|^2\, .
	\end{align*}
	Also ist $|A_n| =\frac{n!}{2}$ eine Quadratzahl. Die Kardinalität von $N$ ist gerade da $n!$ duch $4$ teilbar ist für $n \geq 4$. 
	\bewiesen
	
	\subsubsection{Beweis des Satzes mit dem Bertrandschem Postulat}
	Das Bertrandsche Postulat besagt, dass für $1 \leq m \in \mathbb R$ eine Primzahl $p$ mit $m < p \leq 2m$ existiert. 
	\newline
	Sei nun $m =\frac{n}{2}$, dann existiert eine Primzahl $p$ mit $\frac{n}{2} < p \leq n$. Da $n \geq 5$ ist, gilt $p > 2$. Somit gilt $p \mid \frac{n!}{2}$, aber $p^2 > 2p >  n$. Damit teilt $p$ aber nicht $n!$. Ein Widerspruch!
	\bewiesen
	
	\subsubsection{Beweis des Satzes mit dem Satz von Cauchy}
	Da $|N|$ eine nicht triviale Gruppe gerader Ordnung ist, besagt der Satz von Cauchy, dass $N$ ein Element $\sigma$ mit $ord(\sigma) = 2$ enthält. 
	Dann kann $\sigma$ als gerade Anzahl an 2-Zyklen geschrieben werden:
	\begin{align*}
		\sigma = c_0 \cdot \ldots \cdot c_k\, ,
	\end{align*} 
	wobei $k\geq 1$ gilt, $k$ gerade ist und $c_0, \ldots, c_k$ Zyklen der Ordnung $2$ mit paarweise disjunkten Trägern sind. Damit gilt $c_ic_j = c_jc_i$ für alle $i,j$. 
	Sei nun $\tau = c_0$. Dann ist $N \cap \tau N \tau = \{1\}$, da dies für alle $\tau \in \mathcal T_n$ gilt. Durch $\sigma\tau = \tau \sigma$ erhalten wir
	\begin{align*}
		\sigma = \tau\sigma\tau \in N\cap \tau N \tau\, .
	\end{align*} 
	Dies impliziert jedoch $\sigma = 1$. Ein Widerspruch! 
	
	\section{Gruppentheorie 5 - Vorlesung 6}
	\subsection{Kranzprodukte}
	\subsubsection{Vorraussetzungen}
	Seien $M = (M, +, 0)$ nicht notwendig kommutativ und $N=(N, \cdot, 1)$ beides Monoide, sowie $X$ eine Menge. 
	Dann operiert $N$ von rechts auf $X$. Wir betrachten die Menge der Abbildungen von $X$ nach $M$: $M^x = \{ f: X \to M \mid \text{ f ist eine Abbildung} \}$. Wir schreiben statt $f(x)$ nun $xf$. 
	Somit operiert $N$ auf $M^X$ von links durch
	\begin{align*}
		nf : X \to M \\ 
		x(n\cdot f) := (xn)f = xnf \, .
	\end{align*}
	\subsubsection{Definition Konstante Funktion}
	Wir definieren für alle $y$ die konstante Funktion $c_y$ durch	$$c_y(x) = xc_y = y \, \, \, \forall x\, .$$ 
	
	\subsubsection{Definition Kranzprodukt}
	Nun hei\ss t $M \wr N$ Kranzprodukt, falls $M^X \rtimes N$ gilt. Dabei ist das Kranzprodukt für Monoide mit der Eigenschaft
	\begin{align*}
		(f,m)(g,n) = (f + mg, mn) \text{ mit } x(f+mg) = xf + xmg \, \, \, \forall x
	\end{align*}
	definiert.
	Wir können also die Klammern ''vergessen''. Somit ist das Kranzprodukt wieder ein Monoid mit dem Neutralelement $1_{M \wr N}= (c_0,1)$.
	\\
	Im Folgenden zeigen wir noch die Assoziativität von $M \wr N$:
	\begin{align*}
		[(f,k)(g,m)](h,n) = (f +kg, km)(h,n) = (f +kg + kmh, kmn) \\
		(f,k)[(g,m)(h,n)] = (f,k)(g +mh, mn) = (f + k ( g +mh),kmn) 
	\end{align*}
	Nun bleibt zu zeigen, dass $\forall x : x(f+kg + kmh) \overset{!}{=} x(f+k(g+mh))$ gilt. \\
	Dies ist der Fall, wegen 
	\begin{align*}
		x(f+k(g+mh)) = xf+(xk)(g + mh) = xf + xkg + xkmh\, .
	\end{align*}
	\bewiesen
	Es kann auch $X=N$ gesetzt werden.
	
	\subsubsection{Satz: Kranzprodukt bei Gruppen}
	Wenn $M, N$ Gruppen sind, dann ist auch $M^X \rtimes N$ bzw. $M \wr N$ eine Gruppe. 
	
	\subsubsection{Beweis}
	Das Neutralelement $(c_0, 1)$ ist offensichtlich enthalten.\\
	Gesucht ist nun für alle $(f, m) \in M \wr N$ ein $(g,n)$ mit $(f, m)(g,n) = (c_0, 1)$.
	Damit ist in durch die zweite Komponente festgelegt, dass $n=m^{-1}$ ist und es bleibt zu zeigen, dass $(f,m)(g, m^{-1}) = (c_0,1)$  gilt. \\
	Wir wollen also, dass $\forall x \, : \,xf+xmg=0$ gilt. das ist gleichbedeutend mit $xf=-xmg$.
	Dafür setzen wir $xg = -xm^{-1}f$. Dann ist $$xf-xmm^{-1}f = xf-xf = 0\, .$$	\bewiesen
	
	\subsubsection{Satz: Kranzprodukte durch exakte Sequenzen}
	Wir betrachten erneut die exakte Sequenz 
	\begin{figure}[H]
		\centering
		\begin{equation*}
			\begin{tikzcd}[column sep=1.5pc]
				1 \arrow{r}{} & H \arrow{r}{} & G \arrow{r}{\psi} & F \arrow{r}{} & 1
			\end{tikzcd}
		\end{equation*}
	\end{figure} 
	von Gruppen.\\
	Sei $\{[x] \in G \mid Hx, \, \, x \in F\}$ ein Repräsentantensystem von $F$ mit $[1] = 1$. 
	Dann ist $$\varphi: G \to H \wr F = H^F \rtimes F$$ eine Einbettung von Gruppen mit $\varphi(g) = (f_g, \psi(g))$ und $f_g(x) = [x]g[xg]^{-1}$ für $x \in F$. \\  Insbesondere ist dann $$G \leq H^F \rtimes F\, .$$
	
	\subsubsection{Beweis}
	Es gilt $\psi[xg] = H\psi(xg) = Hx\psi(g)$. Daher ist
	\begin{align*}
		\psi([x]g[xg]^{-1}) = Hx\psi(g)(x\psi(g)^{-1}) = H
	\end{align*}
	und $H$ ist das Einselement in F.\\
	Dann bleibt zu zeigen, dass $\varphi$ ein Hom. ist, also, dass
	\begin{align*}
		\varphi((f_h, h)(f_g, g)) = \varphi(f_nhf_g, hg) 
	\end{align*}
	gilt. Wenn man die erste Komponente betrachtet, gilt
	\begin{align*}
		x(f_h \cdot hf_g) = [x]h\underbrace{[xh]^{-1}[xh]}_{\substack{=1}}g[xhg] = [x]hg[xhg] = xf_{hg}\, .
	\end{align*}
	Dies impliziert dann, dass $\varphi((f_h, h)(f_g,g)) = (\varphi f_{hg}, hg)$ und somit $\varphi$ ein Hom. ist. 
	Abschlie\ss end ist nachzuweisen, dass die $1$ auf die $1$ abgebildet wird. Es gilt:
	\begin{align*}
		\varphi(f_g, g) = 1 \in H \wr F &\implies \psi(g) = H \\
		&\implies g \in H
	\end{align*}
	und
	\begin{align*}
		xfg = 1 \, \, \forall x &\implies 1f_g = [1]g[1g]^{-1} = g \cdot 1 = 1 \\
		&\implies g = 1\, .
	\end{align*}
	\bewiesen
	
	\section{Erkennbare und Rationale Mengen 1 - Vorlesung 7}
	\subsection{Erkennbare Mengen, Rationale Mengen und Sternfreie Sprachen}
	\subsubsection{Definition Rationale Menge ($\rat$)}
	Sei $M$ eine Monoid (z.B $M = \sigstern$).
	Dann ist $\rat(M)$ die Menge der rationalen Mengen von $M$ und die Elemente von $\rat(M)$ sind induktiv definiert durch:
	\begin{enumerate}[label=\arabic*)]
		\item $L \subseteq M \wedge |L| \leq \infty \implies L \in \rat(M)$
		\item $L_1, L_2 \in \rat(M) \implies L_1 \cup L_2 \in \rat(M) \, \wedge \, L_1 \cdot L_2 \in \rat(M)$, \\ 
		wobei $ L_1 \cdot L_2 = \{w \in M \mid \exists u,v \in M : w = uv \, \wedge \, u \in L_1 \,\wedge\, v \in L_2\}$
		\item $L \in \rat(M) \implies L^\ast = \bigcup_{i \geq 0} L^i \in \rat(M)\,,$\\
		mit $L^0=\{1_m\}$ und $L^{i+1} = L^iL$.\\ \newline
		Man beachte, dass $\bigcup_{i \geq 0} L^i $ hierbei das erzeugte Untermonoid von $L$ in $M$ ist.
	\end{enumerate}
	
	
	\subsubsection{Definition Sternfreie Sprache ($\starfree$)}
	Für ein Monoid $M$ enthält die Menge der sternfreien Sprachen $\starfree(M)$ folgende Mengen:
	\begin{enumerate}[label=\arabic*)]
		\item $L \subseteq M \wedge |L| < \infty \implies L \in \starfree(M)$
		\item $L_1, L_2 \in \starfree(M) \implies L_1 \cup L_2 \in \starfree(M) \, \wedge \, L_1 \cdot L_2 \in \starfree(M) \, \wedge \, M \setminus L = \overline{L} \in \starfree(M)$\\ 
	\end{enumerate}
	
	\subsubsection{Beispiele für Sternfreie Sprachen}
	Mit $\Sigma = \{a,b\}$ gilt:
	\begin{itemize}
		\item $(aa)^\ast \not\in \starfree(\sigstern)$
				\item $\sigstern \in \starfree(\sigstern)$, da $\sigstern = \overline{\emptyset}$
		\item $(ab)^\ast \in \starfree(\sigstern)$, da $(ab)^\ast \in \starfree(\sigstern) \iff \overline{(ab)^\ast}\in \starfree(\sigstern)$ und $\overline{(ab)^\ast} = \sigstern aa \sigstern \cup \sigstern bb \sigstern \cup b\sigstern \cup \sigstern a$
		\item $A^\ast \in \starfree(\sigstern)$ für $A\subseteq \Sigma$, da $A^\ast = \{ w \in \sigstern \mid \forall b \in \Sigma \setminus A : w \notin \sigstern b\sigstern\}$.
	\end{itemize}
	
	
	
	\subsubsection{Definition erkennbare Sprachen ($\rec$)}
	\label{sec:rec}
	Wir definieren die Menge $\rec(M)$ der erkennbaren Mengen eines Monoids $M$ wie folgt:  $$L \in \rec(M) \iff \exists \varphi : M \to N \text{ ein Hom. von Monoiden mit } |N| < \infty \text{ und } \varphi\inv\varphi(L) = L$$
	Das hei\ss t $\forall w \in M$ gilt $$w\in L \iff \varphi(w) \in \varphi(L) \subseteq N\, .$$
	
	\subsubsection{Definition aperiodisch}
	Ein Monoid $N$ ist aperiodisch genau dann, wenn alle Unterhalbguppen von $N$, die Gruppen sind, sind trivial, bzw. $N$ gruppenfrei ist.\\
	Alternativ gilt: Ein Monoid $M$	ist aperidodisch, falls $$\exists t \in \N \, \forall x \in M\, : \, x^{t+1} = x^t \, .$$
	Falls $M$ endlich ist, gilt: $$M \text{ ist aperiodisch} \iff \forall x \in M \, \exists t \in \N \,  : x^{t+1} = x^t$$
	
	
	\subsubsection{Satz von Schützenberger}
	Es gilt: 
	\begin{align*}
		L &\in \starfree(\sigstern)\\
		&\iff \\
		\exists \varphi: \sigstern \to N \text{ ist ein Hom. mit } |N| \leq &\infty \text{ und } \varphi\inv\varphi(L) = L \text{ und $N$ ist aperiodisch} \\ 
		&\iff \\
		\text{das syntaktische Monoid } &\synt(L) \text{ ist aperiodisch}
	\end{align*}
	
	\subsubsection{Definition DFA über M}
	Ein DFA (Deterministic Finite Automaton) über einem Monoid $M$ ist ein Tupel $(Q, \cdot, q_0, F)$, wobei
	\begin{enumerate}[label=\arabic*)]
		\item $\cdot: Q \times M \to Q$ ist eine Operation von $M$ auf $Q$ von rechts. Das heißt also
		\begin{align*}
			\forall q \in Q \text{ und } \forall u,v \in M \text{ gilt } (q \cdot u) \cdot v = q(uv) \text{ und } q1_M = q \, . 
		\end{align*}
		\item $|Q| < \infty$ ist eine endliche Menge von Zuständen, $F\subseteq Q$ ist die Menge der Endzustände und $q_0 \in Q$ ist der Startzustand. \\
	\end{enumerate}
	gilt.\\
	Dies definiert dann die Sprache $L(A) = \{w \in M \mid q_0\cdot w \in F\}$.
	
	\subsubsection{Beispiel für einen DFA über M}
	Sei $L \in \rec(M)$ mit $\varphi: M \to N$ wie in der Definition~\ref{sec:rec}. \\ 
	Dann definiert dies einen DFA $A = (Q,\cdot, q_0, F)$ mit $L(A) = L$ und $N = Q$. 
	Hierbei ist: 
	\begin{itemize}
		\item $q_0 = 1_M \in N$
		\item $\cdot : N \times M \to N$ mit $q\cdot u := q\varphi(u)$. Dann gilt
		\begin{align*}
			(q \cdot u)\cdot v = (q\varphi(u))v = q \varphi(u)\varphi(v) = q(\varphi(uv)) = q(uv)
		\end{align*}
		\item $q = q \cdot 1_M = q \cdot \varphi(1_M) = q1_N = q$
		\item $F = \{\varphi(u) \mid u \in L \}$
	\end{itemize}

	\subsubsection{Satz von Kleene}
	Für ein endliches Alphabet $\Sigma$ gilt $$\rat(\Sigma^*)=\starfree(\Sigma^*)=\rec(\Sigma^*)\,.$$
	
	\section{Erkennbare Mengen 2 - Vorlesung 8}
	\subsection{Abschlusseigenschaften von $\rat$ und $\rec$}
	\subsubsection{Abschluss von $\rat$ unter Hom.}
	Wenn $h: M' \to M$ ein Monoid-Hom. ist, dann gilt $$L' \in \rat(M') \implies h(L') \in \rat(M)\, .$$
	Das bedeutet, rationale Mengen sind unter Homomorphismen abgeschlossen.
	
	\subsubsection{Abschluss von $\rec$ unter Hom.}
	Wenn $h: M' \to M$ ein Monoid-Hom. ist, dann gilt $$L \in \rec(M) \implies h\inv(L) \in \rec(M')\, .$$
	Das bedeutet, erkennbare Mengen sind unter Homomorphismen abgeschlossen.
	
	\subsection{Minimaler Erkennender DFA}
	\subsubsection{Definitionen}
	\label{sec:min_dfa}
	Für eine Teilmenge $L \subseteq M$ eines Monoids $M$, soll ein DFA $A_L$ definiert werden.
	Dazu sei $Q_L = \{L(u) \mid u \in M\}$ die Zustandsmenge, wobei $L(u) = \{ w \in M \mid uw \in L\}$ die Leistung eines Wortes ist. Weiter sei $q_{0,L}=L(1)=L$ der Startzustand und $F_L=\{L(u) \, | \, u \in L\}= \{L(u) \, | \, 1 \in L(u)\}$ die Menge der Endzustände.
	Die Übergangsfunktion sei definiert durch:
	\begin{align*}
		\cdot: Q_L \times M  &\to Q_L\, ,\\
		L(u)\cdot v &\mapsto L(uv)
	\end{align*}
	Dann gilt $L(A_L) = L$, also erkennt dieser Automat $L$.\\
	Nun wollen wir zeigen, dass $A_L$ minimal ist.
	Seien $A, A'$ deterministische endliche Automaten über $M$. Dann hei\ss t 
	\begin{align*}
		f: Q \to Q'
	\end{align*} ein Morphismus, falls $f(q)u=f(qu)$, $f(q_0) = q_0'$ und $f(F) \subseteq F'$ gilt.
	Wir folgern daraus, dass $L(A) \subseteq L(A')$ gilt und für Gleichheit $L(A) = L(A')$ genau dann zutrifft, wenn $f\inv(F') = F$ gilt. 
	
	\subsubsection{Lemma: Minimalität des DFA}
	Sei $A = (Q, \cdot, q_0, F)$ ein deterministischer Automat mit $L = L(A)$ und $A_L = (Q_L, \cdot, q_{0,L}, F_L)$ der in Abschnitt~\ref{sec:min_dfa} definierte Automat.  \\
	
	Wir setzen $A' = (\{q_0u \mid u \in M\}, \cdot, q_0, \{q_0u \in F \mid u \in M\})$, dann definiert $$f: \{q_0u \mid u \in M\} \to Q_L$$ durch $f(q_0u) = L(u)$ einen surjektiven Morphismus.\\
	Daraus können wir schlie\ss en, dass $A$ nicht kleiner sein kann als $A_L$ und somit $A_L$ der minimale erkennende Automat für $L$ ist.
	
	
	\subsubsection{Beweisskizze Lemma}
	Um die Wohldefiniertheit von $f$ zu zeigen, definieren wir die Leistung $L(q)$ für $q \in Q$ durch $$L(q) = \{v \in M \mid qv \in F\}\, .$$ Also gilt dann $L(q_0u) = \{v \in M \mid q_0uv \in F\} = \{v \in M \mid uv \in F\}$.
	Dadurch hängt die Leistung dann nur vom Zustand ab. 
	Der Rest des Beweises ist trivial.
	
	\subsection{Syntaktische Kongruenz}
	\subsubsection{Definition}
	Sei $L \subseteq M$ eine Teilmenge eines Monoids $M$. Wir definieren dann $[u] = \{v \in M \mid u \equiv_L v\}$ als die Kongruenzklasse von $u$.\\
	Die Äquivalenzrelation $\equiv_L$ ist dabei definiert durch $$ u \equiv_L v \iff \forall x,y \in M : (xuy \in L \iff xvy \in L)\, .$$
	\\
	Die Menge der Kongruenzklassen nennt man Syntaktisches Monoid oder $Synt(L)$.
	
	\subsubsection{Lemma: $\equiv_L$ ist eine Kongruenz}
	$\equiv_L$ ist eine Kongruenz. Also gilt laut der Definition von Kongruenzen: $$[u][v]=[uv]$$ 
	
	\subsubsection{Beweis des Lemmas}
	Seien $u \equiv_L u'$ und $v \equiv_L v'$. Nun ist zu zeigen, dass $uv \equiv_L u'v'$ gilt. 
	
	Betrachte $x,y \in M$ mit $xuvy \in L$. 
	Es folgt: $$xuvy \in L \iff xu'vy \in L \iff xu'v'y \in L$$ Damit ist auch $\pi: M \to \synt(L), \, u \mapsto [u]$ ein surjektiver Hom.. 
	
	\subsubsection{Satz: Minimalität von Synt(L)}
	Sei $h: M \to N$ ein Monoid-Hom. mit $h\inv(h(L)) = L$. Dann definiert $f:h(M) \to \synt(L)$ durch $h(u) = [u]$ einen surjektiven Hom.. \\
	Durch die Surjektivität folgt wieder, dass $\synt(L)$ nicht größer als $N$ sein kann und damit das kleinste Monoid ist, dass $L$ erkennt. 
	
	\subsubsection{Beweis des Satzes}	 
	Zu zeigen ist (nur) die Wohldefiniertheit, also, dass $h(u) = h(v) \implies [u]=[v]$ gilt. Dies ist trivial.
	
	\subsubsection{Graphische Interpretation}	
	Abbildung~\ref{fig:synt} veranschaulicht den Beweis für $n = h(u) = h(v) \implies [u] = [v]$.
	\begin{figure}[h!]
		\centering
		\begin{tikzpicture}[node distance=3cm, auto]
			\node (A) {$h:M$};
			\node (B) [right of=A] {$h(M) = N' \leq N$};
			\node (C) [below of=A] {$\synt(L)$};
			
			\draw[-{Stealth}] (A) to node {} (B);
			\draw[-{Stealth}, dashed] (B) to node [] {$\exists! f: f(n) = [u], \text{ falls } n = h(u)$} (C);
			\draw[-{Stealth}] (A) to node [swap] {$\pi : u \mapsto [u]$} (C);
		\end{tikzpicture}
		\caption{Graphische Interpretation des Beweises der Minimalität von $Synt(L)$.}
		\label{fig:synt}
	\end{figure}
	
	\subsubsection{Folgerung: Zusammenhang von Synt(L) und erkennenden Automaten}
	\label{sec:equiv}
	Es gilt:\\	
	$L \in rec(M) \iff |\synt(L)| < \infty \iff A_L \text{ ist ein DFA, dh. } Q_L = \{L(u) \mid u \in M\} \text{ ist endlich}$
	
	\subsubsection{Beweis der Folgerung}
	Sei $L \subseteq M$ und  $A = (Q, \cdot, q_0, F)$ ein deterministischer Automat mit $L = L(A)$. \\
	Dann ist $(Q^Q, \circ, id_Q)$ ein Monoid mit  $Q^Q = \{ f : Q \to Q \mid f\text{ ist eine Abbildung}\}$ und $(f \circ g)(q) = g f(q)$.
	Wir definieren einen Homomorphismus $$ \varphi : M \to Q^Q, \, \, u \mapsto f_u$$  mit $f_u(q) = q_u$. 
	Dann ist $(f_u \circ f_v)(q) = quv$.\\
	Weiter sei $T = \{f_u \mid u \in M\}$ das Transformationsmonoid.
	Somit folgt $\varphi: M \to T$. Für $Q=n$ gilt $|T| \leq n^n \in 2^{n \log n}$. 
	Graphisch kann man sich den Beweis nun analog zu Abbildung~\ref{fig:synt} vorstellen, durch
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[node distance=3cm, auto]
			\node (A) {$M$};
			\node (B) [right of=A] {$T$};
			\node (C) [below of=A] {$\synt(L)$};
			
			\draw[-{Stealth}] (A) to node {} (B);
			\draw[-{Stealth}, dashed] (B) to node [] {$\psi$} (C);
			\draw[-{Stealth}] (A) to node [swap] {$y \mapsto [y]$} (C);
		\end{tikzpicture}
	\end{figure}
	
	mit $\psi(f_u)=[u]$, wobei $f_u = f_v \overset{!}{\implies} [u] = [v]$ zu zeigen ist. 
	
	Wir betrachten nun $x, y \in M$ mit $xuy \in L$.
	Dann gilt:
	\begin{align*}
		xuy \in L &\implies q_0xuy \in F\\
		&\implies q_0xu = f_u(q_0x) = f_v(q_0x)\\
		&\implies q_0xvy \in F \\
		&\implies xvy \in L\\
		&\implies \psi \text{ ist wohldefiniert}
	\end{align*}
	Damit wissen wir, dass die Existenz eines endlichen erkennenden Automaten, die Endlichkeit des syntaktischen Monoids impliziert.\\
	
	Für die Umkehrung sei nun $Q = Q_L = \{L(x) \mid x \in M\}$ die Zustandsmenge des minimalen deterministischen Automaten. Dann gilt $[u]= [v] \implies f_u = f_v$. Dies ist begründet durch:
	\begin{align*}
		[u]= [ v ] \implies f_u(L(x)) &= L(x)u \\
		&= L(xu) = \{y \mid xuy \in L\} \\ 
		&= \{y \mid xvy \in L\} \\
		&= L(x)v = f_v(L(x))
	\end{align*}
	Aus $\forall x\, :\, L(x)u = L(x)v$ folgt $f_u = f_v$.\\
	Insgesamt gilt damit die Äquivalenz aus Abschnitt~\ref{sec:equiv}. 
	\bewiesen
	
	\subsubsection{Konsequenz: Isomprphie von Synt(L) und T}
	Für das syntaktische Monoid $Synt(L)$ und das Trasnformationsmonoid $T$ gilt:
	$$\synt(L) \cong T = \{f_u \mid u \in M\}$$
	Das bedeutet, man kann $Synt(L)$ aus dem minimalen DFA berechnen.
	
	\subsubsection{Satz von McKnight}
	Es gilt: 
	\begin{align*}
		\rec(M) \subseteq \rat(M) &\iff M \in \rat(M)\\ 
		&\iff M \text{ ist endlich erzeugt} \\ 
		&:\iff \exists \, \Sigma \text{ endlich und } \pi : \sigstern \to M \text{ ist surjektiver Hom. }
	\end{align*}
	
	\subsubsection{Beweis des Satzes von McKnight}
	Es gilt $\emptyset, M \in \rec(M)$ durch das triviale Monoid, vermöge $$h: M \to \{1\}\, .$$ Wenn $M \in \rat(M)$ ist, dann folgt daraus, dass $M=L$ für einen rationalen Ausdruck für $M$. 
	Da dieser nur eine endliche Teilmenge von $M$ benutzt, folgt die Hin-Richtung der Behauptung.
	
	Zu zeigen ist also nun noch die andere Richtung. 
	\newline
	
	Sei $\pi : \sigstern \to M$ ein surjektiver Hom. und $|\Sigma| < \infty$. 
	Wir wollen zeigen, dass dann $L \in \rec(M) \implies L \in \rat(M)$ gilt.\\
	Wir haben also
	
	\begin{equation*}
		\begin{tikzcd}[column sep=1.5pc]
			\sigstern \arrow{r}{\pi} & M \arrow{r}{h} & N 
		\end{tikzcd}
	\end{equation*}
	mit $|N| < \infty$ und $h\inv(h(L)) = L$. Dann folgt $\pi\inv(L) \in \rec(M)$ wegen der Abgeschlossenheit unter Hom..
	Weiter gilt dann $\exists \text{ DFA } A \text{ mit } \pi\inv(L) = L(A)$, woraus $\pi\inv(L) \in \rat(\Sigma^*)$ folgt.
	Wegen der Surjektivität von $\pi$ gilt $\pi\pi\inv(L) = L \in \rat(M)$.
	\bewiesen
	
	\subsubsection{Definition NFA über M}
	Ein NFA $A$ über einem Monoid $M$ ist ein Tupel $(Q, \delta, I, F)$ mit $I, F \subseteq Q$, wobei $$\delta \subseteq Q \times M \times Q$$ und $|\delta| < \infty$ gilt. 
	Dann ist die erkannte Sprache $L(A) = \{w \in M \mid \exists u_1, \ldots, u_n \in M : w = u_1 \ldots u_n \, \wedge \text{ es gibt Pfad } \begin{tikzcd}[column sep=1.7pc]
		q_0\arrow{r}{u_1} &  q_1 \arrow{r}{u_2} & \ldots \arrow{r}{u_n} & q_n
	\end{tikzcd} \text{ aus Übergängen in } \delta \text{ mit } q_0 \in I \wedge q_n \in F\}$. 

	
	\subsubsection{Satz: Zusammenhang von rationalen Mengen und NFAs}
	Es gilt $$ L \in \rat(M) \iff \exists \text{ NFA mit } L(A) = L \, .$$
	
	\subsubsection{Beweis des Satzes}
	Wie in der Vorlesung Formale Sprachen und Automatentheorie.
	
	\section{Syntaktische Monoide - Vorlesung 9}
	\subsection{Wortproblem in Gruppen}
	\subsubsection{Definition}
	Sei $\pi : \sigstern \to G$ eine Präsentation einer endlich erzeugten Gruppe(Eine präsentation einer Gruppe ist eine Menge von Elementen, die die Gruppe erzeugen, und eine Menge von Relationen, die zwischen diesen Erzeugern bestehen.). Dann definiert $$\wop(G) = \{ w \in \sigstern \mid \pi(w)=1_G\}$$das Wortproblem in dieser Gruppe.
	
	\subsubsection{Lemma: Syntaktisches Monoid des Wortproblems}
	Es gilt $\synt(\wop(G))=G$.\\
	Wiederholung: Das syntaktische Monoid wird gebildet durch: 
	\begin{align*}
		\sigstern &\to \synt(L) \\
		u &\mapsto [u]
	\end{align*}
	
	\subsubsection{Beweis des Lemmas}
	Für die Rück-Richtung sei $\pi(u) = \pi(v)$. Daraus folgt dann
	\begin{align*}
		xuy \in \wop(G) &\iff \pi(x)\pi(u)\pi(y) = 1  \\
		&\iff \pi(x)\pi(v)\pi(y) = 1 \\
		&\iff xvy \in \wop(G)
	\end{align*}
	Daraus schlie\ss en wir $u \equivWP v$.
	\newline
	
	Für die Hin-Richtung sei jetzt $u \equivWP v$. Dann gilt 
	\begin{align*}
		\pi(y) = \pi(u)\inv &\iff  1\cdot u \cdot y \in \wop(G)\\
		&\iff 1\cdot v \cdot y \in \wop(G)\\
		&\iff \pi(y) = \pi(v)\inv
	\end{align*}
	Also folgt $\pi(u) = \pi(v)$.
	\bewiesen
	
	\subsubsection{Korrolar: Regularität des Wortproblems}
	Wir können ohne Beweis also schlie\ss en, dass $$|G| < \infty \iff \wop(G) \text{ ist reguläre Sprache}$$ gilt.
	
	\subsubsection{Satz: Untergruppen erkennbarer Sprachen}
	Sei $L \in \rec(G)$. Dann gibt es eine Untergruppe (sogar einen Normalteiler $H \trianglelefteq G$) von endlichem Index und es existieren Elemente
	$g_1, \ldots, g_n$ so, dass $L = g_1H \cup g_2H \cup \ldots \cup g_nH$.   
	
	\subsubsection{Beweis des Satzes}
	Sei $L \in \rec(G)$. Dann gilt $L= h\inv(F)$ für einen Hom. $h:G \to N$ mit $|N| < \infty$ und $F \subseteq N$. \\
	
	\OE $\, \,$gilt $h$ ist surjektiv und da $h:G \to N$ ein Hom. ist, folgt, dass $N$  eine Gruppe ist. 
	
	Sei nun $h(g) \in N$ und $H= ker(h) \trianglelefteq G$ ein Normalteiler von endlichem Index, dann folgt $h(gH) \in F$ und somit $gH \subseteq L$.
	\bewiesen
	
	\subsubsection{Folgerung des Satzes}	
	Ist $G$ eine unendliche Gruppe und $L \subseteq G$ endlich (zB. $L = \{1\}$), dann ist $L \in rat(G) \setminus \rec(G)$
	
	\subsection{Idempotenz}
	\subsubsection{Definition}
	Ein Element $e$ aus einem Monoid $M$ hei\ss t idempotent, falls $$e^2 = e$$gilt.
	Damit können wir die folgende Menge der Idempotente definieren: $$E(M) = \{ e \in M \mid e^2 = 2\}$$ Es gilt immer $1\in E(M)$.
	
	\subsubsection{Definition lokales Monoid}
	Sei $S$ eine Halbgruppe, $E(S) = \{e \in S \mid e^2 = e\}$ und $e \in E(S)$. Dann ist die Unterhalbgruppe $eS^1e \leq S$ sogar ein Monoid, da 	$e(exe) = exe = (exe)e$, wobei 
	\begin{align*}
		eS^1e &:= eSe \cup \{ee\} \\
		&=eSe \cup \{e\}
	\end{align*}
	gilt.\\
	Für ein Monoid $M$, nennt man das Monoid $eMe$ das lokale Monoid bei $e \in E(M)$.
	
	\subsubsection{Definition Teilwort}
	Ein Wort $a = a_1 \ldots a_n$ hei\ss t Teilwort von $w$ falls $w \in \sigstern a_1 \sigstern a_2 \sigstern \ldots a_n\sigstern$ gilt.
	
	\subsubsection{Beispiele für Idempotente und syntaktische Monoide} 
	\begin{itemize}
		\item Sei $\Sigma = \{a, b\}$ und $\synt((ab)^\ast) = \{1, a ,b , ab, ba, 0\} = B^1_2$ das Brandt-Monoid mit $2$ Erzeugenden und den folgenden Rechenregeln für alle $x \in B^1_2$: 
		\begin{align*}
			1x &= x1 = x   &&aba = a  &&&a^2=b^2 = 0\\
			0x &= x0 = 0   &&bab = b 
		\end{align*}
		Weiter ist $$\pi: \sigstern \to B^1_2$$ definiert durch $\pi(a) = a$ und $\pi(b) = b$. \\
		Es gilt:
		\begin{align*}
			(ab)^n &\equiv 1 \text{ für } n = 0 \\
			(ab)^n &\equiv ab \text{ für } n \geq 1 
		\end{align*} Die idempotenten Elemente sind also: $1, ab ,ba, 0$.
		\item Wir betrachten $\mathsf{Synt}(\Sigma^*a\Sigma^*b\Sigma^*)$ für $\Sigma= \{a,b\}$. Dieses syntaktische Monoid lässt sich darstellen als $M = \{1, a, b, ba, 0\}$ mit den folgenden Rechenregeln: 
		\begin{align*}
			ab &= 0    && a^2 = a &&&b^2 = b \\
			b(ba) &= ba   &&(ba)a = ba &&& (ba)b = 0 \\
			a(ba) &= 0  &&(ba)^2 = (ba)(ba) = 0
		\end{align*}
		Somit ist zu erkennen, dass $ba$ das einzige nicht idempotente Element ist. 
		\item Kontextfreie Grammatiken erlauben Regeln der Form $$A \to \alpha \text{ mit } A \in V, \alpha \in (\Sigma \cup V)^\ast$$ oder $$\varepsilon \to \alpha, \text{ mit } \alpha \in (V \cup \Sigma)^\ast\, .$$ 
		
		Für $\Sigma = \{a, b\}$, betrachten wir nun die folgende Grammatik $\mathscr{G}$:
		\begin{align*}
			S &\to \varepsilon \\ 
			\varepsilon &\to a^2 \mid b^2 
		\end{align*} 
		Sei $L=L(\mathscr{G})$.\\
		\textbf{Frage:} $a^nb^2a^m \in L$? 
		\newline
		\textbf{Antwort:} Ja, genau dann, wenn $n+m \equiv 0\, (2)$ gilt.\\
		\newline
		\textbf{Frage:} $(ab)^n(ba)^m \in L$? 
		\newline
		\textbf{Antwort:} Ja, genau dann, wenn $n=m$ gilt.\\
		\newline
		Somit folgt: $L$ ist nicht regulär.\\
		Diese Sprache ist das Wortproblem einer Gruppe:\\
		Es gilt $L(\mathscr{G})=\mathsf{WP}(G)$ für die Gruppe $G=\Z \rtimes \Z/2\Z$ mit $$(m,i)(n,j) = (m+(-1)^in, i+j\, \mod 2) $$.
	\end{itemize}
	
	\section{Halbgruppentheorie Teil 1 - Vorlesung 10}
	\subsection{Green's Relations}
	\subsubsection{Definition Ideal}
	Bei Idealen eines Rings unterscheidet man in sogenannte Links-, Rechts- und Beidseitige Ideale. 
	Sei $I \subseteq R$ für einen Ring $R=(R,+,\cdot)$. Dann ist $I$ ein Linksideal, falls 
	\begin{enumerate}[label= \arabic*.)]
		\item $(I, +)$ bildet eine Untergruppe von $R$ 
		\item $\forall a \in I, r \in R : r \cdot a \in I  $
	\end{enumerate}
	gilt und analog ein Rechstideal falls 1.) von oben und
	\begin{enumerate}[label= \arabic*.)]
		\setcounter{enumi}{2}
		\item $\forall a \in I, r \in R : a \cdot r \in I  $
	\end{enumerate}
	gilt.
	Falls $I$ alle drei Kriterien erfüllt, ist es ein beidseitiges Ideal.\\
	Ein Hauptideal ist ein, von einem einzigen Element erzeugtes, Ideal.
	\newline
	
	Das Konzept lässt sich auch auf Monoide anwenden, indem man auf Kriterium 1.) verzichtet.
	\subsubsection{Definition Green's Relations}	
	Green's Relations sind die, im Folgenden für ein Monoid $M$ definierten, Äquivalenzrelationen $\mathcal{L,R, J, H}$ und $\mathcal{D}$. 
	\begin{align*}
		\mathcal L \subseteq M \times M: x \grel y &\iff Mx = My \\ 
		&\iff x,y \text{ erzeugen identische Linksideale} \\
		\mathcal R \subseteq M \times M: x \grer y &\iff xM = yM  \\ 
		&\iff x,y \text{ erzeugen identische Rechtsideale} \\
		\mathcal J \subseteq M \times M: x \grej y &\iff MxM = MyM \\ 
		&\iff x,y \text{ erzeugen identische beidseitige Ideale} \\
		\mathcal H = \mathcal L \cap \mathcal R: x \greh y &\iff x \grel y \wedge x \grer y
	\end{align*}
	\newline
	
	Neben der $\sim$-Relation ist auch jeweils eine $\leq$-Relation wie folgt definiert:
	\begin{align*}
		\mathcal L \subseteq M \times M: x \lgreleq y &\iff Mx \subseteq My \\
		\mathcal R \subseteq M \times M: x \lgrereq y &\iff xM \subseteq yM \\
		\mathcal J \subseteq M \times M: x \lgrejeq y &\iff MxM \subseteq MyM  \\
		\mathcal H \subseteq M \times M: x \lgreheq y &\iff x \lgreleq y \land x \lgrereq y 
	\end{align*}
	\newline
	
	Mit der allgemeinen Definition der Verknüpfung $\circ \,$ für $R \subseteq X \times Y$ und $S \subseteq Y \times Z$:
	\begin{align*}
		R \circ S &= \{(x,z) \in X \times Z \mid \exists y \in Y: (x,y) \in R, (y, z) \in S\} 
	\end{align*}
	können wir nun noch die fünfte Relation $\mathcal{D}$ angeben.  
	Es gilt dann: 
	\begin{align*}
		\mathcal{D}&=\mathcal L \circ \mathcal R = \{ (x,y) \subseteq M \times M \mid \exists z \in M : x \grel z \grer y \}\\
		&=\mathcal R \circ \mathcal L
	\end{align*}
	Ein Beweis über die Gleichheit von $\mathcal L \circ \mathcal R$ und $\mathcal R \circ \mathcal L$ findet sich im Abschnitt 7.18 des Buchs ``Discrete Algebraic Methods''.
	 
	\subsubsection{Beziehungen der Green's Relations}
	Abbildung~\ref{fig:greens} veranschaulicht, wie die Relationen zueinander in Beziehung stehen. 
	\begin{figure}[h!]
		\centering
		\begin{tikzpicture}[node distance=3cm, auto]
			\node (H) {$\mathcal{H}$};
			\node (L) [above right of=H] {$\mathcal{L}$};
			\node (R) [below right of=H] {$\mathcal{R}$};
			\node (LUR) [below right of=L] {$\mathcal L \cup \mathcal R$};
			\node (LDR) [right of=LUR] {$\mathcal L \circ \mathcal R = \mathcal D$};
			\node (J) [right of=LDR] {$\mathcal J$};
			
			\draw[-] (H) -- (L) node[midway,sloped,above,rotate=0] {$\subseteq$};
			\draw[-] (H) -- (R) node[midway,sloped,below,rotate=0] {$\subseteq$};
			\draw[-] (L) -- (LUR) node[midway,sloped,above,rotate=0] {$\subseteq$};
			\draw[-] (R) -- (LUR) node[midway,sloped,below,rotate=0] {$\subseteq$};
			\draw[-] (LUR) -- (LDR) node[midway,sloped,above,rotate=0] {$\subseteq$};
			\draw[-] (LDR) -- (J) node[midway,sloped,above,rotate=0] {$\subseteq$};
		\end{tikzpicture}
		\caption{Die Verbindungen zwischen den einzelnen Green's Relations.}
		\label{fig:greens}
	\end{figure} \\ 
	
	Im Allgemeinen gilt $\mathcal D \not = \mathcal J$, für endliche Monoide gilt jedoch $\mathcal D = \mathcal J$, was wir in Abschnitt~\ref{sec:dgleichj} noch zeigen werden. 

	\subsubsection{Definition K-Trivial}		
	Sei $\mathcal{K} \in \{\mathcal{H}, \mathcal{L},\mathcal{R}, \mathcal{D}, \mathcal{J}\}$, dann hei\ss t $M$, das zugehörige Monoid, $\mathcal{K}$-Trivial, falls $$x \sim_K y \implies x = y$$gilt.
	
	\subsubsection{Green's Relations in Gruppen}
	Für eine Gruppe $G$ gilt:
	$$\mathcal{H=L=R=D=J}=G \times G\, ,$$
	weshalb diese Relationen auf Gruppen uninteressant sind.
	
	\subsubsection{Lemma: idempotente Potenzen}
	Sei $x \in M$ und $|M| < \infty$. Dann existiert genau eine $x$-Potenz $x^n \in M$ mit $x^n = x^{2n}$. 
	Für diese Potenz gilt also $x^n \in E(M)$ und sie wird mit $x\pom$ bezeichnet. 		
	
	\subsubsection{Beweis des Lemmas}
	Für alle $x \in M $ existiert ein threshold $t \in \N$ und eine Zahl $p \in \N$ mit $p \geq 1$, sodass $x^{t+p} = x^t \in M$ gilt.
	Abbildung~\ref{fig:idempotenz} veranschaulicht die Idee.
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[node distance=1.9cm, auto]
			\node (1) {$1$};
			\node (x) [right of=1] {$x$};
			\node (x2) [right of=x]{$x^2$};
			\node (dots) [right of=x2]{$\ldots$};
			\node (xt) [right of=dots]{$x^t$};
			\node (xt1) [above right of=xt] {$x^{t+1}$};
			\node (xtpm1)  [ below right of = xt] {$x^{t+p -1}$};
			\node (dotslow) [below right of=xt1]{ $\ldots$};
			
			
			\draw[ ->] (1) -- (x) node[ midway,sloped,above,rotate=0] { };
			\draw[->] (x) -- (x2) node[midway,sloped,above,rotate=0] {};
			\draw[->] (x2) -- (dots) node[midway,sloped,above,rotate=0] {};
			\draw[->] (dots) -- (xt) node[midway,sloped,above,rotate=0] {};
			\draw[->] (xt) edge   [bend left] (xt1) node[midway,sloped,above,rotate=0] {};
			\draw[->] (xt1) edge   [bend left](dotslow) node[midway,sloped,above,rotate=0] {};
			\draw[->] (dotslow) edge   [bend left] (xtpm1) node[midway,sloped,above,rotate=0] {};
			\draw[->] (xtpm1) edge   [bend left] (xt) node[midway,sloped,above,rotate=0] {};
		\end{tikzpicture}
		\caption{Bei wiederholter Verknüpfung mit $x$ wird, wegen der endlichen Anzahl an verschiedenen Elementen, irgendwann ein Element erneut erreicht.}
		\label{fig:idempotenz}
	\end{figure} 
	
	Wir sehen, dass in der Folge $( x^i \mid i \in \N)$ mindestens ein paar $(i,j)$ mit $i < j$ und $x^i = x^j$ existieren muss. Wir wählen nun $t=i$ minimal, dann ist auch $t+p = j$ minimal. 
	Für die Idempotenz von $x^t$ gilt nun:
	\begin{align*}
		x^{t+j} = x^{2t + 2j} = x^{t + t + 2j} 
		&\iff j \equiv t + 2j \mod p \\
		&\iff t \equiv -j \mod p
	\end{align*}
	\bewiesen
	
	\subsubsection{Beobachtung}
	Sei $x^{t+p} = x^t$. Dann gilt: 
	\begin{align*}
		x^t \geqslant_{\mathcal{L, R}} x^{t+1} \geqslant_{\mathcal{L, R}} \ldots \geqslant_{\mathcal{L, R}} x^{t+p-1} \geqslant_{\mathcal{L, R}} x^{t+p} = x^t
	\end{align*}
	Also müssen alle $\mathcal{L}$- und $\mathcal{R}$-Klassen gleich sein.\\
	Weiter sehen wir
	\begin{align*}
		x^{t+i} \greh x^t \, \, \forall i \in \N 
		\implies \forall x \text{ gilt } x^{t+i} \in \mathcal{H}(x\pom), \text{ wobei } x\pom \in E(M) \text{gilt.}
	\end{align*}
	
	\subsubsection{Lemma: Idempotente in Gruppen}
	Sei $G \leq M$ eine Unterhalbgruppe, die eine Gruppe ist. 
	Dann gilt $\forall x,y \in G:\, x\pom = y\pom = 1_G$.
	Daraus folgt weiter: $\exists x\pom = e \in M, \, e = 1_G$ und $ G \leq \mathcal H(e)$.
	
	
	\subsubsection{Lemma: Folgerungen aus beidseitigen Idealen}
	\label{sec:jklassen}
	Sei $M$ ein endliches Monoid und sei weiter $s \grej t$ mit $s = ptu$ und $t=qsv$. Nun gilt Folgendes: 
	\begin{enumerate}[label = \alph*)]
		\item $s \lgrereq t \implies s \grer t$ (Analoges gilt für $\grel$)
		\item $\mathcal{L}(s) \cap \mathcal{R}(t) \not = \emptyset$
		\item $\mathcal{D} = \mathcal{J}$
	\end{enumerate}
	

	Dieses Lemma und der zugehörige folgende Beweis können auch unter Lemma 7.42 des Buchs ``Discrete Algebraic Methods'' nachgelesen werden.
	
	\subsubsection{Beweis des Lemmas}
	\label{sec:dgleichj}
	\begin{enumerate}[label = \alph*)]
		\item Sei $s \lgrereq t$. \OE\hspace{1pt} setzen wir $p=1$, wodurch $s = tu$ gilt. Weiter gilt dann: 
		\begin{align*}
			t=qsv = qtuv&= q(qtuv)uv \\
			&= q\pom t(uv)\pom \\
			&= q\pom t(uv)\pom(uv)\pom \quad |\text{ aufgrund der Idempotenz-Eigenschaft}\\
			&= t(uv)\pom  \quad |\text{ durch Einsetzten in die entgegengesetzte Richtung}
		\end{align*}
	 	Das Element $t(uv)\pom$ ist aus $tuM = sM$.\\
		Es folgt also $t \lgrereq s \implies t \grer s$.
		\bewiesen
		
		\item Nach Voraussetzung gilt $s=ptu$ und $t=qsv$. Daraus folgt: 
		\begin{align*}
			s=ptu &= (pq)s(vu) \\
			&=(pq)\pom s(vu)\pom \\
			&= (pq)\pom(pq)\pom s (vu)\pom \\
			&= (pq)\pom s
		\end{align*}
		
		Somit gilt $s \lgreleq qs$, woraus $s \grel qs$ folgt. Es bleibt nun zu zeigen, dass $qs \grer t$ gilt. 
		Durch Symmetrische Vorgehensweise bekommt man: $s \lgrereq sv$ und damit
		$s \grer sv$. \\ 
		Insgesamt gilt also $qs \grer qsv = t$ und $qs \in \mathcal{L}(s) \cap \mathcal{R}(t)$, wodurch diese Menge nicht leer sein kann.
		\bewiesen
		
		\item Da $\mathcal{D} \subseteq \mathcal{J}$ immer gilt, reicht es, die Implikation $(s,t) \in \mathcal{J} \implies (s,t) \in \mathcal{L} \circ \mathcal{R}$ zu zeigen. 
		Nach b) gilt $\exists z = qs$ mit $s \grel z \grer t$. Dies zeigt die Behauptung.
		\bewiesen
	\end{enumerate}
	
	\section{Divisoren, aperiodische Monoide - Vorlesung 11}
	\subsection{Divisoren}
	\subsubsection{Definition Subquotient}
	\label{sec:subquotient}
	Sei $M$ ein Monoid,  $L \subseteq M$ eine Sprache und $A$ ein DFA mit $L=L(A)$. \\ 
	Dann existiert ein Subautomat $A'$ von $A$, der $L$ auch erkennt, mit der Zustandsmenge $Q_{A'} = \{q_0u \mid u \in M\}$, wobei $q_0$ der Startzustand ist.\\
	Weiter wissen wir nach Abschnitt~\ref{sec:min_dfa}, dass es auch einen minimalen erkennenden Automaten $A_L$ gibt mit der Zustandsmenge
	$Q_{A_L}=\{L(u) \mid u \in M\}$, wobei $L(u) = \{ v \in M \mid uv \in L\}$ gilt. \\
	Nun lässt sich folgende surjektive Abbildung definieren, welche in Abbildung~\ref{fig:subquotient} visualisiert ist:
	\begin{align*}
		A' &\to A_L\\
		q_0u &\mapsto L(u)
	\end{align*}
	Wir nennen dann $A_L$ den Subquotient von $A$.
	
	\begin{figure}[h!]
		\centering
		\begin{tikzpicture}[node distance=2.5cm, auto]
			\node (AS) {$A'$};
			\node (A) [right of=AS] {$A$};
			\node (AL) [below of=AS] {$A_L$};
			
			\draw[right hook->] (AS) -- (A) node[ midway,sloped,above,rotate=0] { };
			\draw[ ->>] (AS) -- (AL) node[ midway,right,rotate=0] { $q = u \mapsto L(u)$};
		\end{tikzpicture}
		\caption{Beziehung der Automaten und Subquotienten.}
		\label{fig:subquotient}
	\end{figure} 
	
	\subsubsection{Subquotienten in syntaktischen Monoiden}
	Analog zu Abschnitt~\ref{sec:subquotient}, kann man auch Subquotienten für syntaktische Monoide definieren.
	Wir betrachten dafür den Monoidhomomorphismus $\varphi: M \to N$ mit $L = \varphi\inv \varphi(L)$. 
	Das bedeutet, $\varphi$ erkennt $L \subseteq M$.
	In Abbildung~\ref{fig:subquotient_monoid} ist nun zu sehen, dass wir wieder eine surjektive Abbildung haben ($\varphi$) und es dadurch auch einen eindeutig bestimmten Hom. von $\varPhi(M)$ nach $M_L$ gibt.
	Hier ist nun $M_L$ der Subquotient von $N$.
	\begin{figure}[h!]
		\centering
		\begin{tikzpicture}[node distance=2.9cm, auto]
			\node (M) {$M$};
			\node (PM) [right of=AS] {$\varphi(M) \leq N$};
			\node (ML) [below of=AS] {$M_L$};
			
			\draw[->>] (M) -- (PM) node[ midway,sloped,above,rotate=0] { $\varphi$};
			\draw[ ->] (M) -- (ML) node[ midway,right,rotate=0] { $\varphi_L$};
			\draw[ dotted, ->] (PM) -- (ML) node[ midway,right,rotate=0] {$\exists! \psi$};
		\end{tikzpicture}
		\caption{Beziehung der Monoide.}
		\label{fig:subquotient_monoid}
	\end{figure} 
	
	Hierbei gilt $M_L = \synt(L) = \{[u] \mid u \in M\}$, $ \psi(\varphi(u))= [u]$, und $[u] =\{v \in M \mid u \equiv_L v\}$.
	
	\subsubsection{Definition Divisor}
	$M$ ist ein Divisor von $N$, falls es ein Untermonoid $N'$ von $N$ gibt und ein surjektiver Hom. $$\psi: N' \to M$$ existiert. Wir schreiben dann $M \prec N$.\\
	
	Ein Divisor ist also das Quotientenmonoid einer Unterhalbgruppe.
	
	\subsubsection{Beispiel für Divisoren in Gruppen}
	Wir betrachten die Quaternionenruppe $Q_8 =  \{\pm1, \pm i ,\pm j, \pm k\}$ mit $i^2 = j^2 = k^2 = -1$ und den folgenden Verknüpfungsregeln:
	\begin{align*}
		ij &= k && jk = i  \\ 
		ik&=-j 	&& ki = j \\
		ji&= -k && kj = -i \\
	\end{align*}
	Man kann sich die Verknüpfung also als eine Art ``Stellwerk'' vorstellen, wie in Abbildung~\ref{fig:quaternion} dargestellt.
	\begin{figure}[h!]
		\centering
		$ \begin{array}{ccc}
			\begin{tikzpicture}[->,scale=.7] 
				\foreach \a/\t in {90/j,-30/k,210/i}{
					\node (\t) at (\a:1cm) {$\t$};
					\draw (\a-20:1cm)  arc (\a-20:\a-100:1cm);
				} 
			\end{tikzpicture}
		\end{array}$
		\caption{Verknüpfung in der Quaternionengruppe}
		\label{fig:quaternion}
	\end{figure}
	
	Dann ist das Zentrum $Z(Q_8) = \{1, -1\}$ und es gilt $Q_8/Z(Q_8) = V = \Z/2\Z \times\Z/2\Z$.\\
	Wir behaupten dann, dass $V$ ein Divisor des semidirekten Produkts $Q_8  \rtimes \Z / 3\Z$ ist, aber weder eine Untergruppe noch ein Quotient davon ist.
	
	Wir verzichten auf einen Beweis, aber zur Erklärung betrachte man die Isomorphie zur speziellen linearen Gruppe von Grad 2 über einem Körper mit drei Elementen $$Q_8  \rtimes \Z / 3\Z = SL(2, \mathbb{F}_3)\, ,$$ 
	wobei hier $\mathbb{F}_3 = \Z / 3\Z$ gesetzt wird.
	
	\subsubsection{Definition lokaler Divisor}
	Sei $M$ eine Monoid und $c \in M$. Dann sei $M_c = cM \cap Mc$ eine Teilmenge von $M$ und $\circ$ die folgende Multiplikation: $$xc \circ cy = xcy$$
	Dann hei\ss t $M_c = (\{cM \cap Mc\}, \circ, c)$ der lokale Divisor von $M$ bei $c$.
	
	\subsubsection{Beweis der Wohldefiniertheit und Assoziativität der Definition}
	Für die Wohldefiniertheit betrachten wir $x'c \circ cy' = x'cy'$.
	Seien nun $x = x'c = x''c$ und $y = cy' = cy''$. Es ist zu zeigen, dass $x'c \circ cy' = x''c \circ cy''$ gilt. Dies ist der Fall, da $$x'c \circ cy' = x'cy' = (x'c)y' = x''cy' = x''(cy')= x''cy''$$ gilt. 
	
	Die Assoziativität sieht man folgenderma\ss en:
	\begin{align*}
		(x'c \circ y'c)\circ z'c &= (x'y')z'c \\
		&= x'(y'z')c \\
		&= x'c \circ (y'c \circ z'c)
	\end{align*}
	\bewiesen
	
	\subsubsection{Beweis der Divisor-Eigenschaft des lokalen Divisors}
	Betrachte das Untermonoid $M' :=\{x \in M \mid xc \in cM\}$ von $M$ mit folgender Rechtsmultiplikation:
	\begin{align*}
		\rho_c: M' &\to M_c\\
		x &\mapsto xc
	\end{align*}
	
	Es ist leicht, zu sehen, dass $M'$ tatsächlich ein Untermonoid ist:
	\begin{align*}
		1 \in M' \text{ gilt, wegen }& 1c=c\in cM\\
		xy \in M' \text{ gilt für } x, y \in M'\text{, wegen }& xc \in cM \wedge yc \in cM \implies xyc \in cM
	\end{align*}
	
	 Nun gilt $$\rho_c(xy) = xyc = xc \circ yc = \rho_c(x) \circ \rho_c(y)\, ,$$ was bedeutet, dass $\rho_c$ ein Hom. ist.\\

	Sei $z = cx = yc \in M_c$. 
	Dann gilt $z = \rho_c(y)$ und $y \in \{x \in M \mid xc \in cM\}$, was die Surjektivität von $\rho_c$ zeigt.\\
	
	Wie sehen also insgesamt, dass $M_c$ ein Divisor ist.
	\bewiesen
	
	\subsubsection{Lemma: Zusammenhang lokale Divisoren und Einheiten}
	Sei $c\in M$. Dann gilt $$M_c = cM \cap Mc = M \iff c \in U(M) \iff \exists d \in M : cd = dc = 1 \iff 1 \in M_c\, .$$
	Dabei bildet $U(M)$ die Menge der Einheiten in $M$.\\
	Beachte: $U(M) = M \iff M$ ist Gruppe. \\
	
	Insbesondere folgt damit die Implikation $c \notin U(M) \wedge |M| < \infty \implies |M_c| < |M|$.
	
	\subsubsection{Beweis des Lemmas}
	Sei $c \in U(M)$. Dann gilt $cd = dc = 1$ für ein $d$.
	Damit gilt $\{x \in M \mid xc \in cM\}  = M$ und $cM = Md = M$, sowie $\rho_c\rho_d = id_M = \rho_d\rho_c$. 
	Also ist $M_c=M$, womit die erste Richtung bewiesen ist.\\
	
	Sei jetzt $c \notin U(M)$.
	Angenommen, es gelte $cM \cap Mc = M$. 
	Das führt zu $\exists d : cd = 1 \, \wedge \, \exists d': d'c=1$. Dann folgt dass, jedes $c$ ein Rechtsinverses hat und somit, dass $M$ eine Gruppe ist, woraus $c \in U(M)$ folgen würde, was ein Widerspruch ist und damit die zweite Richtung beweist.
	\bewiesen
	
	\subsection{Aperiodische Monoide}
	\subsubsection{Definition lokales Untermonoid}
	Sei $M$ eine Halbgruppe  und $E(M) = \{e \in M \mid e^2 = e\}$. Dann ist das lokale Untermonoid bei $e$ (für $e \in E(M)$) definiert durch die Menge $eMe$.
	Die Abgeschlossenheit und die Existenz eines neutralen Elementes kann man folgenderma\ss en sehen:
	\begin{align*}
		exe \cdot eye = e \cdot (xeey) \cdot e \quad \implies exe \cdot eye \in M\\
		e(exe) = (ee)\cdot(xe) = exe = (ex)\cdot (ee) = (exe)e\quad \implies e \text{ ist neutral}
	\end{align*}
	
	Falls $M$ ein Monoid ist und $e\not = 1$, dann gilt $eMe \subsetneq M$.
	
	\subsubsection{Satz: Zusammenhang von Divisoren und Aperiodizität}
	Sei $N$ ein Divisor von $M$, dann gilt: $$M \text{ ist aperiodisch} \implies N \text{ ist aperiodisch}$$
	
	\section{Satz von Schützenberger - Vorlesung 12}
	\subsection{Vorbereitungen}
	\subsubsection{Satz: Aperioditzität von sternfreien Konkatenationen}
	\label{sec:aperiodisch_konkat}
	Seien $L_1, L_2 \in \starfree(\aast)$.
	Für $i \in \{1,2\}$ seien
	 $t_i \in \N$ gewählt mit $\forall u \in \aast: u^{t_{i +1}} \equiv_{L_i} u^{t_i}$.
	Dann gilt $$u^{t+1} \equiv_K u^t$$ für $t = t_1 +t _2 +1$ und $K = L_1 \cdot L_2$.
	
	\subsubsection{Beweis des Satzes}
	Für den Beweis ist, unter Annahme der Voraussetzung, zu zeigen, dass
	\begin{align*}
		\forall x,y \in \aast: xu^{t+1}y \in \iff  xu^{t}y \in K
	\end{align*}
	gilt.\\
	
	Dafür sei $s \in \{t, t+1\}$ und $xu^sy \in K$. Nun existieren drei Fälle für die Trennung des Wortes $xu^sy$: 
	\begin{enumerate}[label= \arabic*.]
		\item $x=u_1x'$ mit $x'u^sy \in L_2$ und $u_1 \in L$. In diesem Fall folgt $xu^{s\pm1}y \in L_1L_2$. 
		\item $y = y'u_2$ mit $xu^sy' \in L_1$ und  $u_2 \in L_2$. Dieser Fall funktioniert analog zu 1..
		\item $xu^sy = xu^{s_1}u'u''u^{s_2}y$ mit $xu^{s_1}u' \in L_1$ und $u''u^s_2y \in L_2$, sowie $u'u'' = u$. In diesem Fall muss nun $s_i \geq t_i$ für ein $i \in \{1,2\}$ gelten, da $s_1 + s_2 + 1 = s$ gilt.
	\end{enumerate}
	
	\bewiesen
	
	\subsubsection{Folgerung des Satzes}
	Sei weiter $L \subseteq \aast$ mit $\varphi\inv(\varphi(L))= L$ für einen erkennenden Hom. $\varphi: \aast \to N$, wobei $|N| < \infty$ gilt und $N$ aperiodisch ist. \\
	Dann ist das $\synt(L)$ ein Divisor von $N$ und damit auch aperiodisch. 
	
	\subsection{Satz und Beweis}
	\subsubsection{Satz von Schützenberger}
	Für ein Alphabet $A$ gilt: 
	\begin{align*}
		L \in \starfree(A) &\iff L \text{ wird von einem endlichen aperiodischen Monoid erkannt } \\ 
		&\iff \synt(L) \text{ ist aperiodisch }
	\end{align*}
	
	\subsubsection{Beweis des Satzes - Erste Richtung}
	Wir beweisen die erste Richtung einzeln für die verschiedenen Möglichkeiten der sternfreien Sprachen.\\
	
	Sei $L \in \starfree(A)$ und $|L| < \infty$.
	In diesem Fall folgt, dass $\synt(L)$ aperiodisch ist, da man den threshold $t$ auf eine Zahl setzten kann, die grö\ss er ist als die Länge des längsten Wortes.\\
	
	Seien nun $L_1, L_2 \in \starfree(A)$ und seien für $i \in \{1,2\}$
	\begin{align*}
		\varphi_{i} : \aast \to N_i
	\end{align*} erkennende Hom. mit $\varphi_i\inv\varphi_{i}(L_i) = L_i$, wobei $N_i$ endlich und aperiodisch ist.
	Es folgt nun, dass auch $N_1 \times N_2$ endlich und aperiodisch ist. Wir setzen 
	\begin{align*}
		\varphi: \aast &\to N_1 \times N_2 \\
		u &\mapsto (\varphi_1(u), \varphi_2(u))
	\end{align*} 
	und sehen nun, dass $\varphi$ sowohl $L_1, \,L_2,  \, L_1 \cap L_2,   \,L_1 \cup L_2,$ als auch $\aast \setminus L_i$ für $i \in \{1,2\}$ erkennt.
	Das bedeutet, dass auch diese Sprachen alle aperiodisch sind.\\
	
	Au\ss erdem folgt aus der Aperiodizität der syntaktischen Monoide von $L_1, L_2 \in \starfree(A)$ mit den Erkenntnissen aus Abschnitt~\ref{sec:aperiodisch_konkat}, dass $\synt(L_1 \cdot L_2)$ aperiodisch ist. \\
	
	Damit ist die erste Richtung des Satzes für alle Fälle bewiesen. 
	
	\subsubsection{Lemma: Erzeugende aperiodischer Monoide \label{Lemma:Schütz}}
	Sei $M$ aperiodisch und gelte $M \not = \{1\}$, sowie $M = \langle \Sigma \rangle$ (Das bedeutet, $M$ wir von einer endlichen Teilmenge $\Sigma$ erzeugt.). 
	Dann gibt es ein $c \in \Sigma$ mit $1 \not \in cM \cap Mc$.
	
	\subsubsection{Beweis des Lemmas}
	Sei $w \in McM$ mit $w = 1$ für ein Element $c \in \Sigma$. Dann gilt $w = ucv$ für Elemente $u,v \in M$ und es folgt: 
	\begin{align*}
		ucv = 1 &\implies uc(ucv)v = 1 \\
		&\implies 1 = (uc)^t v^t \quad |\, t\text{ ist hier der threshold des Monoids}\\
		&\implies 1 = (uc)^t v^{t+1} \\
		&\implies v = 1
	\end{align*}
	Analog dazu gilt auch $ucv = 1 \implies u = 1$. Also folgt $w = 1 \implies c = 1$. 
	Da nun $M \not= \{1\}$ gilt, existiert ein $c = \Sigma$ mit $c \not = 1$. Angenommen es gibt eine $1 \in cM \cap Mc \subseteq McM$, dann ist $c = 1$, was einen Widerspruch ergibt.
	\bewiesen
	
	\subsubsection{Beweis des Satzes (Schützenberger) - Zweite Richtung}
	Für die zweite Richtung ist $\synt(L)\text{ ist aperiodisch} \implies L \in \starfree(A)$ zu zeigen.\\
	Sei also nun $M$ aperiodisch und endlich. Weiter sei $\varphi: \aast \to M$ ein surjektiver Hom.. 
	Wir betrachten nun die Elemente, die auf 1 abgebildet werden $A_1 = \{a \in A \mid \varphi(a) = 1\}$.
	Dann folgt aus dem Lemma \ref{Lemma:Schütz}, dass $$\varphi\inv(1) = \aast_1\, ,$$ sowie $\aast_1 \in \starfree(A)$, wegen
	\begin{align*}
		\aast_1 = A \setminus \bigcup \{\aast a \aast \mid  a \in A \setminus A_1\} \in \starfree(A)
	\end{align*}
	und $\aast = \aast \setminus \emptyset$ und $\emptyset \in \starfree(A)$ gilt.
	\newline
	
	Wir nehmen nun ohne Einschränkung an, dass $A\setminus A_1 \not = \emptyset$ ist, da sonst $\synt(L) = \{1\}$ wäre. Also existiert ein $c \in A$ mit $\varphi(c) \not = 1$. Wir setzen nun $B = A \setminus \{c\}$ und damit ist $|B| < |A|$, sowie $|\varphi(c)M \cap M\varphi(c)|< |M|$. \\
	
	Der Beweis wird nun durch Induktion nach $(|M|, |A|)$ mit lexikographischer Ordnung geführt. \\
	Die lexikographische Ordnung funktioniert folgenderma\ss en. Es gilt
	\begin{align*}
		(|M'|, |A'|) \leq (|M|, |A|) \iff |M'| < |M|\quad \text{(\textit{Giant-Step})}
	\end{align*}
	und  
	\begin{align*}
		(|M'|, |A'|) \leq (|M|, |A|) \iff |M'| = |M| \wedge |A'| \leq |A|  \quad \text{(\textit{Baby-Step})}.
	\end{align*}
	\newline
	
	Es gilt $\varphi\inv\varphi(L) = \bigcup \{\varphi\inv(p) \mid p \in \varphi(L)\}$. Daher reicht es, $ \varphi\inv(p) \in \starfree(A)$ für $p \in \varphi(L)$ zu zeigen, um $L \in \starfree(A)$ zu beweisen. \\ 

	
	Da wir oben schon gesehen haben, dass $\aast_1 \in \starfree(A)$ gilt, zeigen wir nur noch $\varphi\inv(p) \in \starfree(A)$ für $p \not = 1$.  \\
	
	Es gilt $$\varphi\inv(p) = \bigcup \{\varphi\inv (s) c \varphi\inv(r) \mid s\varphi(c)r = p, \, \varphi(c) \not = 1, \, c \in A\}\, .$$
	Sei nun $c\in A$ fest gewählt mit $\varphi(c) \not = 1$. Dann müssen wir nun zeigen, dass $\varphi\inv(s)c\varphi\inv(r) \in \starfree(A)$ gilt. 
	\newline
	
	Wir nehmen hier nun ohne Einschränkung an, dass $\aast \cap M = \{1, c\}$ und $\varphi(c)=c$ gilt, was durch mengentheoretisches Umbenennen erreicht werden kann. \\
	Nun sei $\aast = \bast \cup \bast (c \bast) c \bast$ für $B = A \setminus \{c\}$.
	Dann zeigen wir $\varphi\inv(p) \cap \bast(c\bast)^\ast c\bast \in \starfree(A)$. 
	Es gilt:
	\begin{align*}
		\varphi\inv(p) \cap \bast(c\bast)^\ast c\bast = \bigcup \{(\varphi\inv(q) \cap \bast)(\varphi\inv(r)\cap(c\bast)^\ast c) (\varphi\inv(s) \cap \bast) \mid p = qrs\}
	\end{align*} 
	Es folgt $\varphi\inv(q) \cap \bast \in \starfree(B) \subseteq \starfree(A)$ nach \textit{Baby-Step-Induktion}, da $|B| < |A|$ gilt. 
	Gleiches gilt für $\varphi\inv(q) \cap \bast$.
	\newline
	
	Es reicht also, wenn wir uns auf den mittleren Teil, $(\varphi\inv(r)\cap(c\bast)^\ast c)$, konzentrieren und zeigen, dass $\varphi\inv(p) \cap (c\bast)^*c \in \starfree(A)$ für alle $p \in M$ gilt. \\
	
	Man kann sich den Zusammenhang der benutzten Monoide an der folgenden Abbildung verdeutlichen, wobei 
	 $$T = \{[v] \mid  [v] = \varphi(v), \, v \in \bast\} \subseteq M$$ ein endliches Alphabet ist, $\psi$ durch $$\psi[v] = c\varphi(v)c \in cM \cap Mc$$ definiert ist und $\sigma$ durch
	$$\sigma(cv_1 \cdots cv_k) = [v_1] \cdots [v_k] \in T^k \subseteq T^\ast\, .$$
	
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[node distance=5.5cm, auto]
			\node (cb) {$(c\bast)^\ast$};
			\node (t) [right of=cb] {$T^\ast$};
			\node (xm) [below of=cb] {$\{x \in M \mid xc \in cM\}$};
			\node (mc) [right of=xm] {$M_c = (cM\cap Mc, \circ, c)$};
			
			\draw[->] (cb) -- (t) node[ midway,sloped,above,rotate=0] { $\sigma$};
			\draw[ ->] (cb) -- (xm) node[ midway,right,rotate=0] { $\varphi$};
			\draw[ ->] (xm) -- (mc) node[ midway,above,rotate=0] { $\rho_c$};
			\draw[ ->] (t) -- (mc) node[ midway,right,rotate=0] { $\psi$};
		\end{tikzpicture}
	\end{figure}
	
	Um nun $\varphi\inv(p) \cap (c\bast)^*c \in \starfree(A)$ zu zeigen, betrachten wir $$\varphi\ast(p) \cap (c\bast)^\ast c = \bigcup \{\varphi\inv(q) \cap (c\bast)^\ast\mid qc = p\}c\, .$$
	Dann wählen wir ein festes $q \in \varphi(c\bast)^\ast$ und zeigen $(\varphi\inv(q) \cap (c\bast)^\ast)c \in \starfree(A)$. \\ 
	Es gilt: 
	\begin{align*}
		w \in \varphi\inv(q) \cap (c\bast)^\ast c \iff w = vc \text{ für ein } v \text{ mit } \varphi(v) = q
	\end{align*} 
	Also ist $\rho_c\varphi(v) = q \cdot c$ und $v =cv_1 \cdots cv_k$ mit $k \geq 0$, wobei die $i \in \bast$ eindeutig sind. 
	Weiter gilt dann $\sigma(v) = [v_1] \cdots [v_k] \in T^k \subseteq T^\ast$ mit 
	\begin{align*}
		\psi\sigma(v) &= [cv_1c] \circ \ldots \circ [cv_kc] \\
		&= cv_1 \cdots cv_kc \\
		&= \varphi(v) \cdot c \\ 
		&=\rho_c \varphi(v) \\
		&= qc \in M_c = cM \cap Mc
	\end{align*}
	\newline
	
	Nach einem Schritt der \textit{Gigant-Step- Induktion} gilt $\psi\inv(qc) \in \starfree(T)$, da $|M_c| < |M|$. Beachte: es gilt $|T| \leq |M|$.\\
	Es bleibt jetzt nur noch zu zeigen, dass 
	$$ K \in \starfree(T) \implies \sigma\inv(K) \in \starfree(A)$$
	gilt.\\
	Es gilt $K = \{1\} \implies \sigma\inv(1) \cap (c\bast)^\ast = \{1\} \in \bast$ und $\{1\} \in \starfree(A)$.
	\newline
	
	Nun sei $t \in T$. Dann ist $\sigma\inv(t) \in \starfree(A)$, denn 
	\begin{align*}
		w \in \sigma\inv(t) \cap(c\bast)^\ast \iff w = cv \text{ mit } v \in \bast \text{ und } v \varphi(v)c = t\, .
	\end{align*} 
	Mit \textit{Bayb-Step-Induktion} gilt $\{v \in B^\ast \mid c \varphi(v)c = t\} \in \starfree(B) \subseteq \starfree(A)$. 
	Wir wissen nun also, dass Buchstaben und das leere Wort in $\starfree(A)$ sind.\\
			
	Weiter gilt für die Vereinigung $\sigma\inv(K_1 \cap K_2) = \sigma\inv(K_1) \cup \sigma\inv(K_2)$, sowie für das Komplement $\sigma\inv(T^\ast \setminus K_1) = (c\bast)^\ast \setminus K_1$, dass diese Mengen dann auch sternfrei sind, denn $(c\bast)^\ast = c \aast$.\\
	Um das auch für die Konkatenation zu zeigen, betrachten wir $K_1, K_2 \in \starfree(T)$. Mit struktureller Induktion gilt $\sigma\inv (K_i) \in \starfree(A)$ für $i \in \{1,2\}$.
	Es folgt $\sigma\inv(K_1K_2) \in \starfree(A)$, da $\sigma\inv(K_1K_2) = \sigma\inv(K_1) \sigma\inv(K_2) \in \starfree(A)$. 
	\bewiesen
	
	\section{Halbgruppentheorie Teil 2 - Vorlesung 13}
	\subsection{Green's Relations Teil 2}
	
	\subsubsection{Beziehungen von lokalen Divisoren und Green's Relations}
	Für ein endliches Monoid $M$ gelten die  folgenden Zusammenhänge:
	\begin{enumerate}
		\item $x \in cM \cap Mc \iff x \lgreheq c$
		\item $c \notin U(M) = \{x \in M \mid \exists y:\, xy=1\} \iff |M_c| < |M|$
		\item  $M_c \text{ ist Divisor, vermöge } \rho_c: \{x \in M \mid xc \in cM\} \to  M_c,\, \rho_c(x) \mapsto xc$.
	\end{enumerate}
		
	
	\subsubsection{Strukturelle Aussagen über Green's Relations}
	Für ein endliches Monoid $M$ gelten die  folgenden Sätze:
	\begin{enumerate}[label = \alph*)]
		\item  \label{Aussage1}$(\hcal(c), \circ, c) = U(M_c, \circ, c)$. Man nennt das das Schützenberger Produkt auf $\hcal(c)$.
		\item  \label{Aussage2} Sei $s \grer t$ mit $s = tu \land t = sv$. Dann gilt $\rho_v: M_s \to M_t, \, x \mapsto xv$ ist ein Isomorphismus von $(sM \cap Ms, \circ, s)$ auf $(tM \cap Mt, \circ, t)$.
		\item  \label{Aussage3} Sei $s = tu$, $t = sv$ und $s \grej t$, sowie $s \grer t$. Dann ist $\rho_v: \lcal(s) \iso \lcal(t)$ eine Bijektion. 
		\item  \label{Aussage4} Sei $s \grer t$ mit $s = tu \land t = sv$. Dann gilt $\rho_c$ respektiert die $\hcal$-Klassen. Das bedeutet, es gilt $\hcal(x)v = \hcal(xv)$.
	\end{enumerate}
	
	\subsubsection{Beweis der Aussage \ref{Aussage1}}
	Für die erste Richtung sei $x \in \hcal c $, also $x \greh c $. Es folgt $c = yx$ und $yc \in Mc$.
	Wegen $cM = xM$ folgt weiter:
	\begin{align*}
		 yc \circ x = yc = c 
		\implies x \in U(M_c, \circ, c)
	\end{align*}
	Für die andere Richtung sei $x = x'c = cx'' \in U(M_c)$. Dann gilt: 
	\begin{align*}
		 \exists y'c = c y'' :\, (x'c)y'' = y'(cx'') =c 
		&\implies c \lgreheq x \\
		&\implies x \greh c \quad| \text{ wegen } x \in M_c \text{ und damit } x \lgreheq c
	\end{align*}
	\bewiesen
	
	\subsubsection{Beweis der Aussage \ref{Aussage2}}
	\label{sec:beweis_aussage_b}
	Sei $x = x's = sx''$ und $\rho_v(x) = xv$.
	Dann gilt $xv = x'sv \in Mt$. Ferner gilt $xv = sx''v = tux''v \in tM$. 
	Es folgt dann $\rho_s(M_s) \subseteq Mt$. 
	Nun ist $\rho_v$ ein Hom., wegen der Gleichheit von  
	\begin{align*}
		\rho_v(x's)\circ \rho_v(y's) &= x'sv \circ y'sv \\
		&= x't \circ y'sv\\ 
		&= x'y'sv \\
		&= x'y't
	\end{align*}
	und 
	\begin{align*}
		\rho_v(x's \circ y's) &= \rho_v(x'y's) \\
		&= x'y'sv \\
		&= x'y't\, .
	\end{align*}
	Um nun noch zu zeigen, dass $\rho_v$ ein Isomorphismus ist, betrachten wir $x = x's \in M_s$. Dann gilt: 
	\begin{align*}
		\rho_u\rho_v(x) &= \rho_u(x'sv) \\
		&= x'svu \\
		&= x'tu \\
		&=x's \\
		&\implies \rho_v \text{ ist injektiv}
	\end{align*}
	Analog dazu kann man zeigen, dass auch $\rho_u: Mt \to Ms$ injektiv ist. Also folgt $\rho_u\rho_v = \rho_v\rho_u = id$, was bedeutet, dass $\rho_v$ bijektiv und damit ein Isomorphismus ist.
	\bewiesen
	
	\subsubsection{Beweis der Aussage \ref{Aussage3}}
	Sei $x \grel s$ und damit $Mx = Ms$. Dann folgt $Mxv = Msv = Mt$. Nun ist $\rho_v$ bijektiv, da $\rho_u\rho_v = id$ gilt (vgl. Abschnitt~\ref{sec:beweis_aussage_b}).
	\bewiesen
	
	\subsubsection{Beweis der Aussage \ref{Aussage4}}
	Sei $x\grel s$. Dann folgt  $ xv \grel sv \grel t$ und damit gilt $xv \grej t$. In Kombination mit $xv \lgrereq x$ und dem Lemma aus Abschnitt~\ref{sec:jklassen} (im Buch 7.42) folgt dann $xv \grer x$. \\
	
	 Für den weiteren Beweis, veranschaulichen wir die verschiedenen Klassen in einem sogenannten Eggbox Diagramm in Abbildung~\ref{fig:eggbox}. Die ``Zeilen'' entsprechen dabei verschiedenen $\rcal$-Klassen, die ``Spalten'' den $\lcal$-Klassen und die einzelnen ``Zellen'' den $\hcal$-Klassen.
	%Sorry dass das hässlich is aber ich bekomme es nicht hin dass es zentriert in der Seite eingebettet ist :(
	%Wegen mir können wir das auch raus lassen
	
	%No, ist mir egal, ob die Graphik zentriert ist, solange sie die Information überbringt, die sie soll.
	
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[every fit/.style={inner sep=0pt, outer sep=0pt, draw}]
			
			\begin{scope}[yshift=1.5cm,y=1cm]
				\node [fit={(0,2) (1,3)}, label={[align=left] $\lcal$- Klasse \\ $\quad \quad \downarrow$}] {$s$}; 
			\end{scope}
			
			\begin{scope}[yshift=0.5cm,y=1cm]
				\node [fit={(0,1) (1,3)}, label=center:{$\vdots$}] {};
			\end{scope}
			
			\begin{scope}[yshift=0.5cm,y=1cm]
				\node [fit={(0,0) (1,1)}, label=below:{}] {$x$};
			\end{scope}
			
			\begin{scope}[yshift=3.5cm,y=1cm]
				\node [fit={(1,0) (4,1)}, label=center:{$\cdots$}] {};
			\end{scope}
			
			\begin{scope}[yshift=3.5cm,y=1cm]
				\node [fit={(1,-3) (4,-2)}, label=center:{$\cdots$}] {};
			\end{scope}
			
			\begin{scope}[yshift=3.5cm,y=1cm]
				\node [fit={(4,0) (5,1)}, label=below:{}] {$t$};
			\end{scope}
			
			\begin{scope}[yshift=3.5cm,y=1cm]
				\node [fit={(4,0) (5,-2)}, label=center:{$\vdots$}] {};
			\end{scope}
			
			\begin{scope}[yshift=3.5cm,y=1cm]
				\node [fit={(4,-2) (5,-3)}, label=right:{$\leftarrow \rcal$- Klasse }] {$xv$};
			\end{scope}
			
			\begin{scope}[yshift=2.5cm,y=1cm]
				\node [fit={(1,-1) (4,1)}] { $\vdots$};
			\end{scope}
			
		\end{tikzpicture} 
		
		\caption{Eggbox Diagram}
		\label{fig:eggbox}
	\end{figure}

	Nun folgt $ xv \grer x \sim y \grer yv$ aus $x \grer y$ und 
	$xv \grel t \grer yv$ aus $x \grel y$ und damit folgt die Behauptung. 
	\bewiesen
	
	\subsubsection{Korrolar: Isomorphismen für $\hcal$-Klassen}
	Seien $s\grej t \in M$ und $M$ endlich. Dann gilt $\dcal = \jcal$ und $\exists z: s \grer z \grel t$ und damit $s = zv$ und $t =uz$. \\
	Dann gibt es Isomorphismen $\lambda_u, \rho_v$ mit $\lambda_u\inv \rho_v:\, (\hcal(s), \circ, s) \to (\hcal(t), \circ, t)$.
	
	\subsubsection{Beweis des Korrolars}	
	Aus den Isomorphismen zwischen $\hcal(s)$ und $\hcal(z)$, sowie $\hcal(t)$ und $\hcal(z)$, die in Abbildung~\ref{fig:isos} abgebildet sind, folgt direkt die gewünschte Eigenschaft des Isomorphismus zwischen $\hcal(s)$ und $\hcal(t)$.
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[node distance=3.5cm, auto]
			\node (lam) {$(\hcal(s), \circ, s)$};
			\node (ht) [right of=lam] {$(\hcal(t), \circ, t)$};
			\node (hz) [below of=lam] {$(\hcal(z), \circ, z)$};
			
			\draw[->] (lam) -- (ht) node[ midway,sloped,above,rotate=0] { $\sim$};
			\draw[] (lam) -- (ht) node[ midway,sloped,below,rotate=0] { $\lambda_u\inv\rho_v$};
			\draw[  ] (lam) -- (hz) node[midway,sloped, above, rotate=0] { $\sim$};
			\draw[ ->] (lam) -- (hz) node[ midway,left=.2,rotate=0] { $\rho_v$};
			\draw[ ->] (ht) -- (hz) node[ midway,right=.2cm,rotate=0] { $\lambda_u$};
			\draw[  ] (ht) -- (hz) node[midway,sloped, above, rotate=0] { $\sim$};
		\end{tikzpicture}
		\caption{Isomorphismen zwischen $\hcal$-Klassen}
		\label{fig:isos}
	\end{figure} 
	
	\subsubsection{Definition Regulär}	
	Ein Element aus einem Monoid $s \in M$ hei\ss t regulär, falls $\exists r \in M: srs = s$ gilt. 
	
	\subsubsection{Lemma: Zusammenhang zwischen Idempotenz und Regularität}
	\label{sec:idempotent_und_regulär}
	Für ein Element $s \in M$ gelte $srs=s$. Dann gilt $s\grer sr$ und $(sr)^2 = sr \in E(M)$.	
	
	\subsubsection{Beweis des Lemmas}
	Sei $srs=s$. Dann folgt $sr \lgrereq s$ und $sr \lgrereq srs = s$. Das bedeutet, es gilt $s \grer sr$. Damit folgt $(sr)(sr) = (srs)r = sr \in E(M)$.
	\bewiesen
	
	\subsubsection{Satz: Aussagen über $\dcal$-Klassen}
	Für ein endliches Monoid $M$ sind die folgenden Aussagen äquivalent für eine $\dcal$-Klasse D: 
	\begin{enumerate}[label=\arabic*.)]
		\item $D$ ist regulär $:\iff \exists s \in D$  $\exists r \in M$ : $srs = s$ (d.h $\exists s \in D$ und $s$ regulär)
		\item $\exists e \in E(M)$ und $e \in D$
		\item $\forall s \in D: s$ ist regulär
		\item Jede $\lcal$-Klasse von $D$ und jede $\rcal$-Klasse von $D$ enthält ein Idempotent
	\end{enumerate}
	
	\subsubsection{Beweis des Satzes}
	Sei 1.) wahr. Es gibt also $srs = s$ mit $s \in D$. Dann gilt $s \grer sr$ und $sr=e \in E(M)$ nach Abschnitt~\ref{sec:idempotent_und_regulär}. Daraus folgt: 
	\begin{align*}
		 \exists e \in M: e \grer s \wedge e^2 = e 
		&\implies s \in eM \\
		&\implies es = s \quad | \text{ da } s=es' \text{ und } es = ees' = es' = s
	\end{align*}
	Somit gilt also 2.).
	\newline
	
	Wir zeigen jetzt $e^2 = e \grer s$. Betrachte dazu $e=sr$. Dann gilt $ s = es = srs$. Daraus folgt, dass $s$ regulär ist und somit, dass alle Elemente, die $\rcal$-äquivalent zu $e$ sind, regulär sind.
	Analog kann man das Gleiche für $\lcal$ zeigen. \\
	Insgesamt gilt das also auch für $\dcal$ und damit gilt 3.).
	\newline
	
	Nun existiert $s \in D$ regulär und somit folgt, dass $\rcal(s)$ und $\lcal(s)$ eine Idempotenz enthalten. \\
	Damit gilt 4.).
	
	\subsubsection{Satz: Reguläre $\dcal$-Klassen}
	Seien $s,t \in D$ für eine $\dcal$-Klasse $D$ und sei $M$ endlich. Sei weiter $st \in D$. Dann ist $D$ regulär und es gilt $st \in \rcal(s) \cap \lcal(t)$. 
	Ferner gilt $\exists e \in \lcal(s) \cap \rcal(t):\, e^2=e$ und somit $ st \in \rcal(s) \cap \lcal(t)$.
	Abbildung~\ref{fig:d_klassen} veranschaulicht dies, wobei Idempotente in Eggbox Diagrammen mit * gekennzeichnet werden.
	\begin{figure}[H]
		\centering
		\begin{tikzpicture}[every fit/.style={inner sep=0pt, outer sep=0pt, draw}]
			
			\begin{scope}[yshift=1.5cm,y=1cm]
				\node [fit={(0,2) (1,3)}] {$s$}; 
			\end{scope}
			
			\begin{scope}[yshift=0.5cm,y=1cm]
				\node [fit={(0,1) (1,3)}, label=center:{$\vdots$}] {};
			\end{scope}
			
			\begin{scope}[yshift=0.5cm,y=1cm]
				\node [fit={(0,0) (1,1)}, label=below:{}] {$e^ast$};
			\end{scope}
			
			\begin{scope}[yshift=3.5cm,y=1cm]
				\node [fit={(1,0) (4,1)}, label=center:{$\cdots$}] {};
			\end{scope}
			
			\begin{scope}[yshift=3.5cm,y=1cm]
				\node [fit={(1,-3) (4,-2)}, label=center:{$\cdots$}] {};
			\end{scope}
			
			\begin{scope}[yshift=3.5cm,y=1cm]
				\node [fit={(4,0) (5,1)}, label=below:{}] {$st$};
			\end{scope}
			
			\begin{scope}[yshift=3.5cm,y=1cm]
				\node [fit={(4,0) (5,-2)}, label=center:{$\vdots$}] {};
			\end{scope}
			
			\begin{scope}[yshift=3.5cm,y=1cm]
				\node [fit={(4,-2) (5,-3)}] {$t$};
			\end{scope}
			
			\begin{scope}[yshift=2.5cm,y=1cm]
				\node [fit={(1,-1) (4,1)}] { $\vdots$};
			\end{scope}
			
		\end{tikzpicture} 
		\caption{Position der Elemente in den Klassen}
		\label{fig:d_klassen}
	\end{figure}
	
	\subsubsection{Beweis des Satzes}
	Seien $s,t \in D$ mit $st \in D$. Dann gilt $s \grej t \grej st$, sowie $st \lgrereq s$ und $st \lgreleq t $ und damit $ st \in \rcal(s) \cap \lcal(t)$.
	Betrachte nun 
	\begin{align*}
		\rho_t : \lcal(s) &\to \lcal(st) = \lcal(t) \\
		x &\mapsto xt
	\end{align*}
	Da $\rho_t $ eine Bijektion ist, folgt, dass $\exists! e \in \lcal(s): et = t$. Ferner gilt $e \in R(t)$, da $\rho_t$ die $\rcal$-Klassen erhält. Somit gilt für ein $y$: 
	\begin{align*}
		e = ty \implies e^2 &= e(ty)  \\
		&= (et)y =ty = e
	\end{align*}
	Es folgt $ e \in E(M)$ mit $e \in \lcal(s) \cap \rcal(t)$. 
	\newline
	
	Umgekehrt sei $e^2 = e \in \lcal(s) \cap \rcal(t)$. Zu zeigen ist $st \in \rcal(s) \cap \lcal(t)$. \\
	Wegen $ t \in eM$ und $e^2 = e$ gilt $et =t$.
	Nun folgt wegen $e \in \lcal(s)$, dass $\rho_t = st \in \lcal(t)$ gilt. \\ 
	Ferner gilt $\rho_t(s) \grer s$, woraus $st \in \rcal(s) \cap \lcal(t)$ folgt.
	\bewiesen
	
\section{Monadic Second Order Logic ($\mso$) - Vorlesung 14}
\label{sec:vl14}
\subsection{Grundlagen}
\subsubsection{Allgemeines}
Wir betrachten $\mso$ hier für gerichtete Graphen mit Knotenbeschriftungen, also für Modelle $G=(V, E ,\lambda)$ mit einer Knotenmenge $V$, einer Kantenmenge $E \subseteq V \times V$ und einer Beschriftung $\lambda : V \to \Sigma$, wobei $\Sigma$ ein endliches Alphabet ist.
Das bedeutet, jeder Knoten ist mit einem Buchstaben beschriftet.\\
Zur Synatx: Wir benutzen Variablen $x$ für Elemente aus $V$ und $X$ für Teilmengen von $V$ (Monadische Prädikate).

\subsubsection{Freie Variablen}
	Die freien Variablen einer prädikatenlogischen Formel sind diejenigen, die nicht an einen Quantor gebunden sind. 
	Die Menge der freien Variablen einer Formel $\phi$ wird mit $\mathsf{FV}(\phi)$ bezeichnet.

\subsubsection{Atomare Formeln}
	Folgende Formeln sind alle atomar. In Klammern sind jeweils die freien Variablen der Formel angegeben.
	\begin{itemize}
		\item $x=y$\quad ($\mathsf{FV}(x=y)=\{x,y\}$)
		\item $\lambda(x) = a$ mit $a \in \Sigma$, alternativ auch als Prädikat $P_a(x)$ geschrieben\quad ($\fv(\lambda(x))=\{x\}$)
		\item $x$\quad ($\fv(\lambda(x)=\{x\}$)
		\item $T= true$ \quad ($\fv(T)=\emptyset$)
		\item $x \in X$\quad ($\fv(x \in  X)=\{x,X\})$
		\item $(x,y) \in E$\quad ($\fv((x,y) \in  E)=\{x,y\})$
	\end{itemize}
	

	
\subsubsection{Makros}
Wir definieren die folgenden Makros:
\begin{itemize}
	\item $(X = Y) :\iff \forall x :( x \in X \iff x \in Y)$ \quad ($\fv{(X = Y ) = \{X,Y\}}$)
	\item $(X \subseteq Y) :\iff \forall x : (x \in X \implies x \in Y)$
	\item $\phi \land \psi := \neg (\neg \phi \lor \neg \psi)$ etc. 
	\item $\forall z \phi := \neg (\exists z (\neg\phi))$
\end{itemize}

\subsubsection{Weitere $\mso$ Formeln}
	Sei $z \in \{x, X\}$ und $\phi$ eine $\mso$-Formel, dann gibt es auch die $\mso$-Formel $\exists z\phi$ mit $\fv(\exists z \phi) = \fv(\phi) \setminus \{z\}$.\\
	
	Au\ss erdem gibt es boolesche Formeln. Seien hierfür $\phi$ und $\psi$ $\mso$-Formeln. Dann sind auch $(\phi \lor \psi)$ und $\neg \phi$ $\mso$-Formeln, 
	mit $\fv(\phi \lor \psi) = \fv(\phi) \cup \fv(\psi)$ und $\fv(\neg \phi) = \fv(\phi)$.

\subsubsection{Semantik}
	Die Semantik der atomaren Formeln ist klar.\\
	Sei $\phi$ eine Formel mit $\fv(\phi)=\{x_1,\ldots, x_k, X_1,\ldots, X_l\}$. Dann ist $I: \fv(\phi) \to V \cup 2^V$ eine Interpretation, wobei $I(x_i) \in V$ und $I(X_j) \subseteq V$ für $1\leq i\leq k, 1\leq j\leq l$ gilt. \\
	
	Dann liefert die Anwendung von $\phi$ auf einen Graphen und eine Interpretation $\phi((V,E,\lambda), I)$ einen Wahrheitswert aus $\B = \{\bot, \top\}$ mit $1 = \top$ und $0 = \bot$. \\
	Für die Gültigkeit gilt dann:
	\begin{itemize}
		\item 	Falls $\phi((V,E,\lambda), I) = \top$ gilt, dann ist $(V,E,\lambda) \models_I \phi$ ein Modell für $\phi$ unter $I$. 
		\item	Falls $\fv(\phi) = \emptyset$ und $(V,E,\lambda) \models_{\emptyset} \phi$, dann hei\ss t $(V,E,\lambda)$ Modell von $\phi$ und $\phi \in \mso(V,E,\lambda)$ ist ein Satz.
	\end{itemize}

\subsection{First Order Logic ($\fo$)}
\subsubsection{Definition}
	$\fo$ ist für einen Graphen $G=(V,E,\lambda)$ ist das Fragment von $\mso$ ohne die Mengenvariablen $X$.
	
\subsubsection{Makros}
	Wir definieren die folgenden Makros:
	\begin{itemize}
		\item  Für $(x,y) \in \east$ :$\iff$ $(x,y)$ ist ein Element des reflexiven, transitiven Abschlusses von $E$. (Das bedeutet, die gerichtete Kantenmenge $E$ entspricht der Nachfolger-Relation und $\east$ der $\leq$-Relation.)
		\item $R(x,Y) := [x \in Y \land \forall z \forall z': (z \in Y \land (z,z') \in E \implies z' \in Y)]$
		\item $\east(x,y) := [\forall Y (R(x,Y) \implies y \in Y)]$ 
	\end{itemize}

\subsection{$\mso$-Theorie auf $\sigstern$}

\subsubsection{Grundlagen und Beispiel}
	Wir betrachten Modelle $(V,E,\lambda)$ mit $V= \{1, \ldots, n\}$ und $E=\{(i, i+1) \mid 1 \leq i < n\}$, sowie $\lambda: \{1, \ldots n\} \to \Sigma$.\\


	Dann entsprechen Wörter jeweils Graphen.
	Zum Beispiel wäre das Wort $abcd$ ein Graph $ 1 \to 2 \to 3 \to 4$ mit $\lambda(1) = a$, $\lambda(2) = b$, $\lambda(3) = c$  und $\lambda(4) = d$. \\ 
	Dann ist $\east$ die $\leq$-Relation auf $\{1, \ldots, n\}$.\\
	Für die Beispielformel $$\phi = \exists x,y: \lambda(x) = b \land \lambda(y) = d \land x \leq y$$ und das Wort $abcd$ gilt $abcd \models \phi$, also $abcd$ ist ein Modell für $\phi$.

\subsubsection{Satz: Zusammenhang von $\mso$ und regulären Sprachen}
	Sei $L \subseteq \sigstern$. Dann gilt 
	\begin{align*}
	L \in \reg(\Sigma) \iff& \exists \phi \in \mso(\Sigma^\ast) \text{ mit } \fv(\phi) = \emptyset \text{ und } L=L(\phi) = \{w \mid w \models \phi \}\\
	\iff& \exists \psi(\Sigma^\ast) \in \mso  \text{ mit } \fv(\psi) \subseteq \{X_1, \ldots, X_n\}, \psi \text{ ist quantorenfrei und }\\ &L=L(\exists X_1 \ldots \exists X_n : \psi) 
	\end{align*}


\subsubsection{Beweis des Satzes - Erste Richtung}
	Sei $L= L(A)$ für einen NFA $A= (Q, \Sigma, \delta, I, F)$. Wir konstruieren jetzt $\phi \in \mso$ mit: $$w \in L(A) \iff w \models \phi$$
	Sei dafür $w = a_1 \ldots a_n$ mit $a_i \in \Sigma$ für $1\leq i \leq n$. Dann ist also $V = \{1, \ldots, n\}$ und $E=\{(i, i+1) \mid 1 \leq i <n\}$, sowie $\lambda(i) = a_i$.\\
	Es gelte $Q = \{0, \ldots, m\}$. Dann existieren Mengenvariablen $X_0, \ldots, X_m$, sodass wir $\phi$ folgenderma\ss en setzen können:
	$$\phi = \Bigl\lbrack(\exists X_q : 1 \in X_q \land q \in I) \land (\exists X_q : n \in X_q \land q \in F) \land  (\bigwedge_{p, q \in Q} (p \not = q \implies X_p \cap X_q = \emptyset))$$
	$$ \forall x \forall y ( \bigwedge_{p, q, a} (x \in X_p \land \lambda(x)= a \land (x,y \in E)) \implies  \bigvee_{(p,q,a) \in \delta} y \in X_q)\Bigr\rbrack$$
	Damit ist die erste Richtung bewiesen.

\subsubsection{Vorbereitungen für zweite Richtung des Beweises}
Wir führen folgende Preprocessing-Schritte durch, um den Beweis zu vereinfachen:
	\begin{enumerate}[label= \arabic*.)]
		\item Das Makro $y = x +1$ gilt dann, wenn $(x,y) \in E$ gilt und das Makro $x \leq y$ dann, wenn $(x,y) \in \east$ gilt. 
		Dabei kann man das erste Makro in $\fo[\leq]$ definieren über: 
				$$ y = x +1 \iff [x \leq y \land \forall z : (x \leq z \leq y \land x \not = z \implies z = y \land x \not= y)]$$
		\item Durch diesem und den nächsten Schritt sollen alle $\fo$-Variablen eliminiert werden. Dafür definieren wir das Makro: $$|X| = 1 \iff [X \not =\emptyset \land \forall Y : (Y \subseteq X \land Y \not= \emptyset \implies X = Y) ]$$
		Man beachte hierbei dass $\sigstern \not = \emptyset$  gilt, auch für $ \Sigma = \emptyset$, wegen $\emptyset^\ast = \{\varepsilon\}$.\\
		Weiter definieren wir das Makro:
		$$X=\emptyset :\iff (\forall Y: X \subseteq Y)$$
		\item Wir führen neue atomare Formeln ein(Achtung DAM Seite 223 Druckfehler): 
			\begin{itemize}
				\item $X < Y :\iff [\forall x \forall y : x \in X \land y \in Y \implies x < y]$
				\item $a\in X :\iff [\exists x \in X \land \lambda(x)=a] $
			\end{itemize}
		\item Boolsche Kombinationen von $\mso$-Formeln sind ''harmless'', da $\reg(\sigstern)$ eine boolsche Algebra ist.
	\end{enumerate}

\subsubsection{Beweis des Satzes - Zweite Richtung}
	Für diese Richtung ist zu zeigen, dass $L \in \reg(\Sigma)$ gilt für $L=\varphi(L)$ für eine $\mso$-Formel $\varphi$. 
	Man beachte, dass ohne Einschränkung folgende Form für $\varphi$ angenommen werden kann: $\varphi = Q_1X_1\ldots Q_nX_n\psi$ mit $\psi$ ist quantorenfrei, 
	$\fv(\psi) \subseteq \{X_1, \ldots, X_n\}$ und $Q_i \in \{\forall, \exists\}$.
	Also können wir davon ausgehen, dass sich $\varphi$ in Pränexnormalform befindet. $\psi$ benutzt nur boolesche Kombinationen, sowie die atomaren Formeln
	$X_i \subseteq X_j$, $a \in X_i$ und $X_i < X_j$. \\
	
	Wir definieren nun für $n \geq 0$ ein neues Alphabet $\Gamma_n = (\Sigma \times \{0,1\}^n)$. Somit hat $w' \in \Gamma_n$ dann $n+1$ Spuren mit $w_0' \in \Sigma$ und $w_1', \ldots, w_n' \in \{0,1\}$. Dann gilt für Worte aus $\Gamma_n^l$ Folgendes:  $w \in \Gamma_n^l = (w_0, w_1, \ldots, w_n)$ mit $w_0 \in \Sigma^l$ und $w_i \in \B^l = \{0,1\}^l$. 
	\newline
	
	Es gilt $\Gamma_0 = \Sigma$. 
	Mit Induktion nach $n$ zeigen wir nun : \\
	Es existiert ein NFA $A_n$ mit $L(A_n) = L(\psi) \subseteq \Gamma_n^\ast$. Hierfür interpretieren wir die Mengenvariablen $X_i$ durch Teilmengen $I(X_i) \subseteq \Gamma^l$ für alle $l$.
	Dann ist $I(X_i) = \{w \in \Gamma_n^l \mid w_i(X)= 1\}$, wobei $$w_i(X) = 1 \iff \lambda_i(w_i) = 1$$ mit $\lambda_i$ als Beschriftung der $i$-ten Spur gilt.
	\newline
	
	Wir beginnen die Induktion mit $n= 0$. Dann gilt $\fv(\psi) = \emptyset$. Die einzige atomare Formel ist dann $\top = true$, also folgt $L(A_n) = \sigstern$.\\
	
	Sei nun $n \geq 1$. Es müssen dann Automaten für die folgenden atomaren Formeln konstruiert werden: $\top, X_i \subseteq X_j$, $a\in X_i$ und $X_i < X_j$. Diese Automatenkonstruktion ist in DAM nachzulesen.
	Dann verbleibt nur noch, einen Automaten für $\exists X_n  \psi (X_1, \ldots, X_n)$ zu finden.
	Den Allquantor muss man nicht weiter betrachten, da $\forall X_n \psi = \neg (\exists X_n(\neg\psi))$ gilt und $\reg(\sigstern)$ unter Komplement abgeschlossen ist.
	\newline 
		
	Es wurde ein Automat $A_n$ mit $L(A_n) \subseteq \Gamma_n^\ast$ und $L(A_n) = L(\psi)$ konstruiert. Sei $A_n=(Q,\Gamma_n, \delta, I, F)$. Wir konstruieren $A_{n-1} = (Q, \Gamma_{n-1}, \delta', I, F)$. 
	Es gilt $\delta \subseteq Q \times \Gamma_n \times Q$. Wir definieren nun $$(p, w ', q) \in \delta' :\iff \exists b \in \{0,1\}: (p, \binom{w'}{b}, q) \in \delta\, .$$
	Dann gilt $L(A_{n+1}) = L(\exists X_n \psi)$. Nach $n$ Iterationen erhalten wir einen NFA $A_0$ mit $L(A_0) \subseteq \Gamma_0^\ast = \sigstern$ und 
	\begin{align*}
		L(A_0) &= L(Q_1X_1\ldots Q_nX_n : \psi) \\
		&=L(\varphi)
	\end{align*}
	\bewiesen
	
\section{$\fo \implies \starfree $ und das Splitting Lemma - Vorlesung 15}

\subsection{Allgemeines}
	Für $\sigstern$ gilt: $$\ap = \starfree = \fo[\leq] = \fo^3[\leq] = \ltl = \tl[UX]$$ \\
	Hierbei steht $\ltl$ für Lineare Temporale Logik, $\tl[UX]$ ist die Temporale Logik mit $XU$ (next until) als einzigem Operator und $\fo^3[\leq]$ ist das Fragment der First-Order Logik, das nur drei Variablenbezeichnungen benutzt.\\
	
	In diese Kapitel soll der Teil $\fo[\leq] \implies \starfree$ gezeigt werden. Für eine Sprache $L \subseteq \sigstern$, die in $\fo[\leq]$ definierbar ist, folgt $L \in \sf(\sigstern)$. 
	Modelle für $\fo[\leq]$ sind dann Wörter $w \in \sigstern$ mit $$w = (\{1, \ldots, |w|\}, \{(i,j) \mid 1 \leq i \leq j \leq |w|\}, \lambda)$$
	Für die atomare Formel ``$\lambda(x) =a$'' schreiben wir $w(x) = a$.
	Die übrigen atomaren Formeln und Makros aus Kapitel~\ref{sec:vl14} gelten weiterhin.

\subsubsection{Beispiel}
	Gegeben sei die $\fo[\leq]$-Sprache $L = b\sigstern bb \sigstern a $. 
	Diese kann man als $\starfree$-Sprache schreiben, durch $L = b \sigstern \cap \Sigma^+bb\Sigma^+ \cap \sigstern a$.

\subsection{Das Splitting Lemma}
\subsubsection{Aussage des Splitting Lemma}
	Sei $L \in \starfree(\sigstern)$ und seien $A, B \subseteq \Sigma$ mit $A \cap B = \emptyset$. Dann gilt für $K_i, L_i \in \starfree(\bast)$: $$L \cap \bast A \bast= \bigcup_{\text{endlich}} K_iAL_i$$
	Auch die Umkehrung des Lemmas ist wahr, hier ist jedoch nur die gegebene Richtung relevant.
	
\subsubsection{Beweis des Lemmas - Teil 1\label{Beweis: 1}}
	\OE\hspace{1pt} gilt $\bigcup_{\text{endlich}} K_iAL_i = \bigcup_{i = 0}^n K_iAL_i$ mit $K_0 = \sigstern$ und $n \geq 1$. Die ist möglich, da $L_0 = \emptyset$ erlaubt ist und somit auch der Fall des leeren Wortes abgedeckt ist. \newline
	
	Der Beweis ist einfach, unter Verwendung von $\ap = \starfree$, was als Selbsttest geprüft werden kann.
	Wir geben hier deshalb den direkten Beweis mittels struktureller Induktion an.
	\newline
	
	Wir unterscheiden nach verschiedenen Formen, die $L$ annehmen kann.
	Zuerst sei $L$ endlich. Dann gilt $L \cap \bast A\bast$ ist sternfrei (trivial).\newline
	
	Nun sei $L = L' \cup L''$ mit $L', L'' \in \starfree(\Sigma)$. Dann gilt: $$L' \cup L'' \cap \bast A \bast = \bigcup_{j = 1,2} \bigcup K_{i,j}AL_{i,j}$$ \newline
	
	Nun sei $L=L' \cdot L''$. Dann gilt: $$L' \cdot L'' \cap \bast A \bast = \bigcup_{i \in I} K_i A L_i (L'' \cap \bast) \cup \bigcup_{j \in J}(L' \cap B) K_jAL_j$$ 
	für $L' \cap \bast A \bast = \bigcup_{i \in I} K_iAL_i$ und $L'' \cap \bast A \bast = \bigcup_{j \in J} K_iAL_j$.\newline
	
	Es fehlt jetzt noch die Betrachtung des Komplements, welche in Abschnitt~\ref{sec:splitting_bew2} folgen wird.

\subsubsection{Beobachtung}
	Sei $L \cap \bast A \bast = \bigcup_{\text{endlich}} K_iAL_i$. Dann gilt ohne Einschränkung $$K_I \cap K_j = \emptyset$$ für alle $i \not = j$ und $$\bigcup_{i \in I} K_i = \sigstern\, .$$

	Das kann man folgenderma\ss en beweisen. \oei gilt $K_i \not = \emptyset$ für alle $i$.
	
	Angenommen $\exists i,j$ mit $i \not = j$ und $K_i \setminus K_j \not = \emptyset \not = K_i \cap K_j$.
	Dann lässt sich $K_i A L_i$ durch $$(K_i \setminus K_j)AL_i \cup (K_i \cap K_j)AL_i$$ darstellen. Abbildung~\ref{fig:teilmengen} veranschaulicht dies. 
	
	\begin{figure}[H]
		\centering
		$\sigstern = 
		\begin{array}{c}
				\begin{tikzpicture}[fill=gray]
				\scope
					\clip (2.7,-2.54) rectangle (-1.5,1.5)
							(0,0) circle (1)
							(1.2,0) circle (1);
							(0.6,-1.04) circle (1);
							(2,-2) circle (1);
				\endscope
				\draw (0,0) circle (1) (0,1)  node [text=black,below,shift={(-0.5,-0.5)}] {$K_1$}
						(1.2,0) circle (1) (0,1)  node [text=black,below right,shift={(1.2, -0.5)}] {$K_2$}
						(0.6,-1.04) circle (1) (1.1,-0.6) node [text=black, below right, shift={(-1,-0.5)}] {$K_3$}
						(2,-1.9) circle (1) (1.1,-0.6) node [text=black, shift={(1,-1.1)}] {$K_4$}
						(3.5,-3.5) rectangle (-2,2) node [text=black,shift={(0.5,-0.5)}] {$K_0$};
				\end{tikzpicture}
			\end{array}$
		\caption{Aufteilung von $\sast$ in Teilmengen.}
		\label{fig:teilmengen}
		\end{figure}
	
\subsubsection{Beweis des Lemmas - Fortsetzung}
	\label{sec:splitting_bew2}
	Nun können wir den Beweis mit der Betrachtung des Komplements $\sast\setminus L$ vervollständigen.
	Betrachte also $(\sigstern \setminus L) \cap \bast A \bast$, wobei $$L \cap BA\bast = \bigcup_{i = 1}^n K_i A L_i$$ gilt mit $K_i \cap K_j \not = \emptyset$ für alle $i \not = j$ und $\bigcup_i K_i = \sigstern$, sowie $K_i \not = \emptyset$. Dann ist $\{K_1, \ldots, K_n\}$ eine Partition von $\sigstern$. Somit gilt: $$(\sigstern \setminus L) \cap (\bast A \bast) = \bigcup_{i = 1}^nK_iA(\bast \setminus L_i)$$ 
	\bewiesen
	
\subsection{$\fo \implies \starfree$}
\subsubsection{Satz: $\fo$-Sprachen sind sternfrei}
	Sei $\varphi \in \fo[\leq] = \fo[<]$ und $\Sigma$ ein endliches Alphabet. Dann gilt $L(\varphi) \in \starfree(\sigstern)$. 

\subsubsection{Beweis des Satzes - Teil 1}
	Sei $\varphi \in \fo[\leq]$ mit $\fv(\varphi) = \{x_1, \ldots, x_n\} = V$ und $w \in \sigstern$ mit $w = \{1, \ldots, l\}$. Dann ist eine Interpretation der freien Variablen $x_i$ gegeben durch eine Abbildung $$\sigma: V \to \{1, \ldots,l\}\, .$$ 
	Dann gilt $w, \sigma \models \varphi \in \{0,1\} = \B = \{\top, \bot\}$ ist wohldefiniert. \newline
	
	Die zentrale Idee des Beweises ist nun folgende: Kodiere das Paar $(w, \sigma)$ durch Wörter über $\Sigma_V = \Sigma \times \{0,1\}^V$. Dabei haben Wörter über $\Sigma_V$ die Form $$(a_1, \tau_1) \cdots (a_l, \tau_l)$$ mit $a_i \in \Sigma$ und $\tau_i : V \to \{0,1\}$. Konkreter bedeutet das, wir kodieren $(w, \sigma)$ durch $$\overline{(w, \sigma)} = (a_1, \tau_1) \cdots (a_{|w|}, \tau_{|w|})\, ,$$ wobei $\tau_p(x) =$ ''$\sigma(x) = p$'' $\in \B$ ist.\newline
	
	Für den weiteren Beweis sind nun noch einige Definitionen notwendig. 

\subsubsection{Definition: Normalform}
	Die Normalformen entsprechen den Kodierungen $\overline{(w, \sigma)}$.
	Die Menge dieser ist definiert als: $$N_V = \bigcap_{x \in V} (\Sigma_V^{x=0})^\ast(\Sigma_V^{x=1})(\Sigma_V^{x=0})^\ast \in \starfree(\sigstern)$$

\subsubsection{Definition: Teilalphabet}
	Wir nennen die folgende Menge ein Teilalphabet von $\Sigma_V$: $$\Sigma_V^{x=b} = \{(a, \tau) \in \Sigma_V \mid \tau(x) = b\}\, ,$$ mit $b \in \{0,1\} = \B$.

\subsubsection{Semantik}
	Wir bezeichnen die Semantik von einem Ausdruck $x$ mit dem Symbol $\llbracket x\rrbracket$.
	Im Folgenden definieren wir die Semantik einiger Ausdrücke in der Menge der Code-Wörter.
	\begin{gather*}
			\rbracedalign
			{}{
				\llbracket \varphi \rrbracket_V &= \{\overline{(w, \sigma)} \in N_V \mid (w, \sigma) \models \varphi \}  \\
				\llbracket x = a \rrbracket_V &= \{\overline{(w, \sigma)} \in N_V \mid w = b_1, \ldots, b_l \in \sigstern \land b_{\sigma(x)}=a\}  \\
				\llbracket x < y\rrbracket_V &= \{\overline{(w, \sigma)} \in N_V \mid \sigma(x) < \sigma(y) \}  \\
				\llbracket \varphi \lor \psi \rrbracket_V &= \llbracket \varphi \rrbracket_V \cup \llbracket \psi \rrbracket_V 
			}{ 
				\llbracket \neg \varphi \rrbracket_V &= N_V \setminus \llbracket \varphi \rrbracket_V  
			}{\in \starfree(\sigstern_V)}
	\end{gather*}
	$$\llbracket \exists x : \varphi \rrbracket_V \in \{ \overline{(w, \sigma)} \in N_V \mid \exists p : 1 \leq p \leq |w| \land \overline{(w, \sigma[x_n \to p])} \in \llbracket \varphi \rrbracket_{V \cup [x_n]} \}$$
	Wobei wir $\sigma$ wie folgt definieren: 
	$$\sigma[x_n \to p](y) = 
	\begin{cases}
	\sigma(y) & \text{ falls }  y \not = x_n\\
	\sigma(x_n) = p & \text{ sonst}
	\end{cases}$$

	Hierbei wurde \oei angenommen, dass $\varphi = Q_1x_1\ldots Q_nx_n \psi$ gilt, wobei $\psi$ quantorenfrei ist, $\fv(\psi) = \{x_1, \ldots, x_n\} = V$ gilt und
	$Q_i \in \{\exists, \forall\}$ ist. 

	
\subsubsection{Beweis des Satzes - Teil 2}
	\oei gilt $\varphi = Q_1x_1\ldots Q_nx_n \psi$, wobei $\psi$ quantorenfrei ist, $\fv(\psi) = \{x_1, \ldots, x_n\} = V'$ gilt,
	$Q_i \in \{\exists, \forall\}$ ist und $x_i \not= x_j$ für alle $i \not=j$. 
	Die zu beweisende Behauptung ist richtig, falls $\fv(\varphi) = V'$ gilt, da dann $\llbracket \varphi \rrbracket_{V'} \in \{\emptyset, \sigstern_{V'}\}$ gilt. Deshalb bleibt die Behauptung dann noch für den Fall, dass nicht alle Variablen frei sind, zu zeigen, also ist zu zeigen, dass die Behauptung für 
	$\exists x\psi$ gilt, da $\starfree(\sigstern_{V'})$ eine boolesche Algebra ist. Wir betrachten nun die Teilalphabete:
	\begin{align*}
		A = \Sigma_{V'}^{x_n = 1}  \quad\text{ und }\quad B= \Sigma_{V'}^{x_n = 0} 
	\end{align*}
	Dann gilt:
	\begin{align*}
	N_{V'} \subseteq \bast A \bast \quad\text{ und }\quad\fv(\exists x \psi) = \fv(\psi) \cup \{x\}
	\end{align*}
	Mit $A \cup B = \Sigma_{V'}$ und $A \cap B  = \emptyset$ können wir nun schlie\ss en, dass 
	\begin{align*}
		\llbracket \exists x \psi \rrbracket_{V'} &= \llbracket \exists x \psi \rrbracket_{V'} \cap N_{V'} \\ 
		&= \bigcup_{\text{endlich}} K_iAL_i 
	\end{align*}
	mit $K_i, L_i, \in \starfree(\bast)$ gilt.
	Wir erhalten zwei bijektive Restriktionen: 
		\begin{align*}
			\pi_0 : B &\iso \Sigma_V \text{ mit } \pi_0(a, \tau) = (a, \tau|_V) \\
			\pi_1 : A &\iso \Sigma_V \text{ mit } \pi_1(a, \tau) = (a_i, \tau|_V) 
		\end{align*}
	Somit sehen wir: $$\llbracket \exists x \psi \rrbracket_V = \bigcup_{\text{endlich}} \pi_0(K_i) \pi_1(A)\pi_0(L_i) \subseteq \sigstern_V$$ 
	Da $\pi_0, \pi_1$ nur Umbenennungen von Buchstaben sind, folgt 
		\begin{align*}
			\pi_0(K_i), \; \pi_0(L_i), \; \pi_1(A) \in \starfree(\Sigma_V)\,.
		\end{align*}  
		\bewiesen
	
\section{Automatentheoretische Verifikation und Modell Checking- Vorlesung 16}
\subsection{Allgemeines}
\subsubsection{Einführung}
	Wir betrachten diskrete Zeitabstände $0,1,2,3. \ldots$. Nun wollen wir durch Abstraktion eines realen Systems zu endlichen Translationssystemen (= NFA's ohne Endzustände) gelangen. 
	Für ein $t \in \N$ sei $\sX = n\sX t(t) = t+1$ und $\sF t = \mathsf{Future}(t) = \{t' \mid t \leq t'\}$. Unsere Spezifikationssprache ist also ein Fragment von $\mso$ über $\Sigma = 2^P$, wobei $P$ die Menge von Eigenschaften die zur Zeit $t$ wahr sind beschreibt mit $|P| < \infty$
\subsubsection{Anwendung}
	\textbf{Gegeben} sei eine Spezifikation $\varphi$ mit $\varphi \subseteq \sigstern$. Für ein reales System $A$ ist unser Translationssystem dann $L(A) \subseteq \sigstern$.
	\newline
	
		\textbf{Das Problem} ist nun zu entscheiden ob 
	\begin{align*}
	L(A) \subseteq L(\varphi) &\iff L(A) \cap \sigstern \setminus L(\varphi) = \emptyset \\
	&\iff L(A) \cap L(\neg \varphi) = \emptyset
	\end{align*} gilt.
	\newline
	
		\textbf{Die Lösung} dazu bringt die Konstruktion eines NFA $B = (Q, \Sigma, \delta, I, F)$ mit $L(\varphi = L(B))$. Ist dies geschafft, dann ist der Test ob $L(A) \cap L(B) \neq \emptyset$ gilt einfach, und liefert sogar einen Zeugen für den Fehler. 

\subsection{Einführung in $\ltl$}
\subsubsection{Allgemein}
	Es gilt 
	\begin{align*}
		\fo[\leq] \subseteq \starfree(\sigstern) &\implies (aa)^\ast \text{ kann nicht in } \fo[\leq] \text{ akzeptiert werden} \\
		&\implies (ab)^\ast \text{ kann in } \fo[\leq] \text{ akzeptiert werden} 
	\end{align*}
	Beachte: $(ab)^\ast = 1.$ Position ist ein $a$, und die letzte Position ist ein $b$ und $$\mathsf{Globally}(\lambda(t) = a \iff \lambda(\sX t) = b) = \sG(a \iff \sX b)$$ wobei $\sG(\varphi) = \neg \sF \neg \varphi$

\subsubsection{Syntax}
	$\varphi \in \ltl$ ist $\fo[\leq]$-Formel mit genau einer freien Variable.
		\begin{enumerate}[label=\arabic*.)]
			\item Sei $a \in \Sigma$, dann ist $a = a(x) \in \ltl$
			\item Sei $\varphi \in \ltl$, also $\varphi = \varphi(x)$. Dann ist $\sX \varphi(x) \in \ltl$
			\item Seien $\varphi, \psi \in \ltl$, dann ist auch $\varphi \sU \psi \in \ltl$ bzw $\varphi(x), \psi(x) \in \ltl$ auch $(\varphi \sU \psi )(x)\in \ltl$
			\item Seien $\varphi, \psi \in \ltl$, dann ist auch $\varphi \cup \psi \in \ltl$ und $\neg \psi\in \ltl$
		\end{enumerate}
	
\subsubsection{Semantik}
	Sei $\varphi \in \fo[\leq]$ mit $\fv(\varphi) = \{x\}$, dann ist ''$w,x \models \varphi$'' $\in \B$ definiert.
	\begin{itemize}
		\item ''$w,x \models a$'' $\iff$ ''$w(x) = a$'' das heißt $w = a_1 \ldots a_{|w|} \in \Sigma$ und $a_x = a$
		\item ''$w,x \models \sX \varphi$'' $\iff$ ''$w\sX x \models \varphi$'' $\iff$ ''$w, x+1 \models \varphi$''
		\item ''$w, x \models (\varphi \sU \psi)$'' $\iff$ $\exists z : x \leq z \land w, z \models \psi \land \forall y: [x \leq y < z \implies w, y \models \varphi]$
		\item ''$w,x$'' $\models \varphi \#\psi \iff (w,x \models \varphi) \# (w,x \models \psi )$ für $\# \in \{\lor, \neg, \land, \implies, \iff, \ldots\}$
	\end{itemize}

\subsubsection{Beispiele}
		\begin{enumerate}[label=\arabic*.)]
			\item Starte bei einer Sprache $L \in \starfree(\sigstern)$
			\item Konstruiere nun $\varphi \in \ltl$ mit $L(\varphi) = \{(w,1) \mid w \in \sigstern \text{ und } w,1 \models \varphi \text{ und } w \in L\}$
		\end{enumerate}
\subsubsection{Makros}
\begin{multicols}{2}
		\begin{itemize}
		\item $\sF \varphi = \sT \sU \varphi$ mit $\sT = true$
		\item $\sG \varphi = \neg \sF \neg \varphi$
		\item $\neg(\varphi \sU \psi) = \sG \neg \psi \cup (\neg \varphi \sU \neg \varphi)$
		\item $\varphi \sU \psi \iff \psi \lor (\varphi \land \varphi\sX\sU\psi)$
	\end{itemize}
\end{multicols}
	
Das unterste Makro ist möglich da $\varphi \sU \psi = (\varphi, \varphi, \ldots,\psi)$ und $$\neg (\varphi \sU \psi) = (\neg \psi, \neg \psi, \ldots, \neg\varphi) \lor (\neg \varphi, \neg \varphi, \ldots, \neg\psi)$$

\subsubsection{Selbsttest und Übung}
	Definiere folgendes: 
		\begin{gather*}
	\rbracedalign
	{}{
		\sY\varphi &= \mathsf{ Yesterday}(\varphi) \\
		\varphi\sS\psi &= \varphi \mathsf{Since}(\varphi)
	}{ 
	}{\in \fo^3[\leq]}
	\end{gather*}
	Beachte das $\fo^k[\leq] \subseteq \fo[\leq]$ und $\varphi \in \fo^k[\leq]$ verwendet nur $k$ viele Namen für die Variablen.
	Ganz allgemein gilt 
	$$\fo^2[\leq] \subsetneqq \fo^3[\leq] = \fo[\leq]$$ und somit auch $$\ltl = \tl[\sX,\sU] = \tl[\sX, \sU, \sY, \sS] \subseteq \fo^3[\leq] \subseteq \fo[\leq] \subseteq \starfree(\sigstern) \subseteq \ap(\sigstern)$$denn es ist $\varphi(\sX\sU)\psi := \sX(\varphi\sU\psi)$ und $\sX\varphi = \bot \sX\sU\varphi$ sowie $\varphi\sU\psi = \psi \lor \varphi \land \varphi \sX \sU \psi$. 

\section{$\ltl = \ap$ - Vorlesung 17}
\subsection{Vorbereitungen zum Beweis des Satzes}
\subsubsection{Satz}
Es gilt $\ltl_\Sigma[\sX \sU] = \ap(\Sigma)$

\subsubsection{Allgemeines}
	Wir wissen dass $$L \in \ap(\Sigma) \iff \exists h : \sigstern \to M$$ mit $h\inv h (L) = L$, $M$ ist endlich und aperiodisch. 
	Dann folgt direkt dass $U(M) = \{1\}$ und $h\inv(1) = \bast$ für $B=\{b \in \Sigma \mid  h(b) = 1\}$. Dann ist 
	\begin{align*}
	L \in \ltl_A[\sX\sU] &\iff L \setminus \{\varepsilon\} \in \ltl_A[\sX\sU] \\
		&\iff  L \setminus \{\varepsilon\} = \{w \in A^+ \mid  w = a_1\ldots a_n \text{ mit } a_i \in A \text{ und } w,1 \models \varphi\}
	\end{align*} wobei $\varphi \in  \ltl_A[\sX\sU]$ ist.


\subsubsection{Strategie}
 Wir zeigen nur $\ap(\Sigma) \subseteq \ltl_\Sigma[\sX\sU]$, da wir wissen dass $$\ltl_\Sigma[\sX\sU] \subseteq \fo_\Sigma^3[\leq] \subseteq \fo_\Sigma[\leq] \subseteq \starfree(\Sigma) \subseteq \ap(\Sigma)\subseteq \ltl[\sX \sU] $$

 Demnach führen wir eine Induktion nach $(|M||\Sigma|)$ durch, denn 
 \begin{align*}
	 (|M'||\Sigma'|) \leq (|M||\Sigma|) \iff  |M'|<|M| \text{ oder } |M'|=|M \text{ und } |\Sigma|\leq |\Sigma|
 \end{align*}
 Weiter gilt ohne Einschränkung: $h:\sigstern \to M$ ist surjektiv. 
 Wir wissen nun dass $\ltl_\Sigma[\sX\sU] \subseteq \ap(\Sigma)$ gilt, falls $M=\{1\}$ oder $\Sigma = \emptyset$ oder $\Sigma = \{a\}$ also $|\Sigma| = 1$: 
 	\begin{align*}
 		L \subseteq A^+ \text{ ist aperiodisch } \iff \exists t \in \N: L \subseteq \{a, a^2, \ldots, a^t\} \cup \{a^m \mid  m \geq t\}
 	\end{align*}
 	Dafür sei $L=\{a^k\}$ mit $k \geq 1$, dann ist $L = L(\underbrace{a \land \sX(a \land \sX(\ldots)}_{\substack{k\text{ -mal}}})\bot)$
 	
\subsubsection{Lemma}
	Sei $A\subseteq \Sigma$ und $L = L(\varphi)$ mit $\varphi \in \ltl_A[\sX\sU]$ und $L \subseteq \aast$. Dann gibt es ein $\varphi_A \in \ltl_\Sigma[\sX\sU]$ mit $L=L(\varphi_A)$

\subsubsection{Beweis des Lemmas}
	Wir zeigen durch strukturelle Induktion
	\begin{align*}
		\varphi = a &\implies\varphi_A \text{ für ein } a \in A \\
		\varphi = \varphi_{1} \lor \varphi_{2} &\implies \varphi_{A} = \varphi_{1A} \lor \varphi_{2A} \\
		(\neg \varphi)_A &= \neg (\varphi_{A}) \land \sG(\bigvee_{a \in A}a)
	\end{align*} Also $L((\neg\varphi)_A) = \ast \setminus L(\varphi_{A})$. Beachte $$(\varphi \sX \sU \psi)_A = (\varphi_{A} \sX \sU \psi_A) \land (\bigvee_{a \in A} a)$$
	\bewiesen
	
\subsubsection{Lemma}
	Es gilt $h\inv h(L) = L$ dann ist $$L = \bigcup_{m \in M}\{h\inv(m) \mid m \in h(L) \}$$
	Somit reicht es also später zu zeigen dass $h^{-1} (m) \in  \ltl_\Sigma[\sX\sU]$. 
	Weiter gilt ab jetzt $\ltl :=  \ltl_\Sigma[\sX\sU]$

\subsubsection{Lemma}
	Es ist $h\inv(1) \in \ltl$
\subsubsection{Beweis des Lemmas}
	Sei $h\inv(1) = \bast$ für $B = \{b \in \Sigma \mid h(b) = 1\}$ und $\bast = L(T)$ in $ \ltl_B[\sX\sU]$. Dann existiert $\varphi_B \in \ltl$ mit $\bast = L(\varphi_B)$.
	Also zeigen wir später nur $$h\inv(m) = \bigcup\{h\inv(m) \cap \sigstern c \sigstern \mid h(c) \neg = 1\} \in \ltl$$ Daher zeigen wir nur für ein festes $c \in \Sigma$, dass $h\inv(m) \cap \sigstern c \sigstern \in \ltl$

\subsubsection{Dirthy Trick}
	Sei $M \cap \sigstern = \{1, c\}$ als Menge definiert und $1 = \varepsilon$ sowie $c \in \Sigma$ und $h(c) = c \neg 1 \in M$. Also ist $M_c = \{cM\cap Mc, \circ, c\}$ ein lokaler Divisor mit $|M_c| < |M|$ und $xc \circ cy = xcy$. 
	\newline
	
	Zeige nun $h\inv(m) \cap \aast c \aast \in \ltl$ mit $A = \Sigma \setminus \{c\}$, und insbesondere $|A| <| \Sigma|$. 
	Es gilt also $$h\inv(m) \cap \aast c \aast  = \bigcup\{(h\inv(p) \cap \aast)c(h\inv(q)\cap \aast) \mid pcq = m\}$$
	Beachte dass $h\inv(p) \cap \aast) \in \ltl_A[\sX\sU] \subseteq \ltl$ und $(h\inv(q)\cap \aast) \in  \ltl_A[\sX\sU]$. Wir zeigen daher nur für $\varphi, \psi \in \ltl$, dass 
	$$(L(\varphi) \cap \aast) c (L(\psi) \cap \aast) \in \ltl$$
	
\subsubsection{Lemma}
	Sei $\varphi \in \ltl$. Dann gilt $\sigstern c (L(\varphi) \cap \aast) \in \ltl$ und $(L(\varphi) \cap \aast)c \sigstern \in \ltl$
	
\subsubsection{Beweis des Lemmas}
	Sei $L(\varphi) \cap \aast = L(\psi)$ für ein $\psi \in \ltl$. Dann gilt $\sigstern c L(\varphi) = L(\sF(c \land \psi))$. 
	Betrachte nun $L(\psi) c \sigstern$. Wir führen eine strukturelle Induktion durch: 
	\newline
	
	Zeige dazu $\forall \psi \in \ltl$ mit $L(\psi) \subseteq \aast$ existiert $\psi^c \in \ltl$, so dass $L(\psi^c) = L(\psi) c \sigstern$. Beachte dass $(\neg \psi )^c = \neg (\psi^c) \land \sF c$, und dann gilt 
	\begin{align*}
		w \in L(\neg \psi) &\iff w \in \aast \lor w = ucv \text{ mit } u \in \aast \text{ und } u \not \in L(\varphi) \\
		&\iff w \in \aast \lor w \in L(\neg(\psi^c))
	\end{align*}

\section{$\ltl \implies \ap$ - Vorlesung 18}
\subsection{Vorbereitungen zum Beweis des Satzes}
\subsubsection{Bezeichnungen}
	Es gilt 
	\begin{itemize}
		\item $\varphi \in \ltl_A[\sX\sU]$ dann ist $L_A(\varphi) = \{w \in A^+ \mid w,1 \models \varphi\}$
		\item $L \in \ltl_A \iff L \setminus \{\varepsilon\} = L_A(\varphi)$ für ein $\varphi \in \ltl_A[\sX\sU]$
		\item $\ltl = \ltl_\Sigma[\sX\sU]$
	\end{itemize}

\subsubsection{Makros}
	\begin{itemize}
		\item $A \in \ltl$ vermöge $A = \bigvee_{a \in A} a$
		\item $A^+ \in \ltl$ vermöge $\neg F(\Sigma \setminus A)$ 
		\item $A \subseteq \Sigma$ und $b \in \Sigma \setminus A$ etwa $b = c \land A = \Sigma \setminus \{c\}$
	\end{itemize}

\subsubsection{Lemma 1}
	 $\forall \varphi \in \ltl_A[\sX\sU]$ existiert ein $\varphi_b \in \ltl$ für das gilt $L(\varphi_b) = \sigstern b L_A(\varphi)$.
	 \newline

	\textit{Hinweis: }Der Beweis dafür wurde bereits in VL17 geführt. Das Lemma wird hier nochmals ausführlicher beschrieben und ist aus Notations Gründen eingefügt. 

\subsubsection{Lemma 2}
	 $\forall \varphi \in \ltl_A[\sX\sU]$ existiert ein  $\varphi_b \in \ltl$ für das gilt $L_A(\varphi)b \sigstern$

\subsubsection{Beweis Lemma 2}
	Mit struktureller Induktion $\varphi = a \in A$. Dann gilt $\varphi_b = a_b = a \land A \sX \sU b$
	\begin{itemize}
		\item $(\varphi \sX \sU \psi)_b = A \land \varphi_b \sX\sU\psi_b \subseteq \{a_1\ldots a_kb\sigstern \mid a_i \in A, k \geq 2\}$
		\item $(\varphi \lor \psi)_b = \varphi_b \lor \psi_b$ 
		\item Weiter ist 
		\begin{align*}
			L((\neg \varphi)_b) &= (\aast \setminus L_A(\varphi))b\sigstern \\
			&= A^+b\sigstern \setminus L_A(\varphi)b\sigstern \\
			&=A^+b\sigstern \cap \sigstern \setminus L_A(\varphi)b\sigstern
		\end{align*} und somit folgt $(\neg \varphi)_b = A \sX\sU B \land A \land \neg (\varphi_b) \in \ltl$
	\end{itemize}
\bewiesen

\subsubsection{Lemma 3}
	Sei $L = L(\varphi)$ mit $\varphi \in \ltl$. Dann existiert ein $\varphi_b \in \ltl$ mit $L(\varphi_b) = Lb\aast$

\subsubsection{Beweis Lemma 3}
	Bleibt der Übung überlassen. \textit{Tipp: } Strukturelle Induktion!

\subsubsection{Satz}
	Es gilt $h\inv h(L) = L \implies L \in \ltl$

\subsubsection{Beweis des Satzes}
	Zeige den folgenden Satz dafür: $\forall m \in M : h\inv (m) \in \ltl$. Für $m = 1$ gilt $h\inv(m) = \bast$ mit $B = \{b \in \Sigma \mid h(b) = a \}$.
	Daher gilt ohne Einschränkung $m \not = 1$ und somit $$h\inv(m) = \bigcup_{c \not \in B } h\inv(m) \cap \sigstern c \sigstern$$ Zeige daher nur den Satz: 
	$$h\inv(m) |çap \sigstern c \sigstern \in \ltl$$

\subsubsection{Lemma}
	Sei $L_A, L'_A \in \ltl_A[\sX\sU]$ dann gilt $L_A c L'_A \in \ltl$

\subsubsection{Beweis des Lemmas}
	Gilt nach Lemma 1 und Lemma 2 und $$L_A c L'_A = L_a c \sigstern \cap \sigstern c L'_A \cap \aast c \aast$$
	\bewiesen

\subsubsection{Lemma}
	Es ist 
	\begin{align*}
	h\inv(m) \cap \sigstern c \sigstern c \sigstern &= h\inv(m) \cap \aast c \sigstern c \aast \in \ltl \\
	&= \bigcup_{p\cdot n = m}(h\inv(p) \cap \aast)(h\inv(n) \cap c \sigstern c \aast)
	\end{align*}

\subsubsection{Beweis des Lemmas}
	Es reicht das nächste Lemma zu zeigen.

\subsubsection{Lemma}
\begin{align*}
	\forall p, n \in M: (h\inv(p) \cap \aast)(h\inv(n) \cap c \sigstern c \aast) &= \\
	(h\inv(p) \cap \aast) c \sigstern \cap \aast(h\inv(n)\cap c \sigstern c \aast) \in \ltl 
	\end{align*}
\subsubsection{Beweis des Lemmas}
Gilt durch Lemma 1, Lemma 2 und den folgenden Satz

\subsubsection{Satz}
	$\forall m \in M : h\inv (n) \cap c \sigstern c \aast \in \ltl$
	
\subsubsection{Beweis des Satzes}
	Ohne Einschränkung gilt $n \not = 1$
	Dann ist $$h\inv(n) \cap c\sigstern c \aast = \bigcup_{qcr = n} L_q c (h\inv(r) \cap \aast) $$ mit $L_q = \{cw \in c \sigstern \mid h(cw)c = qc\}$. Zeige also nur $\forall q : L_q \in \ltl$, dann folgt der Satz mit Lemma 3

\subsubsection{Hauptlemma}
	Sei $L_q \in \ltl$ und $h_A: \aast \to M$ eine Restriktion von $h$ auf $\aast$ und $L_q = \{cw \in c \sigstern \mid h(cw)c = qc\} \in \ltl$. 
	Wir können dann den Beweis für $\ltl = \ap$ mit den lokalen Divisoren führen. 


\subsubsection{Ideen}
\begin{itemize}
	\item Wir wissen das $c\aast$ ein Code ist. Das heißt das $(c\aast)^+$ eine eindeutige Zerlegung in Codewörter hat und $(c\aast)^+ = c\sigstern$ ist, da $A = \Sigma \setminus \{c\}$ gilt. 
	
	\item Falls $h(c\sigstern) \subseteq cM$ ist, dann folgt 
	\begin{align*}
		\rho c h(cw) &= h(cw)c \\ 
		&= ch(w)c \in cMc \subseteq cM \cap Mc
	\end{align*}
	Für $1 \not \in (cM \cap Mc)$ folgt $M_c = (cM \cap Mc, \circ, c)$ ist kleiner als $M$. 
	\item Unseren \textit{Giant-Step} erhalten wir durch $|M_c|<|M|$ und $T= h(\aast) \subseteq M$. Wir interpretieren dabei $T$ als endliches Alphabet, also gilt 
	$$(M_c, T) <(M, \Sigma)$$
\end{itemize}

\subsection{Beweis des Satzes}
\subsubsection{Beweis}
	Wir definieren $g(t) = ctc \in (M_c, \circ, c)$ für $t \in T$. Dann gilt 
	\begin{align*}
		g(t_1\cdots t_k) &= (ct_1c) \circ \ldots \circ (ct_k) \\
		&= ct_1 \ldots ct_kc \in cM \cap Mc \text{ mit } t_i \in T
	\end{align*}
	
	Dann entsteht folgendes Bild:
		\begin{figure}[h]
		\centering
		\begin{tikzpicture}[node distance=6.5cm, auto]
		\node (cs) {$c\sigstern = (c\aast)^+$};
		\node (t) [right of=cs] {$T^+$};
		\node (cm) [below of=cs] {$cM\subseteq \{x \in M \mid xc \in M\}$};
		\node (mc) [below of=t] {$M_c =\{cM\cap Mc, \circ, c\}$};
		
		
		\draw[->] (cs) -- (t) node[ midway,sloped,above,rotate=0] { $\sigma$};
		\draw[ ->] (cs) -- (cm) node[ midway,left=.2,rotate=0] { $h$};
		\draw[ ->] (cm) -- (mc) node[ midway,sloped,below,rotate=0] {$\rho_c = xc$ };
		\draw[ ->] (t) -- (mc) node[midway, right, rotate=0] { $g$};
		\end{tikzpicture}
	\end{figure} 
	
	Es gilt also 
		\begin{align*}
			g\sigma(cw) &= g(t_1\cdots t_k) \\ 
			&= (ct_1)\circ\ldots \circ (ct_kc) \\
			&= h(cw)c \\ 
			&= \rho_ch(cw)
		\end{align*}
		falls $cw = cv_1 \ldots cv_k$ und $t_i = h_A(v_i)$. Also gilt 
		\begin{align*}
				L_q &= \{cw \in c\sigstern \mid \rho_c h(cw) = qc\}\\ 
				&=\{cw \in c\sigstern \mid cw \in h\inv \rho_c\inv(qc)\} \\
				&= \{cw \in c\sigstern \mid cw \in \sigma\inv g\inv(qc)\}
		\end{align*}
		Wir können Induktion verwenden da $(|M_c|,|T|) < (|M|, |\Sigma|)$ und $g\inv(qc) \in \ltl_T[\sX\sU]$. 
		Dann bleibt nun noch das folgende Lemma zu zeigen: 

\subsubsection{Lemma}
	Sei $k \in L_T(\varphi) \subseteq T^+$ mit $\varphi \in \ltl_T[\sX\sU]$, dann folgt $\sigma\inv(k) \in \ltl$		

\subsubsection{Beweis des Lemmas}
	Mittels struktureller Induktion: \\
	Sei $\sigma\inv(t)$ für $t \in T$ dann $\sigma\inv(t) = ch_A\inv(t)$. Nach dem \textit{Baby-Step} gilt: 
	\begin{align*}
		h_A\inv(t) \in \ltl_A[\sX\sU]
	\end{align*}
	somit folgt die Behauptung, denn 
	\begin{align*}
		\sigma(cv_1\cdots cv_k) = h_A(v_1)\ldots h_A(v_k) \in T^+
	\end{align*}

\subsubsection{Beweis Fortsetzung}
	Dann ist $(|M|, |A|) < (|M|,|\Sigma|)$. Genauer gilt: $$\forall \varphi \in \ltl_T[\sX\sU] \exists \varphi_T \in \ltl$$ mit $\sigma\inv(L_t(\varphi)) = L(\varphi_T)$. 
	Es folgt: 
	\begin{align*}
		\varphi &= t \implies \varphi_T = c \land \sX\psi \text{ mit } L(\varphi) = h_A\inv(t) \setminus \{c\}  \\
	\end{align*} bzw. 
	\begin{align*}
		\varphi_T &= (c \land \neg \sX T) \lor (c \land \sX\psi_T) \text{ falls } h_A(\varepsilon) = t = 1
	\end{align*} 
	Somit ist $(\varphi \lor \psi)_T = \varphi_T \lor \psi_T$ sowie $(\neg \varphi)_T = c \land \neg(\varphi_T)$, denn $$\sigma\inv(T\setminus K) = c \sigstern \setminus \sigma\inv(K)$$ wobei das $\sigma$ surjektiv ist. 
	\newline
	
	Man kann sich das dann wie folgt vorstellen:

		\[ \begin{array}{*{9}{r}}
		cv_1 &cv_2 &\ldots &cv_i &\ldots &cv_j &\ldots &cv_k\\
		t_1 & \rnode{T2}{t_2} &\ldots & \rnode{Ti}{t_i }&\ldots &\rnode{Tj}{t_j} &\ldots &t_k \\[0.5ex]
		& & & & & & & & \makecell{\rnode{Aj}{\psi}\\
			\rnode{Ai}{\varphi}\\
			\rnode{A2}{\varphi}}
		\end{array}
		\psset{linewidth=0.6pt, linejoin=1, arrows=->, arrowinset=0.12, angleA=-90, angleB=180, nodesep=3pt}
		\foreach \s in {2,i, j}{\ncangle{T\s}{A\s}}
		\]
		
	und somit ist $$(\varphi\sX\sU \psi)_T = (x \land (\neg c \lor \varphi_T) \sX\sU(c \land \psi_T)$$
	\bewiesen

\section{Verifikation und Modell Checking - Vorlesung 19}
\subsection{Modellchecking}
	Sei ab hier $\ltl_\Sigma[\sX\sU] = \ltl$. Gegeben ist $\varphi \in \ltl$. Konstruiere dazu $A_\varphi$ mit $$L(A_\varphi) = L(\varphi) \subseteq \Sigma^+$$

\subsubsection{1. Schritt}
	Wir definieren nun $\ltl_+ = \ltl$ ohne Negation. Dafür brauchen wir neue Makros: 
	\begin{multicols}{2}
	\begin{itemize}
		\item $\top = true$
		\item $\bot = false$
		\item $\sende = \neg \sX \top$
		\item $v = a_1 \ldots a_n$ mit $a_i \in \Sigma$
		\item $v, i \models \sende\iff i = |v|$
		\item $v, i \models\sende \iff a \in \Sigma$
	\end{itemize} 
\end{multicols}
Wir erhalten also 
\[
A_\sende= \left\{\begin{array}{c}
	\begin{tikzpicture}[node distance=2cm, auto, baseline=-0.65ex,scale=0.5]
	\node(a) [semifill={black,ang=90}] {};
	\node(b) [semifill={black,ang=270}, right of = a] {};
	\draw[->] (a) -- (b) node[ midway,sloped,above,rotate=0] { $a \in \Sigma$};
	\end{tikzpicture} 
\end{array} \right\}
\]
Weiter definieren wir neue Makros: $\varphi \; \mathsf{ Release } \;  \psi = $ ''  $\varphi \text{ entlässt } \psi$''$= \varphi \sR \psi$
		
\subsubsection{Idee}
	Wir wollen 
		\begin{align*}
			\neg(\varphi \sU \psi) &= \neg \varphi \sR \neg \psi \\ 
				&= \sG(\neg \psi) \lor \neg \psi \sU (\neg \varphi \land \neg \psi)
		\end{align*}
	Also graphisch
		\[ \begin{array}{*{9}{c}}
				\neg \psi &\neg \psi &\ldots &\neg \psi &\ldots &\neg\psi &\psi &\psi \\
				\bullet & 	\bullet &\ldots  &\bullet &\ldots &\bullet  &\bullet &\bullet  \\
				a_1 & a_2 &\ldots & a_i &\ldots &a_{k-1} &a_{k} &a_{k+1}
	\end{array}
		\]
		mit $\varphi \sR \psi = \sG \psi \lor \psi \sU (\varphi \land \psi)$. Tatsächlich interessiert uns ein Operator $\varphi \sX \sR \psi$ mit Semantik $\neg(\neg \varphi \sX \sU \neg \psi)$
		Weiter ist $\neg a = \bigvee_{a\not = b} b$ mit $\neg a = \bot $ falls $\Sigma =\{a\}$. 
		\newline
		
		Wir definieren $\ltl_+ = \ltl_+[\sX \sU, \sX\sR]$ duch eine kontextfreie Grammatik: 
			\begin{align*}
				\varphi = \top \mid \bot \mid a \in \Sigma \mid \varphi \lor \varphi \mid \varphi \land \varphi \mid \varphi \sX \sU \varphi \mid \varphi \sX\sR\varphi
			\end{align*}
\subsubsection{Lemma}
	Sei $\varphi \in \ltl[\sX\sU]$. Dann existiert ein $\psi \in \ltl_+$ mit den Eigenschaften $$L(\varphi) = L(\psi) \text{ und }|\psi| \leq |\Sigma| \cdot |\varphi|$$

\subsubsection{Definiton Teilformel}
	Definiere für ein $\varphi \in \ltl_+$ die Menge  $\tf(\varphi)$ der Teilformeln. Weiter ist
	\begin{align*}
		\tf(\varphi) &= \{\varphi\} \text{ für ein } \varphi \in \{\top, \bot, \sende, a \mid a \in \Sigma\} \\
		\tf(\varphi_1 \lor \varphi_2) &= \tf(\varphi_1 \land \varphi_2) = \tf(\varphi_1) \cup \tf(\varphi_2)\\
		 \tf(\varphi) &=\{\varphi\} \cup \tf(\varphi_1) \cup \tf(\varphi_2) \text{ für } \varphi \in \{\varphi_1 \sX\sU\varphi_2,  \varphi_1\sX\sR\varphi_2\}
	\end{align*}
	Es gilt: $$\tf(\varphi) \subseteq \{\top, \bot, \sende, a \mid a \in \Sigma\} \cup \{\varphi \sX\sU\psi, \varphi\sX\sR\psi \mid \varphi, \psi \in \ltl_+\}$$ und $|\tf(\varphi)| \leq |\varphi|$

\subsubsection{2. Schritt}
	Ziel: Wir wollen $ A_\varphi =(Q, \Sigma, \delta, I, F)$ mit $Q = \{\{\varphi_1, \ldots, \varphi_k \mid k \geq 1, \varphi_i \in \tf(\varphi)\}$	 definieren. 
	Die Idee ist dass $\{\varphi_1, \ldots, \varphi_k\}$ die Konjunktion von $$\varphi_1 \land \ldots\land \varphi_k = \bigwedge_{i = 1}^k \varphi_i$$
	Wir bezeichnen mit $\B_+(\tf(\varphi))$ die positiven boolschen Ausdrücke. Nun definieren wir eine Abbildung
	\begin{align*}
		\beta: \tf(\varphi) \times \Sigma \to \B(\tf(\varphi))
	\end{align*} durch $\beta(\top, a) = \top$ und $\beta(\bot, a) = \beta(\sende, a) = \bot$ für alle $a \in \Sigma$ und 
	\[\beta(b, a) =  
		\begin{cases}
			\top, & \text{ falls } a = b \\
			\bot, & \text{ sonst}
		\end{cases}	
	\] sowie 
	\begin{align*}
		\beta(\varphi \sX\sU\psi, a) &= \beta(\sX(\varphi \sU \psi), a) \\
		&= \sX \varphi \lor \sX(\varphi \land \varphi \sX\sU \psi)
	\end{align*}
und 
	\begin{align*}
		\varphi \sX\sR\psi &= \neg(\neg\varphi \sX\sU \neg \psi) \\
		&= \neg(\sX(\neg\varphi \sU \neg \psi)) \\
		&=\sende \lor \sX(\neg(\neg \varphi \sU \neg \psi)) \\
		&= \sende \lor \sX(\neg\sG \psi \lor (\neg \varphi\land (\neg \sX\sU \neg \psi)) \\
		&= \sende \lor (\sX(\psi \land (\varphi \lor \neg((\neg \varphi)\sX \sU (\neg \psi))) \\
		&= \sende \lor(\varphi (\varphi \lor \varphi \sX\sR\psi)) \\
		&=\sende \lor \sX(\varphi\land \psi) \cup (\psi \land (\varphi \sX\sR \psi))
	\end{align*} Au\ss erdem ist 
\begin{align*}
	v, i &\models \varphi \sX\sR\psi \iff v, i+1 \models (\varphi \land \psi) \lor (\psi \land \varphi \sX\sR \varphi) \text{ falls } i < |v| \\
	v, |v| &\models \varphi \sX \sR \psi \text{ für alle } \varphi, \psi
\end{align*} und es ist $\beta(\varphi\sX\sR\varphi, a) = (\varphi \land \psi) \lor (\psi \land \varphi \varphi \sX\sR \psi)$. 
\newline

Sei jetzt $\phi = \{\varphi_1, \ldots, \varphi_k\} = \bigwedge_{i = 1}^k \varphi_i$ dann gilt 
\begin{itemize}
	\item$\beta(\phi, a) \in \B(\tf(\varphi))$
	\item $\beta(\phi, a) = \bigvee_{j \in J} \bigwedge_{l \in K_j}\Psi_l$ ist in DNF
\end{itemize} und 
\begin{align*}
	\delta(\phi, a) = \bigcup_{j \in J} \underbrace{\{\varphi_l \mid l \in K_j\} }_{\substack{\Psi_J}}= \bigcup_{j\in J} \Psi_j
\end{align*}
	Nun haben wir 
	\begin{align*}
		Q &= \{\phi \mid \phi \not = \emptyset \text{ und } \phi \subseteq \tf(\varphi)\} \\
		I &= \{\varphi\} \\
		\delta(\phi, a) &= \bigcup_{j \in J} \{\varphi_l \mid l \in K_j\} = \bigcup_{j\in J} \Psi_j \\
		F &= \{\Phi \mid \Phi \not = \emptyset \land \Phi \subseteq \{\top, \sende, \} \cup \{\varphi\sX\psi \mid \varphi, \psi \in \ltl_+\}\}
	\end{align*}
	\newline
	
	Es gelten folgende Vereinfachungen
	\begin{itemize}
		\item $\bot \land \varphi = \bot$
		\item $\sende \land a = (\sende \land \varphi\sX\sU\psi) = \bot$
		\item $\varphi \land \top = \varphi$
		\item $\sende \land \varphi \sX\sR\psi = \sende$
	\end{itemize}
	
\section{Büchi Automaten - Vorlesung 20}
\subsection{Grundlagen}
 Es ist $\Sigma\pom = \{a_1a_2\ldots \mid \forall i \in \N: a_i \in \Sigma \}$ und $\alpha \in \Sigma\pom$. Weiter ist $$L(A) \subseteq L(\varphi) \iff L(A) \cap L(\neg \varphi)$$
 Die Abläufe von $A$ sollen nicht enden, da das System Modell kein Ende haben sollen (Schleusen, Betriebssystem usw)

\subsection{Definition: Büchi Automat}
	Ein Büchi Automat ist ein NFA $A = (Q, \Sigma, \delta, I, F)$ mit $L(A) \subseteq \Sigma\pom$. Wir definieren nun $\alpha = a_1a_2\ldots \in L(A)$ falls:
	\begin{enumerate}[label = \arabic*.)]
		\item es einen Pfad $p_0 \overset{a_1}{\longrightarrow}p_1 \overset{a_2}{\longrightarrow} p_2 \longrightarrow \ldots$ gibt so, dass für alle $i\in \N$ gilt: $p_i \overset{a_{i+1}}{\longrightarrow} p_{i+1} \in \delta$ gilt. (Hier gilt ohne Einschränkung $\delta \subseteq Q \times \Sigma \times Q$) und
		\item $p_0 \in I$  und
		\item $\exists p \in F |\{i \in \N \mid p_i = p\}| = \infty \iff |\{i \in \N \mid p_i \in F\}| = \infty$
	\end{enumerate}

\subsection{Definition: $\omega$-regulär}
	$L \subseteq \Sigma\pom$ hei\ss t $\omega$-regulär, falls $\exists n \in \N : \forall 1 \leq i \leq n$ und $\exists U_i \subseteq \sigstern$ sowie $\exists V_i \subseteq \sigstern$ und $U_i, V_i$ sind regulär und es gilt $$L = \bigcup_{i = 1}^n U_i V_i\pom$$
	
\subsection{Lemma}
	Sei $L = \bigcup_{i = 1}^n U_i V_i\pom$, dann existiert ein Büchi Automat $A$ mit $L=L(A)$.

\subsection{Beweis des Lemmas}
	Es gilt ohne Einschränkung: 
	\begin{itemize}
		\item $L = UV\pom$ mit $U = L(A_u) \subseteq \sigstern$ und $V = L(A_v) \subseteq \sigstern$
		\item $A_u, A_v$ haben nur einen Endzustand
		\item $\delta_u \delta_v \subseteq Q_u \times \Sigma \times Q_v$
	\end{itemize}
	Wir betrachten den Automat für $L = UV\pom$
	\begin{figure}[h!]
		\centering
	
		\begin{tikzpicture}[node distance=2.5cm, auto]
		\node[state](a) [semifill={black,ang=90}] {};
		\node(geist1) [fill=white, above right of = a] {$\cdots$};
		\node(geist2) [fill=white, below right of=a] {$\cdots$};
		\node[state](b) [semifill={black,ang=270}, below right of = geist1] {};
		\node[state] (f)  [right of = b] {$f$};
		
		\node[state] (1)  [semifill={black,ang=90}, right of = f] {};
		\node(spooky1)  [above right of = 1] {$\cdots$};
		\node(spooky2)  [below right of = 1] {$\cdots$};
		\node[state](2)  [semifill={black,ang=270}, above right of = spooky2] {};
		
		
		\draw[->] (a) -- (geist1) node[ midway,sloped,above,rotate=0] {};
		\draw[->] (a) -- (geist2) node[ midway,sloped,above,rotate=0] {};
		\draw[->] (geist1) -- (b) node[ midway,sloped,above,rotate=0] {};
		\draw[->] (geist2) -- (b) node[ midway,sloped,above,rotate=0] {};
		
		\draw[->] (1) -- (spooky1) node[ midway,sloped,above,rotate=0] {};
		\draw[->] (1) -- (spooky2) node[ midway,sloped,above,rotate=0] {};
		\draw[->] (spooky1) -- (2) node[ midway,sloped,above,rotate=0] {};
		\draw[->] (spooky2) -- (2) node[ midway,sloped,above,rotate=0] {};
		
		\draw[->] (b) -- (f) node[ midway,sloped,above,rotate=0] {$\varepsilon$};
		\draw[->] (f) -- (1) node[ midway,sloped,above,rotate=0] {$\varepsilon$};
		\draw[->, bend left,  out=20,in=90] (2) to node[ midway,above,rotate=0] {$\varepsilon$} (f) ;
		
		\node[draw,fit=(a) (b) (geist1) (geist2)] {};
		\node[draw,fit=(1) (2) (spooky1) (spooky2)] {};
		\end{tikzpicture} 
	\end{figure}

	Mit $I=\{q_0\}$ und $F= \{f\}$. Entferne nun die $\varepsilon$-Übergänge und wir sind fertig.
	\bewiesen
	
\subsubsection{Zur Notation im folgenden Kapitel}
	Es ist $A = (Q, \Sigma, \delta, I,F)$ ein Büchi Automat mit $\delta \subseteq Q \times\Sigma \times Q$ und $L \subseteq \Sigma\pom$ sowie $$h:\Sigma^+ \to H$$ ein Hom. von Halbgruppen mit $h(\sigstern) = H$ (surjektiv) und $|H| < \infty$. 





\end{document}


